diff -urN linux-orig/fs/gfs_locking/lock_gulm/gio_wiretypes.h linux-patched/fs/gfs_locking/lock_gulm/gio_wiretypes.h
--- linux-orig/fs/gfs_locking/lock_gulm/gio_wiretypes.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gio_wiretypes.h	2005-01-12 17:20:30.280663287 -0600
@@ -0,0 +1,467 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+#ifndef __gio_wiretypes_h__
+#define __gio_wiretypes_h__
+
+/* an attempt to do something about tracking changes to the protocol over
+ * the wires.
+ * If I was really cute, this would be effectivily a checksum of this file.
+ */
+#define GIO_WIREPROT_VERS (0x67000014)
+
+/*****************Error codes.
+ * everyone uses these same error codes.
+ */
+#define gio_Err_Ok              (0)
+#define gio_Err_BadLogin        (1001)
+#define gio_Err_BadCluster      (1003)
+#define gio_Err_BadConfig       (1004)
+#define gio_Err_BadGeneration   (1005)
+#define gio_Err_BadWireProto    (1019)
+
+#define gio_Err_NotAllowed      (1006)
+#define gio_Err_Unknown_Cs      (1007)
+#define gio_Err_BadStateChg     (1008)
+#define gio_Err_MemoryIssues    (1009)
+
+#define gio_Err_TryFailed       (1011)
+#define gio_Err_AlreadyPend     (1013)
+#define gio_Err_Canceled        (1015)
+
+/* next free error code: 1002 1010 1012 1014 1016 1017 1018 1020 */
+
+/*
+ * Error:  just sort of a generic error code thing.
+ *    uint32: gERR
+ *    uint32: opcode that this is in reply to. (can be zeros)
+ *    uint32: error code
+ */
+#define gulm_err_reply (0x67455252) /* gERR */
+
+#define gulm_nop (0x674e4f50)  /* gNOP */
+
+/********************* Core *****************/
+/* 
+ * login request
+ *    uint32: gCL0
+ *    uint32: proto version
+ *    string: cluster ID
+ *    string: My Name
+ *    uint64: generation number
+ *    uint32: config CRC
+ *    uint32: rank
+ * login reply
+ *    uint32: gCL1
+ *    uint64: generation number
+ *    uint32: error code
+ *    uint32: rank
+ *    uint8:  ama
+ *   If I am the Master or Arbitrating and there are no errors, A
+ *   serialization of the current nodelist follows. And a client or slave
+ *   is connecting (not resources).
+ *
+ * logout request:
+ *    uint32: gCL2
+ *    string: node name
+ *    uint8:  S/P/A/M/R
+ * logout reply:   Don't seem to use this....
+ *    uint32: gCL3
+ *    uint32: error code
+ *
+ * resource login request:
+ *    uint32: gCL4
+ *    uint32: proto version
+ *    string: cluster ID
+ *    string: resource name
+ *    uint32: options
+ *  login reply (gCL1) is sent in return.
+ *
+ * beat req
+ *    uint32: gCB0
+ *    string: My Name
+ * beat rpl
+ *    uint32: gCB1
+ *    uint32: error code
+ *
+ * Membership Request
+ *    uint32: gCMA
+ *    string: node name
+ *
+ * Membership update
+ *    uint32: gCMU
+ *    string: node name
+ *    IPv6:   IP
+ *    uint8:  Current State
+ *
+ * Membership list request info.
+ *    uint32: gCMl
+ *
+ * Membership list info.
+ *    uint32: gCML
+ *    list_start_marker
+ *     string: node name
+ *     IPv6:   IP
+ *     uint8:  state
+ *     uint8:  laststate
+ *     uint8:  mode (S/P/A/M/C)
+ *     uint32: missed beats
+ *     uint64: last beat
+ *     uint64: delay avg
+ *     uint64: max delay
+ *    list_stop_marker
+ *
+ * Request Resource info
+ *    uint32: gCR0
+ *
+ * Resource list info
+ *    uint32: gCR1
+ *    list_start_marker
+ *     string: name
+ *    list_stop_marker
+ *
+ * Force node into Expired:
+ *    uint32: gCFE
+ *    string: node name
+ *
+ * Core state request:
+ *    uint32: gCSR
+ *
+ * Core state changes:
+ *    uint32: gCSC
+ *    uint8:  state  (slave, pending, arbitrating, master)
+ *    uint8:  quorate (true/false)
+ *  If state == Slave, then the next two will follow.
+ *    IPv6:   MasterIP
+ *    string: MasterName
+ *
+ * Quorum Change:
+ *    uint32: gCQC
+ *    uint8:  quorate (true/false)
+ *
+ * Core shutdown req:
+ *    uint32: gCSD
+ *
+ * Switch core from current state into Pending:
+ *    uint32: gCSP
+ *
+ */
+#define gulm_core_login_req  (0x67434c00) /* gCL0 */
+#define gulm_core_login_rpl  (0x67434c01) /* gCL1 */
+#define gulm_core_logout_req (0x67434c02) /* gCL2 */
+#define gulm_core_logout_rpl (0x67434c03) /* gCL3 */
+#define gulm_core_reslgn_req (0x67434c04) /* gCL4 */
+#define gulm_core_beat_req   (0x67434200) /* gCB0 */
+#define gulm_core_beat_rpl   (0x67434201) /* gCB1 */
+#define gulm_core_mbr_req    (0x67434d41) /* gCMA */
+#define gulm_core_mbr_updt   (0x67434d55) /* gCMU */
+#define gulm_core_mbr_lstreq (0x67434d6c) /* gCMl */
+#define gulm_core_mbr_lstrpl (0x67434d4c) /* gCML */
+#define gulm_core_mbr_force  (0x67434645) /* gCFE */
+#define gulm_core_res_req    (0x67435200) /* gCR0 */
+#define gulm_core_res_list   (0x67435201) /* gCR1 */
+#define gulm_core_state_req  (0x67435352) /* gCSR */
+#define gulm_core_state_chgs (0x67435343) /* gCSC */
+#define gulm_core_quorm_chgs (0x67435143) /* gCSC */
+#define gulm_core_shutdown   (0x67435344) /* gCSD */
+#define gulm_core_forcepend  (0x67435350) /* gCSP */
+
+/* in the st field */
+#define gio_Mbr_Logged_in  (0x05)
+#define gio_Mbr_Logged_out (0x06)
+#define gio_Mbr_Expired    (0x07)
+#define gio_Mbr_Killed     (0x08)
+#define gio_Mbr_OM_lgin    (0x09)
+
+/* in the ama field */
+#define gio_Mbr_ama_Slave       (0x01)
+#define gio_Mbr_ama_Master      (0x02)
+#define gio_Mbr_ama_Pending     (0x03)
+#define gio_Mbr_ama_Arbitrating (0x04)
+#define gio_Mbr_ama_Resource    (0x05)
+#define gio_Mbr_ama_Client      (0x06)
+/* the Client entery is ONLY for mode tracking.
+ * nodelist reply is the only place it is used.
+ */
+
+/* options that affect behavors on services. (resources) */
+#define gulm_svc_opt_important (0x00000001)
+#define gulm_svc_opt_locked    (0x00000002)
+
+/********************* Info Traffic *****************
+ *
+ * Note that for many of these, they can be sent to all of the servers and
+ * will get sane replies.  Some of these can only be sent to specific
+ * servers.
+ *
+ * stats req:
+ *    uint32: gIS0
+ * stats rpl:
+ *    uint32: gIS1
+ *    list start:
+ *       string: key
+ *       string: value
+ *    list stop:
+ * Notes:
+ *  The stats reply is a set of string pairs.  This way the server can send
+ *  whatever things it wants, and the same client code will work for
+ *  anything.
+ *
+ * set verbosity:
+ *    uint32: gIV0
+ *    string: verb flags (with -/+) to [un]set
+ * Note:
+ *  We don't bother with a reply for this.  If the server got it, it works.
+ *  If it didn't, it cannot send an error back anyways.
+ *
+ * close socket:
+ *   uint32: gSC0
+ * Note:
+ *   Tells the server to close this connection cleanly.  We're done with
+ *   it.  This is *not* the same as loging out.  You must login before you
+ *   can logout.  And many commands sent from gulm_tool happen without
+ *   logging in.  These commands would be useful for clients in many cases,
+ *   so I don't want to put a close at the end of them, but if I don't,
+ *   there will be error messages printed on the console when gulm_tool
+ *   calls them.
+ *   So we need a way to close a connection cleanly that has not been
+ *   logged in.
+ *
+ * request slave list:
+ *    uint32: gIL0
+ * slave list replay:
+ *    uint32: gIL1
+ *    list start:
+ *       string: name
+ *       uint32: poller idx
+ *    list stop:
+ */
+#define gulm_info_stats_req      (0x67495300) /* gIS0 */
+#define gulm_info_stats_rpl      (0x67495301) /* gIS1 */
+#define gulm_info_set_verbosity  (0x67495600) /* gIV0 */
+#define gulm_socket_close        (0x67534300) /* gSC0 */
+#define gulm_info_slave_list_req (0x67494c00) /* gIL0 */
+#define gulm_info_slave_list_rpl (0x67494c01) /* gIL1 */
+
+/********************* Lock Traffic *****************
+ * All lock traffic.
+ *
+ * login req:
+ *    uint32: gLL0
+ *    uint32: proto version
+ *    string: node name
+ *    uint8:  Client/Slave
+ * login rpl:
+ *    uint32: gLL1
+ *    uint32: error code
+ *    uint8:  Slave/Master
+ *    xdr of current lock state if no errors and master sending reply
+ *       and you're a slave.
+ *       uh, i think i assume that it is only four bytes in some places.
+ *       Need to look into this...
+ *
+ * logout req:
+ *    uint32: gLL2
+ * logout rpl:
+ *    uint32: gLL3
+ *
+ * select lockspace:
+ *    uint32: gLS0
+ *    raw:    usually just four bytes for lockspace name.
+ *            but can be most anything.
+ *
+ * lock req:
+ *    uint32: gLR0
+ *    raw:    key
+ *    uint64: sub id
+ *    uint64: start
+ *    uint64: stop
+ *    uint8:  state
+ *    uint32: flags
+ *    raw:    lvb -- Only exists if hasLVB flag is true.
+ * lock rpl:
+ *    uint32: gLR1
+ *    raw:    key
+ *    uint64: sub id
+ *    uint64: start
+ *    uint64: stop
+ *    uint8:  state
+ *    uint32: flags
+ *    uint32: error code
+ *    raw:    lvb -- Only exists if hasLVB flag is true.
+ *
+ * lock state update:
+ *    uint32: gLRU
+ *    string: node name
+ *    uint64: sub id
+ *    uint64: start
+ *    uint64: stop
+ *    raw:    key
+ *    uint8:  state
+ *    uint32: flags
+ *    raw:    lvb -- Only exists if hasLVB flag is true.
+ *
+ * Action req:
+ *    uint32: gLA0
+ *    raw:    key
+ *    uint64: sub id
+ *    uint8:  action
+ *    raw:    lvb -- Only exists if action is SyncLVB
+ * Action Rpl:
+ *    uint32: gLA1
+ *    raw:    key
+ *    uint64: sub id
+ *    uint8:  action
+ *    uint32: error code
+ *
+ * Action update:
+ *    uint32: gLAU
+ *    string: node name
+ *    uint64: sub id
+ *    raw:    key
+ *    uint8:  action
+ *    raw:    lvb -- Only exists if action is SyncLVB
+ *
+ * Slave Update Rply:   -- for both actions and requests.
+ *    uint32: gLUR
+ *    raw:    key
+ *
+ * Query Lock request:
+ *    uint32: gLQ0
+ *    raw:    key
+ *    uint64: subid
+ *    uint64: start
+ *    uint64: stop
+ *    uint8:  state
+ * 
+ * Query Lock Reply:
+ *    uint32: gLQ1
+ *    raw:    key
+ *    uint64: subid
+ *    uint64: start
+ *    uint64: stop
+ *    uint8:  state
+ *    uint32: error
+ *    list start mark
+ *     string: node
+ *     uint64: subid
+ *     uint64: start
+ *     uint64: stop
+ *     uint8:  state
+ *    list stop mark
+ *
+ * Drop lock Callback:
+ *    uint32: gLC0
+ *    raw:    key
+ *    uint64: subid
+ *    uint8:  state
+ *
+ * Drop all locks callback:  This is the highwater locks thing
+ *    uint32: gLC2
+ *
+ * Drop expired locks:
+ *    uint32: gLEO
+ *    string: node name  if NULL, then drop all exp for mask.
+ *    raw:    keymask  if keymask & key == key, then dropexp on this lock.
+ *
+ * Expire Locks:
+ *    uint32: gLEE
+ *    string: node name  cannot be NULL
+ *    raw:    keymask  if keymask & key == key, then expire on this lock.
+ *
+ * Lock list req:
+ *    uint32: gLD0
+ * Lock list rpl:
+ *    uint32: gLD1
+ *    list start mark
+ *     uint8: key length
+ *     raw:   key
+ *     uint8: lvb length
+ *     if lvb length > 0, raw: LVB
+ *     uint32: Holder count
+ *     list start mark
+ *      string: holders
+ *      uint64: subid
+ *      uint8: state
+ *      uint64: start
+ *      uint64: stop
+ *     list stop mark
+ *     uint32: LVB holder count
+ *     list start mark
+ *      string: LVB Holders
+ *      uint64: subid
+ *     list stop mark
+ *     uint32: Expired holder count
+ *     list start mark
+ *      string: ExpHolders
+ *      uint64: subid
+ *     list stop mark
+ *    list stop mark
+ *
+ */
+#define gulm_lock_login_req   (0x674C4C00) /* gLL0 */
+#define gulm_lock_login_rpl   (0x674C4C01) /* gLL1 */
+#define gulm_lock_logout_req  (0x674C4C02) /* gLL2 */
+#define gulm_lock_logout_rpl  (0x674C4C03) /* gLL3 */
+#define gulm_lock_sel_lckspc  (0x674C5300) /* gLS0 */
+#define gulm_lock_state_req   (0x674C5200) /* gLR0 */
+#define gulm_lock_state_rpl   (0x674C5201) /* gLR1 */
+#define gulm_lock_state_updt  (0x674C5255) /* gLRU */
+#define gulm_lock_action_req  (0x674C4100) /* gLA0 */
+#define gulm_lock_action_rpl  (0x674C4101) /* gLA1 */
+#define gulm_lock_action_updt (0x674C4155) /* gLAU */
+#define gulm_lock_update_rpl  (0x674c5552) /* gLUR */
+#define gulm_lock_query_req   (0x674c5100) /* gLQ0 */
+#define gulm_lock_query_rpl   (0x674c5101) /* gLQ1 */
+#define gulm_lock_cb_state    (0x674C4300) /* gLC0 */
+#define gulm_lock_cb_dropall  (0x674C4302) /* gLC2 */
+#define gulm_lock_drop_exp    (0x674C454F) /* gLEO */
+#define gulm_lock_expire      (0x674C4545) /* gLEE */
+#define gulm_lock_dump_req    (0x674c4400) /* gLD0 */
+#define gulm_lock_dump_rpl    (0x674c4401) /* gLD1 */
+#define gulm_lock_rerunqueues (0x674c5251) /* gLRQ */
+
+/* marks for the login */
+#define gio_lck_st_Slave     (0x00)
+#define gio_lck_st_Client    (0x01)
+
+/* state change requests */
+#define gio_lck_st_Unlock    (0x00)
+#define gio_lck_st_Exclusive (0x01)
+#define gio_lck_st_Deferred  (0x02)
+#define gio_lck_st_Shared    (0x03)
+/* actions */
+#define gio_lck_st_Cancel    (0x09)
+#define gio_lck_st_HoldLVB   (0x0b)
+#define gio_lck_st_UnHoldLVB (0x0c)
+#define gio_lck_st_SyncLVB   (0x0d)
+
+/* flags */
+#define gio_lck_fg_Do_CB       (0x00000001)
+#define gio_lck_fg_Try         (0x00000002)
+#define gio_lck_fg_Any         (0x00000004)
+#define gio_lck_fg_NoExp       (0x00000008)
+#define gio_lck_fg_hasLVB      (0x00000010)
+#define gio_lck_fg_Cachable    (0x00000020)
+#define gio_lck_fg_Piority     (0x00000040)
+ /* this is just an idea, but it might be useful.  Basically just says to
+  * not keep the exp hold, just drop this hold like a shared would be.
+  */
+#define gio_lck_fg_DropOnExp   (0x00000080)
+ /* this is saved on each holder, basically, you are gonna ignore any
+  * callbacks about this lock, so tell the server not to even bother
+  * sending them.  A tiny performance boost by lowering the network load.
+  */
+#define gio_lck_fg_NoCallBacks (0x00000100)
+
+#endif /*__gio_wiretypes_h__*/
+/* vim: set ai cin et sw=3 ts=3 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm.h linux-patched/fs/gfs_locking/lock_gulm/gulm.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm.h	2005-01-12 17:20:30.280663287 -0600
@@ -0,0 +1,245 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef GULM_DOT_H
+#define GULM_DOT_H
+
+#define GULM_RELEASE_NAME "<CVS>"
+
+/* uh, do I need all of these headers? */
+#ifdef MODVERSIONS
+#include <linux/modversions.h>
+#endif				/*  MODVERSIONS  */
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <asm/atomic.h>
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/smp_lock.h>
+#include <linux/list.h>
+#include <linux/types.h>
+#include <linux/fs.h>
+
+#ifndef TRUE
+#define TRUE (1)
+#endif
+
+#ifndef FALSE
+#define FALSE (0)
+#endif
+
+#if (BITS_PER_LONG == 64)
+#define PRIu64 "lu"
+#define PRId64 "ld"
+#define PRIo64 "lo"
+#define PRIx64 "lx"
+#define PRIX64 "lX"
+#define SCNu64 "lu"
+#define SCNd64 "ld"
+#define SCNo64 "lo"
+#define SCNx64 "lx"
+#define SCNX64 "lX"
+#else
+#define PRIu64 "Lu"
+#define PRId64 "Ld"
+#define PRIo64 "Lo"
+#define PRIx64 "Lx"
+#define PRIX64 "LX"
+#define SCNu64 "Lu"
+#define SCNd64 "Ld"
+#define SCNo64 "Lo"
+#define SCNx64 "Lx"
+#define SCNX64 "LX"
+#endif
+
+
+#undef MAX
+#define MAX(a,b) ((a>b)?a:b)
+
+#undef MIN
+#define MIN(a,b) ((a<b)?a:b)
+
+/*  Divide x by y.  Round up if there is a remainder.  */
+#define DIV_RU(x, y) (((x) + (y) - 1) / (y))
+
+#include <linux/lm_interface.h>
+
+#include "gulm_prints.h"
+
+#include "libgulm.h"
+
+#include "handler.h"
+
+/* Some fixed length constants.
+ * Some of these should be made dynamic in size in the future.
+ */
+#define GIO_KEY_SIZE  (48)
+#define GIO_LVB_SIZE  (32)
+#define GIO_NAME_SIZE (32)
+#define GIO_NAME_LEN  (GIO_NAME_SIZE-1)
+#define GULM_CRC_INIT (0x6d696b65)
+
+/* a hash bucket
+ * this puts the bucket list and the spinlock for the list next to each
+ * other.  Mostly because it makes things nice and easy if we're on a
+ * nonsmp machine and the spinlocks don't exist.  (previously I tried to
+ * malloc nothing.  kernel wasn't happy about that.)
+ *
+ * An array of these makes a hash table.
+ */
+struct gulm_hash_bucket_s {
+	struct list_head bucket;
+	spinlock_t lock;
+};
+typedef struct gulm_hash_bucket_s gulm_hb_t;
+
+/* What we know about this filesytem */
+struct gulm_fs_s {
+	struct list_head fs_list;
+	char fs_name[GIO_NAME_SIZE];	/* lock table name */
+
+	lm_callback_t cb;	/* file system callback function */
+	lm_fsdata_t *fsdata;	/* private file system data */
+
+	callback_qu_t cq;
+
+	uint32_t fsJID;
+	uint32_t lvb_size;
+
+	/* Stuff for the first mounter lock and state */
+	int firstmounting;
+	/* the recovery done func needs to behave slightly differnt when we are
+	 * the first node in an fs.
+	 */
+
+	/* Stuff for JID mapping locks */
+	uint32_t JIDcount;	/* how many JID locks are there. */
+	struct semaphore headerlock;
+};
+typedef struct gulm_fs_s gulm_fs_t;
+
+typedef struct gulm_cm_s {
+	uint8_t myName[64];
+	uint8_t clusterID[256]; /* doesn't need to be 256. */
+	uint8_t starts;
+
+	uint32_t handler_threads;	/* howmany to have */
+	uint32_t verbosity;
+
+	uint64_t GenerationID;
+
+	/* lm interface pretty much requires that we maintian a table of
+	 * locks.  The way lvbs work is a prefect example of why.  As is
+	 * the panic you get if you send a cb up about a lock that has been
+	 * put away.
+	 */
+	gulm_hb_t *gfs_lockmap;
+
+	gulm_interface_p hookup;
+
+} gulm_cm_t;
+
+/* things about each lock. */
+typedef struct gulm_lock_s {
+   struct list_head gl_list;
+   atomic_t count; /* gfs can call multiple gets and puts for same lock. */
+
+   uint8_t *key;
+   uint16_t keylen;
+   gulm_fs_t *fs; /* which fs we belong to */
+   char *lvb;
+   int cur_state; /* for figuring out wat reply to tell gfs. */
+} gulm_lock_t;
+
+
+/*****************************************************************************/
+/* cross pollenate prototypes */
+
+/* from gulm_firstlock.c */
+int get_mount_lock (gulm_fs_t * fs, int *first);
+int downgrade_mount_lock (gulm_fs_t * fs);
+int drop_mount_lock (gulm_fs_t * fs);
+
+/* from gulm_lt.c */
+int gulm_lt_init (void);
+void gulm_lt_release(void);
+int pack_lock_key(uint8_t *key, uint16_t keylen, uint8_t type,
+		uint8_t *fsname, uint8_t *pk, uint8_t pklen);
+int pack_drop_mask(uint8_t *mask, uint16_t mlen, uint8_t *fsname);
+void do_drop_lock_req (uint8_t *key, uint16_t keylen, uint8_t state);
+int gulm_get_lock (lm_lockspace_t * lockspace, struct lm_lockname *name,
+	       lm_lock_t ** lockp);
+void gulm_put_lock (lm_lock_t * lock);
+unsigned int gulm_lock (lm_lock_t * lock, unsigned int cur_state,
+	   unsigned int req_state, unsigned int flags);
+unsigned int gulm_unlock (lm_lock_t * lock, unsigned int cur_state);
+void gulm_cancel (lm_lock_t * lock);
+int gulm_hold_lvb (lm_lock_t * lock, char **lvbp);
+void gulm_unhold_lvb (lm_lock_t * lock, char *lvb);
+void gulm_sync_lvb (lm_lock_t * lock, char *lvb);
+
+/* from gulm_plock.c */
+int gulm_punlock (lm_lockspace_t * lockspace, struct lm_lockname *name,
+	      struct file *file, struct file_lock *fl);
+int gulm_plock (lm_lockspace_t *lockspace, struct lm_lockname *name,
+		struct file *file, int cmd, struct file_lock *fl);
+int gulm_plock_get (lm_lockspace_t * lockspace, struct lm_lockname *name,
+		 struct file *file, struct file_lock *fl);
+
+/*from gulm_core.c */
+void cm_logout (void);
+int cm_login (void);
+void delete_ipnames (struct list_head *namelist);
+
+/* from gulm_fs.c */
+void init_gulm_fs (void);
+void request_journal_replay (uint8_t * name);
+void check_all_for_stales(void);
+void passup_droplocks (void);
+gulm_fs_t *get_fs_by_name (uint8_t * name);
+void dump_internal_lists (void);
+void gulm_recovery_done (lm_lockspace_t * lockspace,
+			 unsigned int jid, unsigned int message);
+void gulm_unmount (lm_lockspace_t * lockspace);
+void gulm_others_may_mount (lm_lockspace_t * lockspace);
+int gulm_mount (char *table_name, char *host_data,
+		lm_callback_t cb, lm_fsdata_t * fsdata,
+		unsigned int min_lvb_size, struct lm_lockstruct *lockstruct);
+void gulm_withdraw (lm_lockspace_t * lockspace);
+
+/* from gulm_jid.c */
+void jid_fs_init (gulm_fs_t * fs);
+void jid_fs_release (gulm_fs_t * fs);
+void get_journalID (gulm_fs_t * fs);
+int lookup_name_by_jid (gulm_fs_t * fs, uint32_t jid, uint8_t * name);
+void release_JID (gulm_fs_t * fs, uint32_t jid);
+void put_journalID (gulm_fs_t * fs, int leavebehind);
+void check_for_stale_expires (gulm_fs_t * fs);
+
+int find_jid_by_name_and_mark_replay (gulm_fs_t * fs, uint8_t * name, uint32_t * jid);
+
+/* to be called from the lg_lock callbacks. */
+void jid_header_lock_drop (uint8_t * key, uint16_t keylen);
+void sig_watcher_lock_drop(uint8_t * key, uint16_t keylen);
+
+/* from gulm_recsig.c */
+void tap_sig(gulm_fs_t *fs, uint8_t *name, uint8_t len);
+int watch_sig(gulm_fs_t *fs, uint8_t *name, uint8_t len,
+		void(*func)(void *misc), void *misc);
+void sig_watcher_init(void);
+
+extern struct lm_lockops gulm_ops;
+
+#endif				/*  GULM_DOT_H  */
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_core.c linux-patched/fs/gfs_locking/lock_gulm/gulm_core.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_core.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_core.c	2005-01-12 17:20:30.281663062 -0600
@@ -0,0 +1,259 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "gulm_lock_queue.h"
+#include "utils_tostr.h"
+
+extern gulm_cm_t gulm_cm;
+
+/* private vars. */
+int cm_thd_running;
+struct completion cm_thd_startup;
+struct task_struct *cm_thd_task;
+/**
+ */
+int
+gulm_core_login_reply (void *misc, uint64_t gen, uint32_t error,
+		       uint32_t rank, uint8_t corestate)
+{
+	if (error != 0) {
+		log_err ("Core returned error %d:%s.\n", error,
+			 gio_Err_to_str (error));
+		cm_thd_running = FALSE;
+		return error;
+	}
+
+	if( gulm_cm.GenerationID != 0 ) {
+		GULM_ASSERT(gulm_cm.GenerationID == gen,
+				printk("us: %"PRIu64" them: %"PRIu64"\n",
+					gulm_cm.GenerationID,gen);
+				);
+	}
+	gulm_cm.GenerationID = gen;
+
+
+	log_msg (lgm_Network2, "Logged into local core.\n");
+
+	return 0;
+}
+
+/**
+ * gulm_core_logout_reply - 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_core_logout_reply (void *misc)
+{
+	log_msg (lgm_Network2, "Logged out of local core.\n");
+	return 0;
+}
+
+/**
+ */
+int
+gulm_core_nodechange (void *misc, char *nodename,
+		      struct in6_addr *nodeip, uint8_t nodestate)
+{
+	if (nodestate == lg_core_Fenced) {
+		request_journal_replay (nodename);
+	}
+	/* if me and state is logout, Need to close out things if we can.
+	 */
+	if (gulm_cm.starts && nodestate == lg_core_Logged_out &&
+			strcmp(gulm_cm.myName, nodename) == 0 ) {
+		glq_shutdown ();
+		cm_thd_running = FALSE;
+		lg_core_logout (gulm_cm.hookup);
+		return -1;
+	}
+	return 0;
+}
+
+int gulm_core_statechange (void *misc, uint8_t corestate, uint8_t quorate,
+                           struct in6_addr *masterip, char *mastername)
+{
+	int *cst = (int *)misc;
+	if( misc != NULL ) {
+		if( corestate != lg_core_Slave &&
+				corestate != lg_core_Master ) {
+			*cst = TRUE;
+		}else{
+			*cst = FALSE;
+		}
+	}
+	if( corestate == lg_core_Slave ||
+	    corestate == lg_core_Master ) {
+	   /* we should be part of a live, quorate cluster now. */
+	    check_all_for_stales();
+	}
+	return 0;
+}
+
+/**
+ */
+int
+gulm_core_error (void *misc, uint32_t err)
+{
+	log_err ("Got error code %d %#x back fome some reason!\n", err, err);
+	return 0;
+}
+
+static lg_core_callbacks_t core_cb = {
+      login_reply:gulm_core_login_reply,
+      logout_reply:gulm_core_logout_reply,
+      nodechange:gulm_core_nodechange,
+      statechange:gulm_core_statechange,
+      error:gulm_core_error
+};
+
+/**
+ * cm_io_recving_thread - 
+ * @data: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+cm_io_recving_thread (void *data)
+{
+	int err;
+
+	daemonize ("gulm_res_recvd");
+	cm_thd_task = current;
+	complete (&cm_thd_startup);
+
+	while (cm_thd_running) {
+		err = lg_core_handle_messages (gulm_cm.hookup, &core_cb, NULL);
+		if (err != 0) {
+			log_err
+			    ("Got an error in gulm_res_recvd err: %d\n", err);
+			if (!cm_thd_running)
+				break;
+			/* 
+			 * Pause a bit, then try to log back into the local
+			 * lock_gulmd.  Keep doing this until an outside force
+			 * stops us. (which I don't think there is any at this
+			 * point.  forceunmount would be one, if we ever do
+			 * that.)
+			 *
+			 * If we are still in the gulm_mount() function, we
+			 * should not retry. We should just exit.
+			 *
+			 * Is this really smart?  There is zero garuntees
+			 * that the state of things will be usable when we
+			 * return.
+			 *
+			 */
+			current->state = TASK_INTERRUPTIBLE;
+			schedule_timeout (3 * HZ);
+
+			while ((err =
+				lg_core_login (gulm_cm.hookup, TRUE)) != 0) {
+				log_err
+				    ("Got a %d trying to login to lock_gulmd.  Is it running?\n",
+				     err);
+				current->state = TASK_INTERRUPTIBLE;
+				schedule_timeout (3 * HZ);
+			}
+		}
+	}			/* while( gulm_cm.cm_thd_running ) */
+
+	complete (&cm_thd_startup);
+	return 0;
+}
+
+/**
+ * cm_logout - 
+ */
+void
+cm_logout (void)
+{
+
+	if (cm_thd_running) {
+		cm_thd_running = FALSE;
+		lg_core_logout (gulm_cm.hookup);
+
+		/* wait for thread to finish */
+		wait_for_completion (&cm_thd_startup);
+	}
+
+}
+
+/**
+ * cm_login - 
+ * 
+ * Returns: int
+ */
+int
+cm_login (void)
+{
+	int err = -1;
+	int cst=TRUE;
+
+	cm_thd_running = FALSE;
+	init_completion (&cm_thd_startup);
+
+	err = lg_core_login (gulm_cm.hookup, TRUE);
+	if (err != 0) {
+		log_err
+		    ("Got a %d trying to login to lock_gulmd.  Is it running?\n",
+		     err);
+		goto exit;
+	}
+	/* handle login reply.  which will start the lt thread. */
+	err = lg_core_handle_messages (gulm_cm.hookup, &core_cb, NULL);
+	if (err != 0) {
+		goto exit;
+	}
+
+	/* do not pass go until Slave(client) or Master */
+	while(cst) {
+		lg_core_corestate(gulm_cm.hookup);
+		err = lg_core_handle_messages (gulm_cm.hookup, &core_cb, &cst);
+		if (err != 0) {
+			goto exit;
+		}
+		if(cst) {
+			current->state = TASK_INTERRUPTIBLE;
+			schedule_timeout (3 * HZ);
+			/* TODO if interrupted, exit */
+		}
+	}
+
+	/* start recver thread. */
+	cm_thd_running = TRUE;
+	err = kernel_thread (cm_io_recving_thread, NULL, 0);
+	if (err < 0) {
+		log_err ("Failed to start gulm_res_recvd. (%d)\n", err);
+		goto exit;
+	}
+	wait_for_completion (&cm_thd_startup);
+
+	err = 0;
+      exit:
+	if (err > 0) err = - err;
+	return err;
+}
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_firstlock.c linux-patched/fs/gfs_locking/lock_gulm/gulm_firstlock.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_firstlock.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_firstlock.c	2005-01-12 17:20:30.291660810 -0600
@@ -0,0 +1,310 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#include <linux/crc32.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "handler.h"
+#include "gulm_lock_queue.h"
+
+extern gulm_cm_t gulm_cm;
+
+/****************************************************************************/
+struct gulm_flck_return_s {
+	int error;
+	struct completion sleep;
+};
+
+/**
+ * gulm_firstlock_finish - 
+ * @item: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_firstlock_finish (struct glck_req *item)
+{
+	struct gulm_flck_return_s *g = (struct gulm_flck_return_s *)item->misc;
+	g->error = item->error;
+	complete (&g->sleep);
+}
+
+/**
+ * gulm_cancel_firstlock - 
+ * @misc: 
+ * 
+ */
+void gulm_cancel_firstlock (void *misc)
+{
+	gulm_fs_t *fs = (gulm_fs_t *)misc;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		log_err ("Out of memory, Cannot cancel Firstlock request.\n");
+		return;
+	}
+
+	/* after cancel is processed, glq will call kfree on item->key. */
+	item->key = kmalloc(GIO_KEY_SIZE, GFP_KERNEL);
+	if (item->key == NULL) {
+		glq_recycle_req(item);
+		log_err ("Out of memory, Cannot cancel Firstlock request.\n");
+		return;
+	}
+	item->keylen = pack_lock_key(item->key, GIO_KEY_SIZE, 'F',
+			fs->fs_name, "irstMount", 9);
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_cancel;
+	item->finish = NULL;
+
+	glq_cancel(item);
+}
+
+/**
+ * do_lock_time_out - 
+ * @d: 
+ *
+ * after timeout, set cancel request on the handler queue. (since we cannot
+ * call it from within the timer code. (socket io within interrupt space is
+ * bad.))
+ * 
+ */
+static void
+do_lock_time_out (unsigned long d)
+{
+	gulm_fs_t *fs = (gulm_fs_t *)d;
+	qu_function_call (&fs->cq, gulm_cancel_firstlock, fs);
+}
+
+/**
+ * get_mount_lock - 
+ * @fs: 
+ * @first: 
+ * 
+ * Get the Firstmount lock.
+ * We try to grab it Exl.  IF we get that, then we are the first client
+ * mounting this fs.  Otherwise we grab it shared to show that there are
+ * clients using this fs.
+ * 
+ * Returns: int
+ */
+int
+get_mount_lock (gulm_fs_t * fs, int *first)
+{
+	int err, keylen;
+	struct timer_list locktimeout;
+	struct gulm_flck_return_s gret;
+	uint8_t key[GIO_KEY_SIZE];
+	glckr_t *item;
+
+	keylen = pack_lock_key(key, GIO_KEY_SIZE, 'F', fs->fs_name, "irstMount", 9);
+	if( keylen <= 0 ) return keylen;
+
+
+      try_it_again:
+	*first = FALSE;		/* assume we're not first */
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	/* glq does not try to free the key for state or action requests. */
+	item->key = key;
+	item->keylen = keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Exclusive;
+	item->flags = lg_lock_flag_Try|lg_lock_flag_IgnoreExp|lg_lock_flag_NoCallBacks;
+	item->error = gret.error = 0;
+
+	init_completion (&gret.sleep);
+
+	item->misc = &gret;
+	item->finish = gulm_firstlock_finish;
+
+	glq_queue (item);
+	wait_for_completion (&gret.sleep);
+
+	if (gret.error == 0) {
+		/* we got the lock, we're the first mounter. */
+		*first = TRUE;
+		log_msg (lgm_locking, "fsid=%s: Got mount lock Exclusive.\n",
+			 fs->fs_name);
+		return 0;
+	} else {
+		log_msg (lgm_locking,
+			 "fsid=%s: Didn't get mount lock Exl, someone else "
+			 "was first, trying for shared.\n", fs->fs_name);
+
+		/* the try failed, pick it up shared.
+		 * If it takes too long, start over.
+		 * */
+		init_timer (&locktimeout);
+		locktimeout.function = do_lock_time_out;
+		locktimeout.data = (unsigned long)fs;
+		mod_timer (&locktimeout, jiffies + (120 * HZ));
+
+		item = glq_get_new_req();
+		if (item == NULL) {
+			err = -ENOMEM;
+			goto fail;
+		}
+
+		item->key = key;
+		item->keylen = keylen;
+		item->subid = 0;
+		item->start = 0;
+		item->stop = ~((uint64_t)0);
+		item->type = glq_req_type_state;
+		item->state = lg_lock_state_Shared;
+		item->flags = lg_lock_flag_NoCallBacks;
+		item->error = gret.error = 0;
+
+		init_completion (&gret.sleep);
+
+		item->misc = &gret;
+		item->finish = gulm_firstlock_finish;
+
+		glq_queue (item);
+		wait_for_completion (&gret.sleep);
+
+		del_timer (&locktimeout);
+
+		if (gret.error == 0) {
+			/* kewl we got it. */
+			log_msg (lgm_locking,
+				 "fsid=%s: Got mount lock shared.\n",
+				 fs->fs_name);
+			return 0;
+		}
+
+		log_msg (lgm_locking,
+			 "fsid=%s: Shared req timed out, trying Exl again.\n",
+			 fs->fs_name);
+		goto try_it_again;
+	}
+      fail:
+	log_err ("Exit get_mount_lock err=%d\n", err);
+	return err;
+}
+
+/**
+ * downgrade_mount_lock - 
+ * @fs: 
+ * 
+ * drop the Firstmount lock down to shared.  This lets others mount.
+ * 
+ * Returns: int
+ */
+int
+downgrade_mount_lock (gulm_fs_t * fs)
+{
+	int keylen;
+	struct gulm_flck_return_s gret;
+	uint8_t key[GIO_KEY_SIZE];
+	glckr_t *item;
+
+	keylen = pack_lock_key(key, GIO_KEY_SIZE, 'F',
+			fs->fs_name, "irstMount", 9);
+	if( keylen <= 0 ) return keylen;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return -ENOMEM;
+	}
+
+	item->key = key;
+	item->keylen = keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Shared;
+	item->flags = lg_lock_flag_NoCallBacks;
+	item->error = gret.error = 0;
+
+	init_completion (&gret.sleep);
+
+	item->misc = &gret;
+	item->finish = gulm_firstlock_finish;
+
+	glq_queue (item);
+	wait_for_completion (&gret.sleep);
+
+	if (gret.error != 0)
+		log_err ("fsid=%s: Couldn't unlock mount lock!!!!!! %d\n",
+			 fs->fs_name, gret.error);
+	return 0;
+}
+
+/**
+ * drop_mount_lock - drop our hold on the firstmount lock.
+ * @fs: <> the filesystem pointer.
+ * 
+ * Returns: int
+ */
+int
+drop_mount_lock (gulm_fs_t * fs)
+{
+	int keylen;
+	struct gulm_flck_return_s gret;
+	uint8_t key[GIO_KEY_SIZE];
+	glckr_t *item;
+
+	keylen = pack_lock_key(key, GIO_KEY_SIZE, 'F', fs->fs_name, "irstMount", 9);
+	if( keylen <= 0 ) return keylen;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return -ENOMEM;
+	}
+
+	item->key = key;
+	item->keylen = keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Unlock;
+	item->flags = 0;
+	item->error = gret.error = 0;
+
+	init_completion (&gret.sleep);
+
+	item->misc = &gret;
+	item->finish = gulm_firstlock_finish;
+
+	glq_queue (item);
+	wait_for_completion (&gret.sleep);
+
+	if (gret.error != 0)
+		log_err ("fsid=%s: Couldn't unlock mount lock!!!!!! %d\n",
+			 fs->fs_name, gret.error);
+	return 0;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_fs.c linux-patched/fs/gfs_locking/lock_gulm/gulm_fs.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_fs.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_fs.c	2005-01-12 17:20:30.291660810 -0600
@@ -0,0 +1,782 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/utsname.h>	/* for extern system_utsname */
+
+#include "handler.h"
+#include "gulm_lock_queue.h"
+
+/* things about myself */
+extern gulm_cm_t gulm_cm;
+
+/* globals for this file.*/
+uint32_t filesystems_count = 0;
+LIST_HEAD (filesystems_list);
+struct semaphore filesystem_lck;	/* we use a sema instead of a spin
+					 * here because all of the
+					 * interruptible things we do
+					 * inside of it.  If i stop doing
+					 * nasty things within this it
+					 * doesn't need to be a sema.
+					 */
+struct semaphore start_stop_lock;
+atomic_t start_stop_cnt;
+
+/**
+ * init_gulm_fs - 
+ */
+void
+init_gulm_fs (void)
+{
+	init_MUTEX (&filesystem_lck);
+	init_MUTEX (&start_stop_lock);
+	atomic_set (&start_stop_cnt, 0);
+}
+
+/*****************************************************************************/
+struct rjrpf_s {
+	gulm_fs_t *fs;
+	uint8_t *name;
+};
+
+void
+request_journal_replay_per_fs (void *d)
+{
+	struct rjrpf_s *rf = (struct rjrpf_s *) d;
+	uint32_t jid;
+	unsigned int ujid;
+
+	/* lookup jid <=> name mapping */
+	if (find_jid_by_name_and_mark_replay (rf->fs, rf->name, &jid) != 0) {
+		log_msg (lgm_JIDMap,
+			 "In fs (%s), no jid for name (%s) was found.\n",
+			 rf->fs->fs_name, rf->name);
+	} else {
+		log_msg (lgm_JIDMap,
+			 "In fs (%s), jid %d was found for name (%s).\n",
+			 rf->fs->fs_name, jid, rf->name);
+
+		/* all that the replay journal call back into gfs does is
+		 * malloc some memory and add it to a list.  So we really
+		 * don't need to queue that action.  Since that is what gfs
+		 * is doing.
+		 *
+		 * This will need to change if gfs changes.
+		 *
+		 * Basically, we assume that the callback is non-blocking.
+		 */
+		ujid = jid;
+		rf->fs->cb (rf->fs->fsdata, LM_CB_NEED_RECOVERY, &ujid);
+	}
+
+	kfree (rf->name);
+	kfree (rf);
+
+}
+
+/**
+ * request_journal_replay - give a journal replay request to mounted filesystems
+ * @name: < the name of the node that died.
+ * 
+ * 
+ * Returns: void
+ */
+void
+request_journal_replay (uint8_t * name)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	struct rjrpf_s *rf;
+
+	log_msg (lgm_Always, "Checking for journals for node \"%s\"\n",
+		 name);
+
+	down (&filesystem_lck);
+
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+
+		/* we don't want to process replay requests when we are
+		 * still in the first mounter state.  All the journals are
+		 * getting replayed anyways, and there could be some issue
+		 * with stuff happening twice.
+		 */
+		if (fs->firstmounting)
+			continue;
+
+		/* due to the way the new jid mapping code works, we had to
+		 * move it out of here.
+		 * (making calls to the lock server.  Things can deadlock
+		 * if the jid mapping calls are made from this thread of
+		 * execution.)
+		 *
+		 * I need to look over this.  There HAS to be a better way
+		 * to manage the way we figgure out which journals gfs
+		 * needs to replay.
+		 */
+
+		rf = kmalloc (sizeof (struct rjrpf_s), GFP_KERNEL);
+		GULM_ASSERT (rf != NULL,);
+
+		rf->fs = fs;
+		rf->name = kmalloc (strlen (name) + 1, GFP_KERNEL);
+		GULM_ASSERT (rf->name != NULL,);
+		memcpy (rf->name, name, strlen (name) + 1);
+
+		qu_function_call (&fs->cq, request_journal_replay_per_fs, rf);
+
+	}
+	up (&filesystem_lck);
+}
+
+/* can you say kludges kids?!  I *knew* you could. */
+void
+cast_check_for_stale_expires(void*d)
+{
+	check_for_stale_expires(d);
+}
+/**
+ * check_all_for_stales - 
+ * 
+ * scan every fs we've got for possible journals that need replaying.
+ * 
+ */
+void
+check_all_for_stales(void)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	down (&filesystem_lck);
+
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		if (!fs->firstmounting) {
+			qu_function_call (&fs->cq, cast_check_for_stale_expires, fs);
+		}
+	}
+	up (&filesystem_lck);
+}
+
+/**
+ * passup_droplocks - 
+ */
+void
+passup_droplocks (void)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	down (&filesystem_lck);
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		qu_drop_req (&fs->cq, fs->cb, fs->fsdata, LM_CB_DROPLOCKS, 0,
+			     0);
+		/* If this decides to block someday, we need to change this
+		 * function.
+		 */
+	}
+	up (&filesystem_lck);
+}
+
+#if 0
+/**
+ * dump_internal_lists - 
+ * 
+ */
+void
+dump_internal_lists (void)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	down (&filesystem_lck);
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		log_msg (lgm_Always, "Handler queue for %s\n", fs->fs_name);
+		display_handler_queue (&fs->cq);
+		/* other lists? */
+	}
+	up (&filesystem_lck);
+}
+#endif
+
+/**
+ * get_fs_by_name - 
+ * @name: 
+ * 
+ * 
+ * Returns: gulm_fs_t
+ */
+gulm_fs_t *
+get_fs_by_name (uint8_t * name)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs = NULL;
+	down (&filesystem_lck);
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		if (strcmp (name, fs->fs_name) == 0) {
+			up (&filesystem_lck);
+			return fs;
+		}
+	}
+	up (&filesystem_lck);
+	return NULL;
+}
+
+/*****************************************************************************/
+
+/**
+ * start_gulm_threads - 
+ * @host_data: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+start_gulm_threads (char *csnm, char *hostdata)
+{
+	int error = 0;
+
+	down (&start_stop_lock);
+	atomic_inc (&start_stop_cnt);
+	if (atomic_read (&start_stop_cnt) == 1) {
+		/* first one. get stuff going */
+		strncpy (gulm_cm.clusterID, csnm, 255);
+		gulm_cm.clusterID[255] = '\0';
+
+		if (hostdata != NULL && strlen (hostdata) > 0) {
+			strncpy (gulm_cm.myName, hostdata, 64);
+		} else {
+			strncpy (gulm_cm.myName, system_utsname.nodename, 64);
+		}
+		gulm_cm.myName[63] = '\0';
+
+
+		error = lg_initialize (&gulm_cm.hookup, gulm_cm.clusterID,
+				       "GFS Kernel Interface");
+		if (error != 0) {
+			log_err ("lg_initialize failed, %d\n", error);
+			goto fail;
+		}
+		gulm_cm.starts = TRUE;
+
+		/* breaking away from ccs. just hardcoding defaults here.
+		 * Noone really used these anyways and if ppl want them
+		 * badly, we'll find another way to set them. (modprobe
+		 * options for example. or maybe sysfs?)
+		 * ppl want verbosity
+		 * */
+		gulm_cm.handler_threads = 2;
+		gulm_cm.verbosity = lgm_Network ;
+
+		error = cm_login ();
+		if (error != 0) {
+			log_err ("cm_login failed. %d\n", error);
+			goto fail;
+		}
+		error = glq_startup ();
+		if (error != 0) {
+			log_err ("glq_startup failed. %d\n", error);
+			goto fail;
+		}
+
+	}
+      fail:
+	up (&start_stop_lock);
+	return error;
+}
+
+/**
+ * stop_gulm_threads - 
+ */
+void
+stop_gulm_threads (void)
+{
+	down (&start_stop_lock);
+	atomic_dec (&start_stop_cnt);
+	if (atomic_read (&start_stop_cnt) == 0) {
+		/* last one, put it all away. */
+		glq_shutdown ();
+		cm_logout ();
+		lg_release (gulm_cm.hookup);
+		gulm_cm.hookup = NULL;
+		gulm_cm.GenerationID = 0;
+	}
+	up (&start_stop_lock);
+}
+
+/*****************************************************************************/
+/**
+ * send_drop_exp - 
+ * @fs: 
+ * @name: 
+ * 
+ * 
+ * Returns: int
+ */
+int send_drop_exp (gulm_fs_t * fs, char *name)
+{
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		log_err("drop_exp: failed to get needed memory. skipping.\n");
+		return -ENOMEM;
+	}
+
+	item->keylen = 3 + strlen(fs->fs_name);
+	item->key = kmalloc(item->keylen, GFP_KERNEL);
+	if (item->key == NULL) {
+		glq_recycle_req(item);
+		log_err("drop_exp: failed to get needed memory. skipping.\n");
+		return -ENOMEM;
+	}
+	item->keylen = pack_drop_mask(item->key, item->keylen, fs->fs_name);
+
+	/* lvb is name for drops. */
+	if (name != NULL) {
+		item->lvblen = strlen(name) +1;
+		item->lvb = kmalloc(item->lvblen, GFP_KERNEL);
+		if (item->lvb == NULL) {
+			glq_recycle_req(item); /* frees key for us */
+			log_err("drop_exp: failed to get needed memory. skipping.\n");
+			return -ENOMEM;
+		}
+		memcpy(item->lvb, name, item->lvblen);
+	} else {
+		item->lvb = NULL;
+		item->lvblen = 0;
+	}
+
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_drop;
+	item->state = 0;
+	item->flags = 0;
+	item->error = 0;
+	item->finish = NULL;
+
+	glq_queue (item);
+
+	return 0;
+}
+/**
+ * expire_my_locks - 
+ * @fs: 
+ * 
+ * 
+ * Returns: int
+ */
+int expire_my_locks (gulm_fs_t * fs)
+{
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		log_err("drop_exp: failed to get needed memory. skipping.\n");
+		return -ENOMEM;
+	}
+
+	item->keylen = 3 + strlen(fs->fs_name);
+	item->key = kmalloc(item->keylen, GFP_KERNEL);
+	if (item->key == NULL) {
+		glq_recycle_req(item);
+		log_err("drop_exp: failed to get needed memory. skipping.\n");
+		return -ENOMEM;
+	}
+	item->keylen = pack_drop_mask(item->key, item->keylen, fs->fs_name);
+
+	/* lvb is name for drops. */
+	item->lvblen = strlen(gulm_cm.myName) +1;
+	item->lvb = kmalloc(item->lvblen, GFP_KERNEL);
+	if (item->lvb == NULL) {
+		glq_recycle_req(item); /* frees key for us */
+		log_err("drop_exp: failed to get needed memory. skipping.\n");
+		return -ENOMEM;
+	}
+	memcpy(item->lvb, gulm_cm.myName, item->lvblen);
+
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_expire;
+	item->state = 0;
+	item->flags = 0;
+	item->error = 0;
+	item->finish = NULL;
+
+	glq_queue (item);
+
+	return 0;
+}
+/*****************************************************************************/
+
+/**
+ * gulm_check_replays - 
+ * @misc: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_check_replays(void *misc)
+{
+	gulm_fs_t *fs = (gulm_fs_t*)misc;
+	qu_function_call (&fs->cq, cast_check_for_stale_expires, fs);
+}
+
+/**
+ * gulm_mount
+ * @table_name: clusterID:FS_Name
+ * @host_data:
+ * @cb: GFS callback function
+ * @fsdata: opaque GFS handle
+ * @lockstruct: the structure of crap to fill in
+ *
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+gulm_mount (char *table_name, char *host_data,
+	    lm_callback_t cb, lm_fsdata_t * fsdata,
+	    unsigned int min_lvb_size, struct lm_lockstruct *lockstruct)
+{
+	gulm_fs_t *gulm;
+	char *work=NULL, *tbln;
+	int first;
+	int error = -1;
+	struct list_head *lltmp;
+
+	work = kmalloc(256, GFP_KERNEL);
+	if(work == NULL ) {
+		log_err("Out of Memory.\n");
+		error = -ENOMEM;
+		goto fail;
+	}
+	strncpy (work, table_name, 256);
+
+	tbln = strstr (work, ":");
+	if (tbln == NULL) {
+		log_err
+		    ("Malformed table name. Couldn't find separator ':' between "
+		     "clusterID and lockspace name.\n");
+		error = -1;
+		goto fail;
+	}
+	*tbln++ = '\0';
+
+	/* make sure that the cluster name exists. */
+	if (strlen (work) <= 0) {
+		log_err ("Cluster name \"%s\" is too short.\n", work);
+		error = -EPROTO;
+		goto fail;
+	}
+	if (strlen (work) > 16) {
+		log_err ("Cluster name \"%s\" is too long.\n", work);
+		error = -EPROTO;
+		goto fail;
+	}
+
+	/* the second one is an artifact of the way I use the name.  
+	 * A better fix to this will happen when I actually get dynamic key
+	 * lengths working.
+	 */
+	if (strlen (tbln) > MIN (GIO_NAME_LEN, (GIO_KEY_SIZE - 15))) {
+		log_err
+		    ("Warning! lockspace name (%s) is longer than %d chars!\n",
+		     tbln, MIN (GIO_NAME_LEN, (GIO_KEY_SIZE - 15)));
+		error = -EPROTO;
+		goto fail;
+	}
+	if (strlen (tbln) <= 0) {
+		log_err ("Table name \"%s\" is too short.\n", tbln);
+		error = -EPROTO;
+		goto fail;
+	}
+
+	/*  Check to make sure this lock table isn't already being used  */
+	down (&filesystem_lck);
+	list_for_each (lltmp, &filesystems_list) {
+		gulm = list_entry (lltmp, gulm_fs_t, fs_list);
+		if (!strncmp (gulm->fs_name, tbln, GIO_NAME_LEN)) {
+			log_err ("\"%s\" is already in use\n", tbln);
+			error = -EEXIST;
+			up (&filesystem_lck);
+			goto fail;
+		}
+	}
+	up (&filesystem_lck);
+
+	/*  Set up our main structure  */
+
+	gulm = kmalloc (sizeof (gulm_fs_t), GFP_KERNEL);
+	if (!gulm) {
+		log_err ("out of memory\n");
+		error = -ENOMEM;
+		goto fail;
+	}
+	memset (gulm, 0, sizeof (gulm_fs_t));
+
+	INIT_LIST_HEAD (&gulm->fs_list);
+
+	strncpy (gulm->fs_name, tbln, GIO_NAME_LEN);
+	gulm->cb = cb;
+	gulm->fsdata = fsdata;
+	gulm->lvb_size = min_lvb_size;
+
+	if ((error = start_gulm_threads (work, host_data)) != 0) {
+		log_err ("Got a %d trying to start the threads.\n", error);
+		goto fail_free_gulm;
+	}
+
+	if ((error =
+	     start_callback_qu (&gulm->cq, gulm_cm.handler_threads)) < 0) {
+		log_err ("fsid=%s: Failed to start the callback handler.\n",
+			 gulm->fs_name);
+		goto fail_free_gulm;
+	}
+
+	/* the mount lock HAS to be the first thing done in the LTs for this fs. */
+	error = get_mount_lock (gulm, &first);
+	if (error != 0) {
+		log_err("fsid=%s: Error %d while trying to get the mount lock\n",
+		     gulm->fs_name, error);
+		goto fail_callback;
+	}
+
+	error = watch_sig(gulm, "CFR", 4, gulm_check_replays, gulm);
+	if( error != 0 ) {
+		log_err("fsid=%s: couldn't watch CFR because %d\n",
+				gulm->fs_name, error);
+		goto fail_mountlock;
+	}
+
+	jid_fs_init (gulm);
+	get_journalID (gulm);
+
+	/* things act a bit different until the first mounter is finished.
+	 */
+	if (first)
+		gulm->firstmounting = TRUE;
+
+	/*  Success  */
+	down (&filesystem_lck);
+	list_add (&gulm->fs_list, &filesystems_list);
+	filesystems_count++;
+	up (&filesystem_lck);
+
+	log_msg (lgm_JIDMap, "fsid=%s: We will be using jid %d\n",
+		 gulm->fs_name, gulm->fsJID);
+
+	lockstruct->ls_jid = gulm->fsJID;
+	lockstruct->ls_first = first;
+	lockstruct->ls_lvb_size = gulm->lvb_size;
+	lockstruct->ls_lockspace = gulm;
+	lockstruct->ls_ops = &gulm_ops;
+	lockstruct->ls_flags = 0;
+	log_msg (lgm_Network2, "Done: %s, async mode\n", table_name);
+
+	gulm_cm.starts = FALSE;
+	if(work != NULL ) kfree(work);
+	return 0;
+
+fail_mountlock:
+	drop_mount_lock (gulm);
+
+      fail_callback:
+	stop_callback_qu (&gulm->cq);
+
+      fail_free_gulm:
+	stop_gulm_threads ();
+	kfree (gulm);
+
+      fail:
+
+	if(work != NULL ) kfree(work);
+	gulm_cm.starts = FALSE;
+	log_msg (lgm_Always, "fsid=%s: Exiting gulm_mount with errors %d\n",
+		 table_name, error);
+	/* VFS does weird things with the error results, so before we try
+	 * to return a gulm error code, flip it to -1.
+	 */
+	if (error > 999 || error < -999 ) error = -1;
+	return error;
+}
+
+/**
+ * gulm_others_may_mount
+ * @lockspace: handle to specific lock space
+ *
+ * GFS calls this function if it was the first mounter after it's done
+ * checking all the journals.
+ *
+ */
+void
+gulm_others_may_mount (lm_lockspace_t * lockspace)
+{
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	int err = 0;
+
+	/* first send the drop all exp message.
+	 * */
+	err = send_drop_exp (fs, NULL);
+	if (err < 0)
+		log_err
+		    ("fsid=%s: Problems sending DropExp request to LTPX: %d\n",
+		     fs->fs_name, err);
+
+	/* then move the FirstMountLock to shared so others can mount. */
+	err = downgrade_mount_lock (fs);
+
+	if (err < 0) {
+		log_err ("fsid=%s: error sending Fs_FinMount_Req.(%d)\n",
+			 fs->fs_name, err);
+	}
+
+	/* first mounter is all done.  let the gulm_recovery_done function
+	 * behave as normal now.
+	 */
+	fs->firstmounting = FALSE;
+}
+
+/**
+ * gulm_umount
+ * @lockspace: handle to specific lock space
+ *
+ */
+void
+gulm_unmount (lm_lockspace_t * lockspace)
+{
+	gulm_fs_t *gulm_fs = (gulm_fs_t *) lockspace;
+
+	down (&filesystem_lck);
+	list_del (&gulm_fs->fs_list);
+	--filesystems_count;
+	up (&filesystem_lck);
+
+	/* close and release stuff */
+	watch_sig(gulm_fs, "CFR", 4, NULL, NULL);
+	drop_mount_lock (gulm_fs);
+	put_journalID (gulm_fs, FALSE);
+	jid_fs_release (gulm_fs);
+
+	stop_callback_qu (&gulm_fs->cq);
+
+	kfree (gulm_fs);
+
+	stop_gulm_threads ();
+
+}
+
+/**
+ * gulm_withdraw
+ * @lockspace: handle to specific lock space
+ *
+ */
+void
+gulm_withdraw(lm_lockspace_t * lockspace)
+{
+	gulm_fs_t *gulm_fs = (gulm_fs_t *) lockspace;
+	down (&filesystem_lck);
+	list_del (&gulm_fs->fs_list);
+	--filesystems_count;
+	up (&filesystem_lck);
+
+	/* close and release stuff */
+	drop_mount_lock (gulm_fs);
+	/* leave this around for others to clean up.
+	 * marking myself as being replayed right away so in bad cases,
+	 * atleast check_for_stale will find us.
+	 * */
+	put_journalID (gulm_fs, TRUE);
+	jid_fs_release (gulm_fs);
+
+	stop_callback_qu (&gulm_fs->cq);
+
+	expire_my_locks (gulm_fs);
+	tap_sig(gulm_fs, "CFR", 4);
+
+	/* need to let things run through the queues.
+	 * Only really an issue if you happen to be the only gfs/gulm fs
+	 * mounted.
+	 * */
+	current->state = TASK_INTERRUPTIBLE;
+	schedule_timeout( 2 * HZ);
+
+	kfree (gulm_fs);
+
+	stop_gulm_threads ();
+}
+
+/**
+ * gulm_recovery_done - 
+ * @lockspace: 
+ * @jid: 
+ * 
+ * Returns: void
+ */
+void
+gulm_recovery_done (lm_lockspace_t * lockspace, unsigned int jid,
+		    unsigned int message)
+{
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	int err;
+	uint8_t *name=NULL;
+
+	if (message != LM_RD_SUCCESS) {
+		/* Need to start thinking about how I want to use this... */
+		goto exit;
+	}
+
+	name = kmalloc(64, GFP_KERNEL);
+	if(name == NULL) {
+		log_err("out of memory.\n");
+		goto exit;
+	}
+
+	if (jid == fs->fsJID) {	/* this may be drifting crud through. */
+		/* hey! its me! */
+		strncpy (name, gulm_cm.myName, 64);
+	} else if (lookup_name_by_jid (fs, jid, name) != 0) {
+		log_msg (lgm_JIDMap,
+			 "fsid=%s: Could not find a client for jid %d\n",
+			 fs->fs_name, jid);
+		goto exit;
+	}
+	if (strlen (name) == 0) {
+		log_msg (lgm_JIDMap, "fsid=%s: No one mapped to jid %d\n",
+			 fs->fs_name, jid);
+		goto exit;
+	}
+	log_msg (lgm_JIDMap, "fsid=%s: Found %s for jid %d\n",
+		 fs->fs_name, name, jid);
+
+	err = send_drop_exp (fs, name);
+
+	if (jid != fs->fsJID) {
+		/* rather dumb to do this to ourselves right after we mount... */
+		log_msg (lgm_JIDMap,
+			 "fsid=%s: Clearing JID %d for use by others\n",
+			 fs->fs_name, jid);
+		release_JID (fs, jid);
+	}
+
+	/* If someone died while replaying someoneelse's journal, there will be
+	 * stale expired jids.
+	 */
+	check_for_stale_expires (fs);
+
+exit:
+	if(name!=NULL) kfree(name);
+}
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_jid.c linux-patched/fs/gfs_locking/lock_gulm/gulm_jid.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_jid.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_jid.c	2005-01-12 17:20:30.292660585 -0600
@@ -0,0 +1,651 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "gulm_lock_queue.h"
+
+extern gulm_cm_t gulm_cm;
+
+/****************************************************************************/
+
+/* jid locks:
+ *
+ * Header lock: "JHeader" + \0\0\0 + fsname
+ *         lvb: <uint32> :number of JIDs
+ * Mappinglock: "JM" + <uint32> + \0\0\0\0 + fsname
+ *         lvb: [012] + <node name>
+ *              0: unused
+ *              1: replaying journal
+ *              2: Mounted
+ * list lock  : "JL" + "listlock" + fsname
+ * Node Locks : "JN" + <nodename[8]> + fsname
+ *
+ */
+#define jid_header_lvb_size (8)
+
+/**
+ * jid_get_header_name - 
+ * @fs: <
+ * @key: <>
+ * @keylen: <> 
+ * 
+ * key is buffer to write to, keylen is size of buffer on input, and real
+ * length on output.
+ * 
+ * Returns: int
+ */
+int
+jid_get_header_name (uint8_t * fsname, uint8_t * key, uint16_t * keylen)
+{
+	int len;
+
+	len = pack_lock_key(key, *keylen, 'J', fsname, "Header", 6);
+	if( len <=0 ) return len;
+
+	*keylen = len;
+
+	return 0;
+}
+
+/**
+ * jid_get_lock_name - 
+ * @fs: <
+ * @jid: <
+ * @key: <>
+ * @keylen: <>
+ * 
+ * key is buffer to write to, keylen is size of buffer on input, and real
+ * length on output.
+ * 
+ * Returns: int
+ */
+int
+jid_get_lock_name (uint8_t * fsname, uint32_t jid, uint8_t * key,
+		   uint16_t * keylen)
+{
+	int len;
+	uint8_t temp[9];
+
+	temp[0] = 'M';
+	temp[1] = (jid >> 0) & 0xff;
+	temp[2] = (jid >> 8) & 0xff;
+	temp[3] = (jid >> 16) & 0xff;
+	temp[4] = (jid >> 24) & 0xff;
+	temp[5] = 0;
+	temp[6] = 0;
+	temp[7] = 0;
+	temp[8] = 0;
+
+	len = pack_lock_key(key, *keylen, 'J', fsname, temp, 9);
+	if( len <=0 ) return len;
+
+	*keylen = len;
+
+	return 0;
+}
+
+/**
+ * gulm_jid_finish - 
+ * @item: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_jid_finish (struct glck_req *item)
+{
+	struct completion *sleep = (struct completion *)item->misc;
+	complete (sleep);
+}
+
+/**
+ * jid_lvb_action - 
+ * @key: 
+ * @keylen: 
+ * @lvb: 
+ * @lvblen: 
+ * @action: 
+ * 
+ * 
+ * Returns: void
+ */
+void jid_lvb_action (uint8_t * key, uint16_t keylen, uint8_t * lvb,
+		uint16_t lvblen, uint8_t action)
+{
+	struct completion sleep;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return;
+	}
+
+	item->key = key;
+	item->keylen = keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_action;
+	item->state = action;
+	item->flags = 0;
+	item->error =  0;
+	item->lvb = lvb;
+	item->lvblen = lvblen;
+
+	init_completion (&sleep);
+
+	item->misc = &sleep;
+	item->finish = gulm_jid_finish;
+
+	glq_queue (item);
+	wait_for_completion (&sleep);
+}
+void
+jid_sync_lvb (uint8_t * key, uint16_t keylen, uint8_t * lvb, uint16_t lvblen)
+{
+	jid_lvb_action (key, keylen, lvb, lvblen, lg_lock_act_SyncLVB);
+}
+void
+jid_unhold_lvb (uint8_t * key, uint16_t keylen)
+{
+	jid_lvb_action (key, keylen, NULL, 0, lg_lock_act_UnHoldLVB);
+}
+void
+jid_hold_lvb (uint8_t * key, uint16_t keylen)
+{
+	jid_lvb_action (key, keylen, NULL, 0, lg_lock_act_HoldLVB);
+}
+
+
+/**
+ * jid_get_lock_state_inr - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @flags:
+ * @lvb: 
+ * @lvblen: 
+ * 
+ * 
+ */
+void
+jid_get_lock_state_inr (uint8_t * key, uint16_t keylen, uint8_t state,
+			uint32_t flags, uint8_t * lvb, uint16_t lvblen)
+{
+	struct completion sleep;
+	glckr_t *item;
+	GULM_ASSERT (keylen > 6,
+			printk("keylen: %d\n", keylen););
+
+	init_completion (&sleep);
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return;
+	}
+
+	item->key = key;
+	item->keylen = keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = state;
+	item->flags = flags;
+	item->error =  0;
+	item->lvb = lvb;
+	item->lvblen = lvblen;
+
+	item->misc = &sleep;
+	item->finish = gulm_jid_finish;
+
+	glq_queue (item);
+
+	wait_for_completion (&sleep);
+}
+
+/**
+ * jid_get_lock_state_lvb - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @lvb: 
+ * @lvblen: 
+ * 
+ * 
+ */
+void
+jid_get_lock_state_lvb (uint8_t * key, uint16_t keylen, uint8_t state,
+			uint8_t * lvb, uint16_t lvblen)
+{
+	jid_get_lock_state_inr (key, keylen, state, 0, lvb, lvblen);
+}
+/**
+ * jid_get_lock_state - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * 
+ * 
+ */
+void
+jid_get_lock_state (uint8_t * key, uint16_t keylen, uint8_t state)
+{
+	jid_get_lock_state_inr (key, keylen, state, 0, NULL, 0);
+}
+
+/****************************************************************************/
+
+/**
+ * jid_rehold_lvbs - 
+ * @fs: 
+ * 
+ * 
+ */
+void
+jid_rehold_lvbs (gulm_fs_t * fs)
+{
+	int i;
+	uint32_t oldjcnt;
+	uint8_t key[GIO_KEY_SIZE], lvb[jid_header_lvb_size];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	oldjcnt = fs->JIDcount;
+
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_get_lock_state_lvb (key, keylen, lg_lock_state_Shared, lvb,
+				jid_header_lvb_size);
+	fs->JIDcount = (uint32_t) (lvb[0]) << 0;
+	fs->JIDcount |= (uint32_t) (lvb[1]) << 8;
+	fs->JIDcount |= (uint32_t) (lvb[2]) << 16;
+	fs->JIDcount |= (uint32_t) (lvb[3]) << 24;
+
+	if( fs->JIDcount > oldjcnt ) {
+		for (i = oldjcnt; i < fs->JIDcount; i++) {
+			keylen = sizeof (key);
+			jid_get_lock_name (fs->fs_name, i, key, &keylen);
+			jid_hold_lvb (key, keylen);
+		}
+	}
+
+}
+
+void
+jid_grow_space (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[jid_header_lvb_size];
+	uint16_t keylen = GIO_KEY_SIZE;
+	uint32_t jidc;
+
+	keylen = sizeof (key);
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	down (&fs->headerlock);
+	jid_get_lock_state_lvb (key, keylen, lg_lock_state_Exclusive, lvb,
+				jid_header_lvb_size);
+	jidc = (uint32_t) (lvb[0]) << 0;
+	jidc |= (uint32_t) (lvb[1]) << 8;
+	jidc |= (uint32_t) (lvb[2]) << 16;
+	jidc |= (uint32_t) (lvb[3]) << 24;
+	jidc += 1;
+	lvb[3] = (jidc >> 24) & 0xff;
+	lvb[2] = (jidc >> 16) & 0xff;
+	lvb[1] = (jidc >> 8) & 0xff;
+	lvb[0] = (jidc >> 0) & 0xff;
+	jid_sync_lvb (key, keylen, lvb, jid_header_lvb_size);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+	/* do an unlock here, so that when rehold grabs it shared, there is no
+	 * lvb writing. yeah, bit icky.  fix some other day.
+	 */
+
+	jid_rehold_lvbs (fs);
+	up (&fs->headerlock);
+}
+
+/**
+ * lookup_name_by_jid - 
+ * @fs: 
+ * @jid: 
+ * @name: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lookup_name_by_jid (gulm_fs_t * fs, uint32_t jid, uint8_t * name)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+	int err = 0;
+
+	if (jid >= fs->JIDcount) {
+		err = -1;
+		goto exit;
+	}
+
+	jid_get_lock_name (fs->fs_name, jid, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+				lg_lock_flag_IgnoreExp, lvb, 64);
+
+	if (lvb[0] != 0) {
+		memcpy (name, &lvb[1], strlen (&lvb[1]) + 1);
+	} else {
+		err = -1;
+	}
+
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+      exit:
+	return err;
+}
+
+/**
+ * Release_JID - 
+ * @fs: 
+ * @jid: 
+ * 
+ * This is called when a node replays someone else's journal.
+ * 
+ */
+void
+release_JID (gulm_fs_t * fs, uint32_t jid)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	/* there is no such, so this becomes a nop. */
+	if (jid >= fs->JIDcount)
+		return;
+
+	jid_get_lock_name (fs->fs_name, jid, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+				lg_lock_flag_IgnoreExp, lvb, 64);
+	if (lvb[0] == 1 ) {
+		/* if byte0 is 2, then that node is alive.  They're waiting
+		 * for us to finish, but once we're done, it would be mean
+		 * to mark their jid as free.  So we leave the byte alone.
+		 *
+		 * Actually, If the byte isn't 1 (which means we are
+		 * replaying the journal) don't change it.
+		 *
+		 * Remind: 0 = free, 1 = replaying, 2 = owned.
+		 */
+		lvb[0] = 0;
+		jid_sync_lvb (key, keylen, lvb, strlen (&lvb[1]) + 2);
+	}
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+}
+
+/**
+ * put_journalID - 
+ * @fs: 
+ * 
+ * This is called when this node unmounts or withdraws.
+ * 
+ */
+void
+put_journalID (gulm_fs_t * fs, int leavebehind)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	/* there is no such, so this becomes a nop. */
+	if (fs->fsJID >= fs->JIDcount)
+		return;
+
+	jid_get_lock_name (fs->fs_name, fs->fsJID, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+				lg_lock_flag_IgnoreExp, lvb, 64);
+	if(leavebehind)
+		lvb[0] = 1;
+	else
+		lvb[0] = 0;
+	jid_sync_lvb (key, keylen, lvb, strlen (&lvb[1]) + 2);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+}
+
+/**
+ * get_journalID - 
+ * @fs: 
+ * @jid: 
+ * 
+ * grab EXL on names until we find one we want. (or have all.)
+ * grab that one.
+ * Unlock everything we got.
+ * 
+ * Returns: int
+ */
+void
+get_journalID (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+	int i, first_clear = -1, lockedto;
+
+retry:
+	/* find an empty space, or ourselves again */
+	for (i = 0, lockedto = 0; i < fs->JIDcount; i++, lockedto++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		if (first_clear == -1 && lvb[0] == 0 ) {
+			first_clear = i;
+		} else if (strcmp (gulm_cm.myName, &lvb[1]) == 0) {
+			first_clear = i;
+			break;
+		}
+	}
+	if (first_clear >= 0) {
+		/* we should be hold all jid mapping locks up to this one
+		 * (and maybe beyond) EXL, so just lvb sync to the one we
+		 * want.
+		 */
+		lvb[0] = 2;
+		memcpy (&lvb[1], gulm_cm.myName, strlen (gulm_cm.myName) + 1);
+
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, first_clear, key, &keylen);
+		jid_sync_lvb (key, keylen, lvb, strlen (gulm_cm.myName) + 2);
+
+		fs->fsJID = first_clear;
+	}
+
+	/* unlock them so others can find */
+	for (; lockedto >= 0; lockedto--) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, lockedto, key, &keylen);
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+	}
+
+	if (first_clear < 0) {
+		jid_grow_space (fs);
+		goto retry;
+	}
+}
+
+/**
+ * find_jid_by_name_and_mark_replay - 
+ * @fs: 
+ * @name: 
+ * @jid: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+find_jid_by_name_and_mark_replay (gulm_fs_t * fs, uint8_t * name,
+				  uint32_t * jid)
+{
+	uint32_t i, found = -1;
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	down (&fs->headerlock); /*???*/
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		if (strcmp (name, &lvb[1]) == 0) {
+			*jid = i;
+			found = 0;
+			lvb[0] = 1;
+			jid_sync_lvb (key, keylen, lvb, strlen (&lvb[1]) + 2);
+			jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+			break;
+		}
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	}
+	up (&fs->headerlock);
+
+	return found;
+}
+
+/**
+ * Check_for_replays - 
+ * @fs: 
+ * 
+ * 
+ * Returns: int
+ */
+void
+check_for_stale_expires (gulm_fs_t * fs)
+{
+	uint32_t i;
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+	unsigned int ujid;
+
+	down (&fs->headerlock); /*???*/
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+		if (lvb[0] == 1) {
+			log_msg (lgm_JIDMap,
+				 "fsid=%s: stale JID %d found\n",
+				 fs->fs_name, i);
+			ujid = i;
+			fs->cb (fs->fsdata, LM_CB_NEED_RECOVERY, &ujid);
+		}
+	}
+	up (&fs->headerlock);
+}
+
+
+/**
+ * jid_fs_init - 
+ * @fs: 
+ * 
+ */
+void
+jid_fs_init (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	fs->JIDcount = 0;
+
+	init_MUTEX (&fs->headerlock);
+
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_hold_lvb (key, keylen);
+	jid_rehold_lvbs (fs);
+}
+
+/**
+ * jid_fs_release - 
+ * @fs: 
+ * 
+ */
+void
+jid_fs_release (gulm_fs_t * fs)
+{
+	uint32_t i;
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_unhold_lvb (key, keylen);
+	}
+	keylen = GIO_KEY_SIZE;
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_unhold_lvb (key, keylen);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+}
+
+/**
+ * jid_unlock_callback - 
+ * @d: 
+ * 
+ * *MUST* be called from a Handler thread.
+ * 
+ * Returns: int
+ */
+void
+jid_unlock_callback (void *d)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	gulm_fs_t *fs = (gulm_fs_t *) d;
+	jid_get_header_name (fs->fs_name, key, &keylen);
+
+	down (&fs->headerlock);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	jid_rehold_lvbs (fs);
+	up (&fs->headerlock);
+}
+
+/**
+ * jid_header_lock_drop - 
+ * @key: 
+ * @keylen: 
+ * 
+ * Returns: void
+ */
+void
+jid_header_lock_drop (uint8_t * key, uint16_t keylen)
+{
+	gulm_fs_t *fs;
+	uint8_t *fsname;
+	uint8_t len;
+	uint8_t ktype, jtype;
+	ktype = key[0];
+	len = key[1];
+	fsname = &key[2];
+	jtype = key[4 + len];
+
+	/* make sure this is the header lock.... */
+	if (ktype == 'J' && jtype == 'H' &&
+			(fs = get_fs_by_name (fsname)) != NULL) {
+		qu_function_call (&fs->cq, jid_unlock_callback, fs);
+	}
+}
+
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_lock_queue.c linux-patched/fs/gfs_locking/lock_gulm/gulm_lock_queue.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_lock_queue.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_lock_queue.c	2005-01-12 17:20:30.292660585 -0600
@@ -0,0 +1,778 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/file.h>
+#include <linux/smp_lock.h>
+#include <linux/crc32.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "handler.h"
+
+#include "gulm_lock_queue.h"
+
+/* The Queues. */
+struct list_head glq_Free;
+spinlock_t glq_FreeLock;
+unsigned int glq_FreeCount;
+struct list_head glq_OutQueue;
+spinlock_t glq_OutLock;
+unsigned int glq_OutCount;
+#define ReplyMapBits (13)
+#define ReplyMapSize (1 << ReplyMapBits)
+#define ReplyMapMask (ReplyMapSize - 1)
+gulm_hb_t *glq_ReplyMap;
+
+/* The Threads. */
+struct task_struct *glq_recver_task = NULL;
+struct task_struct *glq_sender_task = NULL;
+struct completion glq_startedup;
+int glq_running;
+wait_queue_head_t glq_send_wchan;
+
+/* */
+extern gulm_cm_t gulm_cm;
+
+/* The code. */
+/**
+ * glq_init - 
+ * 
+ * Returns: int
+ */
+int glq_init(void)
+{
+	int i;
+
+	glq_running = FALSE;
+	glq_recver_task = NULL;
+	glq_sender_task = NULL;
+	init_waitqueue_head (&glq_send_wchan);
+	init_completion (&glq_startedup);
+
+	INIT_LIST_HEAD (&glq_Free);
+	spin_lock_init (&glq_FreeLock);
+	glq_FreeCount = 0;
+	INIT_LIST_HEAD (&glq_OutQueue);
+	spin_lock_init (&glq_OutLock);
+	glq_OutCount = 0;
+
+	glq_ReplyMap = vmalloc(sizeof(gulm_hb_t) * ReplyMapSize);
+	if( glq_ReplyMap == NULL ) {
+		return -ENOMEM;
+	}
+	for(i=0; i < ReplyMapSize; i++) {
+		INIT_LIST_HEAD (&glq_ReplyMap[i].bucket);
+		spin_lock_init (&glq_ReplyMap[i].lock);
+	}
+	/* ?Add some empty reqs to the Free list right now? */
+	return 0;
+}
+
+/**
+ * glq_release - 
+ *
+ * doesn't grab spins, because by the time this is called, there should be
+ * no other threads anywhere that could possibly be working on these lists.
+ * 
+ * Returns: void
+ */
+void glq_release(void)
+{
+	struct list_head *tmp, *lltmp;
+	glckr_t *item;
+	int i;
+
+	list_for_each_safe (tmp, lltmp, &glq_OutQueue) {
+		item = list_entry (tmp, glckr_t, list);
+		list_del (tmp);
+		if (item->key != NULL) kfree (item->key);
+		if (item->lvb != NULL) kfree (item->lvb);
+		kfree (item);
+	}
+	glq_FreeCount = 0;
+	list_for_each_safe (tmp, lltmp, &glq_Free) {
+		item = list_entry (tmp, glckr_t, list);
+		list_del (tmp);
+		if (item->key != NULL) kfree (item->key);
+		if (item->lvb != NULL) kfree (item->lvb);
+		kfree (item);
+	}
+	glq_OutCount = 0;
+	for(i=0; i < ReplyMapSize; i++) {
+		list_for_each_safe (tmp, lltmp, &glq_ReplyMap[i].bucket) {
+			item = list_entry (tmp, glckr_t, list);
+			list_del (tmp);
+			if (item->key != NULL) kfree (item->key);
+			if (item->lvb != NULL) kfree (item->lvb);
+			kfree (item);
+		}
+	}
+
+	vfree(glq_ReplyMap);
+}
+
+/**
+ * glq_get_new_req - 
+ *
+ * WARNING! For state and action requests, glq will not free the key or
+ * lvb pointers.  For drop and cancel glq WILL free the pointer when it is
+ * finished.
+ * 
+ * Returns: glckr_t
+ */
+glckr_t *glq_get_new_req(void)
+{
+	struct list_head *tmp;
+	glckr_t *item = NULL;
+
+	/* try to reclaim a recycled req first. */
+	spin_lock (&glq_FreeLock);
+	if (!list_empty (&glq_Free)) {
+		tmp = glq_Free.next;
+		list_del (tmp);
+		item = list_entry (tmp, glckr_t, list);
+		glq_FreeCount --;
+	}
+	spin_unlock (&glq_FreeLock);
+
+	/* nothing on Free list, make new. */
+	if (item == NULL) {
+		item = kmalloc(sizeof(glckr_t), GFP_KERNEL);
+		if (item == NULL) 
+			return NULL;
+		memset(item, 0, sizeof(glckr_t));
+	}
+
+	/* initialize.
+	 * reset list so its good.
+	 */
+	INIT_LIST_HEAD (&item->list);
+
+	return item;
+}
+
+/**
+ * glq_recycle_req - 
+ * @lckr_t: 
+ * 
+ * assumes that item is not on any lists.
+ * 
+ * Returns: void
+ */
+void glq_recycle_req(glckr_t *item)
+{
+	/* clean it up */
+	INIT_LIST_HEAD (&item->list);
+
+	if (item->type == glq_req_type_drop ||
+	    item->type == glq_req_type_cancel ||
+	    item->type == glq_req_type_expire) {
+		if (item->key != NULL) {
+			kfree(item->key);
+			item->key = NULL;
+		}
+		if (item->lvb != NULL) {
+			kfree(item->lvb);
+			item->lvb = NULL;
+		}
+	} else {
+		item->key = NULL;
+		item->lvb = NULL;
+	}
+	item->misc = NULL;
+	item->finish = NULL;
+
+	/* everything else is ignoreable. */
+
+	/* onto the Free list. unless too many. */
+	spin_lock (&glq_FreeLock);
+	if (glq_FreeCount > 20) { /* XXX icky hidden constant */
+		kfree (item);
+	}else{
+		list_add (&item->list, &glq_Free);
+		glq_FreeCount ++;
+	}
+	spin_unlock (&glq_FreeLock);
+}
+
+/**
+ * glq_calc_hash_key_long - 
+ * @key: 
+ * @keylen: 
+ * @subid: 
+ * @start: 
+ * @stop: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_calc_hash_key_long(uint8_t *key, uint16_t keylen,
+		uint64_t subid, uint64_t start, uint64_t stop)
+{
+	int ret = GULM_CRC_INIT;
+	ret = crc32 (ret, &keylen, sizeof(uint16_t));
+	ret = crc32 (ret, key, keylen);
+	ret = crc32 (ret, &subid, sizeof(uint64_t));
+	ret = crc32 (ret, &start, sizeof(uint64_t));
+	ret = crc32 (ret, &stop, sizeof(uint64_t));
+	ret &= ReplyMapMask;
+	return ret;
+}
+
+/**
+ * glq_calc_hash_key - 
+ * @item: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_calc_hash_key(glckr_t *item)
+{
+	return glq_calc_hash_key_long (item->key, item->keylen, item->subid,
+			item->start, item->stop);
+}
+
+/**
+ * glq_queue - 
+ * @item: 
+ * 
+ * 
+ * Returns: void
+ */
+void glq_queue(glckr_t *item)
+{
+	spin_lock (&glq_OutLock);
+	list_add (&item->list, &glq_OutQueue);
+	glq_OutCount++;
+	spin_unlock (&glq_OutLock);
+	wake_up (&glq_send_wchan);
+}
+
+/**
+ * glq_cancel - 
+ * @item: 
+ * 
+ * You MUST call glq_get_new_req() and fill that with the info of the
+ * request you want to cancel.
+ * 
+ * Returns: void
+ */
+void glq_cancel(glckr_t *cancel)
+{
+	int found = FALSE;
+	struct list_head *tmp, *lltmp;
+	glckr_t *item = NULL;
+
+	spin_lock (&glq_OutLock);
+	list_for_each_safe (tmp, lltmp, &glq_OutQueue) {
+		item = list_entry (tmp, glckr_t, list);
+		if (item->subid == cancel->subid &&
+		    item->start == cancel->start &&
+		    item->stop  == cancel->stop &&
+		    item->keylen == cancel->keylen &&
+		    memcmp(item->key, cancel->key, cancel->keylen) ) {
+			/* found it. */
+			list_del (tmp);
+			found = TRUE;
+			break;
+		}
+	}
+	spin_unlock(&glq_OutLock);
+
+	if (!found) {
+		/* send cancel request to server. */
+		cancel->type = glq_req_type_cancel;
+		glq_queue (cancel);
+	}else{
+		/* finish it here */
+		item->error = lg_err_Canceled;
+		if (item->finish != NULL )
+			item->finish (item);
+		glq_recycle_req (item);
+		glq_recycle_req (cancel);
+	}
+}
+
+/**
+ * glq_send_queue_empty - 
+ * 
+ * Returns: int
+ */
+static int glq_send_queue_empty(void)
+{
+	int ret;
+	spin_lock (&glq_OutLock);
+	ret = list_empty (&glq_OutQueue);
+	spin_unlock (&glq_OutLock);
+	return ret;
+}
+
+/**
+ * glq_sender_thread - 
+ * @data: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_sender_thread(void *data)
+{
+	int err=0, bucket;
+	struct list_head *tmp;
+	glckr_t *item = NULL;
+	DECLARE_WAITQUEUE (__wait_chan, current);
+
+	daemonize ("gulm_glq_sender");
+	glq_sender_task = current;
+	complete (&glq_startedup);
+
+	while (glq_running) {
+		/* wait for item */
+		current->state = TASK_INTERRUPTIBLE; 
+		add_wait_queue (&glq_send_wchan, &__wait_chan);
+		if( glq_send_queue_empty () )
+			schedule ();
+		remove_wait_queue (&glq_send_wchan, &__wait_chan);
+		current->state = TASK_RUNNING;
+		if (!glq_running) break;
+
+		/* pull item off queue */
+		spin_lock (&glq_OutLock);
+		if (list_empty (&glq_OutQueue) ) {
+			spin_unlock (&glq_OutLock);
+			continue;
+		}
+		tmp = glq_OutQueue.prev;
+		list_del (tmp);
+		glq_OutCount--;
+		spin_unlock (&glq_OutLock);
+		item = list_entry (tmp, glckr_t, list);
+
+		/* send to local ltpx or die */
+		if (item->type == glq_req_type_state ) {
+			INIT_LIST_HEAD (&item->list);
+			bucket = glq_calc_hash_key(item);
+			spin_lock (&glq_ReplyMap[bucket].lock);
+			list_add (&item->list, &glq_ReplyMap[bucket].bucket);
+			spin_unlock (&glq_ReplyMap[bucket].lock);
+			err = lg_lock_state_req (gulm_cm.hookup, item->key,
+					item->keylen, item->subid, item->start,
+					item->stop, item->state, item->flags,
+					item->lvb, item->lvblen);
+		} else if (item->type == glq_req_type_action) {
+			INIT_LIST_HEAD (&item->list);
+			bucket = glq_calc_hash_key(item);
+			spin_lock (&glq_ReplyMap[bucket].lock);
+			list_add (&item->list, &glq_ReplyMap[bucket].bucket);
+			spin_unlock (&glq_ReplyMap[bucket].lock);
+			err = lg_lock_action_req (gulm_cm.hookup, item->key,
+					item->keylen, item->subid, item->state,
+					item->lvb, item->lvblen);
+		} else if (item->type == glq_req_type_query ) {
+			INIT_LIST_HEAD (&item->list);
+			bucket = glq_calc_hash_key(item);
+			spin_lock (&glq_ReplyMap[bucket].lock);
+			list_add (&item->list, &glq_ReplyMap[bucket].bucket);
+			spin_unlock (&glq_ReplyMap[bucket].lock);
+			err = lg_lock_query_req (gulm_cm.hookup, item->key,
+					item->keylen, item->subid, item->start,
+					item->stop, item->state);
+		} else if (item->type == glq_req_type_drop) {
+			err = lg_lock_drop_exp (gulm_cm.hookup, item->lvb,
+					item->key, item->keylen);
+			/* drop exp has no reply. */
+			glq_recycle_req (item);
+		} else if (item->type == glq_req_type_expire) {
+			err = lg_lock_expire (gulm_cm.hookup, item->lvb,
+					item->key, item->keylen);
+			/* expire has no reply. */
+			glq_recycle_req (item);
+		} else if (item->type == glq_req_type_cancel) {
+			err = lg_lock_cancel_req (gulm_cm.hookup, item->key,
+					item->keylen, item->subid);
+			/* cancels have no reply. */
+			glq_recycle_req (item);
+		} else {
+			/* bad type. */
+			log_err ("Unknown send type %d, tossing request.\n",
+					item->type);
+			glq_recycle_req (item);
+		}
+		if (err != 0 ) {
+			log_err ("gulm_glq_sender error %d\n", err);
+			glq_running = FALSE;
+			glq_recycle_req (item);
+			break;
+		}
+	}
+	complete (&glq_startedup);
+	return 0;
+}
+
+/**
+ * glq_login_reply - 
+ * @misc: 
+ * @err: 
+ * @which: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_login_reply (void *misc, uint32_t error, uint8_t which)
+{
+	if (error != 0) {
+		glq_running = FALSE;
+		log_err ("glq: Got error %d from login request.\n", error);
+	}
+	return error;
+}
+
+/**
+ * glq_logout_reply - 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_logout_reply (void *misc)
+{
+	glq_running = FALSE; /* if it isn't already. */
+	return 0;
+}
+
+/**
+ * glq_lock_state - 
+ * @misc: 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @flags: 
+ * @error: 
+ * @LVB: 
+ * @LVBlen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+glq_lock_state (void *misc, uint8_t * key, uint16_t keylen,
+		    uint64_t subid, uint64_t start, uint64_t stop,
+		    uint8_t state, uint32_t flags, uint32_t error,
+		    uint8_t * LVB, uint16_t LVBlen)
+{
+	int bucket, found = FALSE;
+	struct list_head *tmp;
+	glckr_t *item=NULL;
+
+	/* lookup and remove from ReplyMap */
+	bucket = glq_calc_hash_key_long(key, keylen, subid, start, stop);
+	spin_lock (&glq_ReplyMap[bucket].lock);
+	list_for_each(tmp, &glq_ReplyMap[bucket].bucket) {
+		item = list_entry (tmp, glckr_t, list);
+		if (item->subid == subid &&
+		    item->start == start &&
+		    item->stop  == stop &&
+		    item->keylen == keylen &&
+		    memcmp(item->key, key, keylen) == 0 ) {
+			/* found it. */
+			list_del (tmp);
+			found = TRUE;
+			break;
+		}
+	}
+	spin_unlock(&glq_ReplyMap[bucket].lock);
+
+	if( !found ) {
+		/* not found complaint */
+		return 0;
+	}
+
+	/* restuff results */
+	item->state = state;
+	item->flags = flags;
+	item->error = error;
+	if (item->lvb != NULL && LVB != NULL) {
+		item->lvblen = MIN(item->lvblen, LVBlen);
+		memcpy(item->lvb, LVB, item->lvblen);
+	}
+
+	/* call finish */
+	if (item->finish != NULL) item->finish (item);
+
+	/* put on Free */
+	glq_recycle_req(item);
+	return 0;
+}
+
+/**
+ * glq_lock_action - 
+ * @misc: 
+ * @key: 
+ * @keylen: 
+ * @action: 
+ * @error: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+glq_lock_action (void *misc, uint8_t * key, uint16_t keylen,
+		     uint64_t subid, uint8_t action, uint32_t error)
+{
+	int bucket, found = FALSE;
+	struct list_head *tmp;
+	glckr_t *item = NULL;
+
+	/* lookup and remove from ReplyMap */
+	bucket = glq_calc_hash_key_long(key, keylen, subid, 0, ~((uint64_t)0));
+	spin_lock (&glq_ReplyMap[bucket].lock);
+	list_for_each(tmp, &glq_ReplyMap[bucket].bucket) {
+		item = list_entry (tmp, glckr_t, list);
+		if (item->subid == subid &&
+		    item->start == 0 &&
+		    item->stop  == ~((uint64_t)0) &&
+		    item->keylen == keylen &&
+		    memcmp(item->key, key, keylen) == 0 ) {
+			/* found it. */
+			list_del (tmp);
+			found = TRUE;
+			break;
+		}
+	}
+	spin_unlock(&glq_ReplyMap[bucket].lock);
+
+	if( !found ) {
+		/* not found complaint */
+		return 0;
+	}
+
+	/* restuff results */
+	item->error = error;
+
+	/* call finish */
+	if (item->finish != NULL) item->finish (item);
+
+	/* put on Free */
+	glq_recycle_req(item);
+	return 0;
+}
+
+/**
+ * glq_lock_query -
+ * this is an ugly interface.....
+ * there is somehting that needs to be done here to clean things up.  I'm
+ * not sure what that is right now, and I need to have somehting working.
+ * So we're going with this for now.
+ *
+ */
+int 
+glq_lock_query (void *misc, uint8_t * key, uint16_t keylen,
+		   uint64_t subid, uint64_t start, uint64_t stop,
+		   uint8_t state, uint32_t error, uint8_t * cnode,
+		   uint64_t csubid, uint64_t cstart, uint64_t cstop,
+		   uint8_t cstate)
+{
+	int bucket, found = FALSE;
+	struct list_head *tmp;
+	glckr_t *item = NULL;
+
+	/* lookup and remove from ReplyMap */
+	bucket = glq_calc_hash_key_long(key, keylen, subid, start, stop);
+	spin_lock (&glq_ReplyMap[bucket].lock);
+	list_for_each(tmp, &glq_ReplyMap[bucket].bucket) {
+		item = list_entry (tmp, glckr_t, list);
+		if (item->subid == subid &&
+		    item->start == start &&
+		    item->stop  == stop &&
+		    item->keylen == keylen &&
+		    memcmp(item->key, key, keylen) == 0 ) {
+			/* found it. */
+			list_del (tmp);
+			found = TRUE;
+			break;
+		}
+	}
+	spin_unlock(&glq_ReplyMap[bucket].lock);
+
+	if( !found ) {
+		/* not found complaint */
+		return 0;
+	}
+
+	/* restuff results */
+	item->error = error;
+	item->subid = csubid;
+	item->start = cstart;
+	item->stop = cstop;
+	item->state = cstate;
+
+	/* call finish */
+	if (item->finish != NULL) item->finish (item);
+
+	/* put on Free */
+	glq_recycle_req(item);
+	return 0;
+}
+
+/**
+ * glq_drop_lock_req - 
+ * @misc: 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+glq_drop_lock_req (void *misc, uint8_t * key, uint16_t keylen,
+		       uint64_t subid, uint8_t state)
+{
+	do_drop_lock_req (key, keylen, state);
+	jid_header_lock_drop (key, keylen);
+	sig_watcher_lock_drop (key, keylen);
+	return 0;
+}
+
+/**
+ * glq_drop_all - 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_drop_all (void *misc)
+{
+	passup_droplocks ();
+	return 0;
+}
+
+/**
+ * glq_error - 
+ * @misc: 
+ * @error: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_error (void *misc, uint32_t error)
+{
+	log_err ("glq: weird last gasp error %d\n", error);
+	return error;
+}
+
+static lg_lockspace_callbacks_t glq_lock_ops = {
+      login_reply:glq_login_reply,
+      logout_reply:glq_logout_reply,
+      lock_state:glq_lock_state,
+      lock_action:glq_lock_action,
+      lock_query:glq_lock_query,
+      drop_lock_req:glq_drop_lock_req,
+      drop_all:glq_drop_all,
+      error:glq_error
+};
+/**
+ * glq_recving_thread - 
+ * @data: 
+ * 
+ * 
+ * Returns: int
+ */
+int glq_recving_thread(void *data)
+{
+	int err;
+	daemonize ("gulm_glq_recver");
+	glq_recver_task = current;
+	complete (&glq_startedup);
+
+	while (glq_running) {
+		err = lg_lock_handle_messages (gulm_cm.hookup, &glq_lock_ops, NULL);
+		if (err != 0) {
+			log_err ("gulm_glq_recver error %d\n", err);
+			glq_running = FALSE;
+			wake_up (&glq_send_wchan);
+			break;
+		}
+	}
+	complete (&glq_startedup);
+	return 0;
+}
+
+/**
+ * glq_shutdown - 
+ * 
+ * Returns: void
+ */
+void glq_shutdown(void)
+{
+	if (glq_running) glq_running = FALSE;
+	if (glq_sender_task != NULL) {
+		wake_up (&glq_send_wchan);
+		wait_for_completion (&glq_startedup);
+		glq_sender_task = NULL;
+	}
+	if (glq_recver_task != NULL) {
+		lg_lock_logout (gulm_cm.hookup);
+		wait_for_completion (&glq_startedup);
+		glq_recver_task = NULL;
+	}
+}
+
+/**
+ * glq_startup - 
+ * 
+ * Returns: int
+ */
+int glq_startup(void)
+{
+	int err;
+
+	if (glq_running) return 0;
+
+	err = lg_lock_login (gulm_cm.hookup, "GFS ");
+	if (err != 0) {
+		log_err ("Failed to send lock login. %d\n", err);
+		return -err;
+	}
+
+	glq_running = TRUE;
+	if( glq_recver_task == NULL ) {
+		err = kernel_thread (glq_recving_thread, NULL, 0);
+		if( err < 0 ) {
+			log_err ("Failed to start glq_recving_thread %d\n",
+					err);
+			glq_shutdown();
+			return err;
+		}
+		wait_for_completion (&glq_startedup);
+	}
+
+	if (glq_sender_task == NULL) {
+		err = kernel_thread (glq_sender_thread, NULL, 0);
+		if( err < 0 ) {
+			log_err ("Failed to start glq_sender_thread %d\n",
+					err);
+			glq_shutdown();
+			return err;
+		}
+		wait_for_completion (&glq_startedup);
+	}
+	return 0;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_lock_queue.h linux-patched/fs/gfs_locking/lock_gulm/gulm_lock_queue.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_lock_queue.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_lock_queue.h	2005-01-12 17:20:30.293660360 -0600
@@ -0,0 +1,80 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+
+/* 
+ * So what if we change this to a request chain like I've got in the
+ * servers.  There are three lists. Free, Send, Reply.  Where the Reply
+ * list is actually more of a hash.
+ *
+ * Activity goes:
+ * - Grab struct from Free, malloc if needed.
+ * - Stuff, stick on Send.
+ * - Send, sends, then sticks on Reply.
+ * - When handle_messages gets a reply, it looks up on Reply and handles
+ *   from there.
+ *
+ * If Reply is a hash, it must be keyed on all important parts!
+ * (keyname, subid, start, stop)
+ */
+#ifndef __gulm_lockqueue_h__
+#define __gulm_lockqueue_h__
+#define glq_req_type_state  (1)
+#define glq_req_type_action (2)
+#define glq_req_type_drop   (3)
+#define glq_req_type_cancel (4)
+#define glq_req_type_query  (5)
+#define glq_req_type_expire (6)
+typedef struct glck_req {
+	struct list_head list;
+
+	/* these five for the key for hash-map look ups.
+	* Any part of any of these can change and thus be a unique request.
+	* (this struct is only put into a hash map to match replies.)
+	*/
+	uint8_t *key;
+	uint16_t keylen;
+	uint64_t subid;
+	uint64_t start;
+	uint64_t stop;
+
+	/* other info about this request. */
+	uint8_t type;
+	uint8_t state;  /* also action */ /* changes on reply (anyflag) */
+	uint32_t flags; /* changes on reply */
+	uint8_t *lvb; /* changes on reply */
+	uint16_t lvblen;
+	uint32_t error;  /* changes on reply */
+
+	/* when we get a reply, do this
+	* this glck_req will not be on any list when finish is called.  Upon
+	* the return of finish, it will be placed onto the Free list.
+	*/
+	void *misc;
+	void (*finish)(struct glck_req *glck);
+
+} glckr_t;
+
+/* prototypes */
+int glq_init(void);
+int glq_startup(void);
+void glq_shutdown(void);
+void glq_release(void);
+glckr_t *glq_get_new_req(void);
+void glq_recycle_req(glckr_t *);
+void glq_queue(glckr_t *);
+void glq_cancel(glckr_t *);
+
+
+#endif /*__gulm_lockqueue_h__*/
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h linux-patched/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h	2005-01-12 17:20:30.293660360 -0600
@@ -0,0 +1,40 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __gulm_log_msg_bits_h__
+#define __gulm_log_msg_bits_h__
+/* log_msg bit flags
+ * These got thier own file so I can easily include them in both user and
+ * kernel space.
+ * */
+#define lgm_Always      (0x00000000)	/*Print Message no matter what */
+#define lgm_Network     (0x00000001)
+#define lgm_Network2    (0x00000002)
+#define lgm_Stomith     (0x00000004)
+#define lgm_Heartbeat   (0x00000008)
+#define lgm_locking     (0x00000010)
+#define lgm_FuncDebug   (0x00000020)
+#define lgm_Forking     (0x00000040)
+#define lgm_JIDMap      (0x00000080)
+#define lgm_Subscribers (0x00000100)
+#define lgm_LockUpdates (0x00000200)
+#define lgm_LoginLoops  (0x00000400)
+#define lgm_Network3    (0x00000800)
+#define lgm_JIDUpdates  (0x00001000)
+#define lgm_ServerState (0x00002000)
+
+#define lgm_ReallyAll   (0xffffffff)
+
+#define lgm_BitFieldSize (32)
+
+#endif /*__gulm_log_msg_bits_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_lt.c linux-patched/fs/gfs_locking/lock_gulm/gulm_lt.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_lt.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_lt.c	2005-01-12 17:20:30.293660360 -0600
@@ -0,0 +1,988 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/file.h>
+#include <linux/crc32.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "handler.h"
+#include "gulm_lock_queue.h"
+#include "utils_tostr.h"
+
+#define gulm_gfs_lmBits (13)
+#define gulm_gfs_lmSize (1 << gulm_gfs_lmBits)
+#define gulm_gfs_lmMask (gulm_gfs_lmSize - 1)
+
+extern gulm_cm_t gulm_cm;
+
+/****************************************************************************/
+/* A bunch of prints that hopefully contain more information that is also
+ * useful
+ *
+ * these are a mess.
+ */
+
+/**
+ * lck_key_to_hex - 
+ * @key: 
+ * @len: 
+ * @workspace: <> place to put string. !! better be 2x len !!
+ * 
+ * 
+ * Returns: char
+ */
+static char *
+lck_key_to_hex (uint8_t * key, uint16_t len, char *workspace)
+{
+	int i;
+	for (i = 0; i < len; i++)
+		sprintf (&workspace[i * 2], "%02x", (key[i] & 0xff));
+	return workspace;
+}
+
+#if 0
+static void __inline__
+db_lck_entered (gulm_lock_t * lck)
+{
+	char bb[GIO_KEY_SIZE * 2 + 3];
+	lck_key_to_hex (lck->key, lck->keylen, bb);
+	printk ("Started  lock 0x%s cur:%#x req:%#x flags:%#x\n", bb,
+		lck->cur_state, lck->req_state, lck->flags);
+}
+static void __inline__
+db_lck_exited (gulm_lock_t * lck)
+{
+	char bb[GIO_KEY_SIZE * 2 + 3];
+	lck_key_to_hex (lck->key, lck->keylen, bb);
+	printk ("Finished lock 0x%s result:%#x\n", bb, lck->result);
+}
+#endif
+
+static void __inline__
+dump_gulm_lock_t (gulm_lock_t * lck)
+{
+	char bb[GIO_KEY_SIZE * 2 + 3];
+
+	lck_key_to_hex (lck->key, lck->keylen, bb);
+	log_msg (lgm_Always, " key = 0x%s\n", bb);
+	log_msg (lgm_Always, " cur_state = %d\n", lck->cur_state);
+}
+
+/* DEBUG_BY_LOCK is gone.  I may later add something back if needed.
+ *
+ * I love the idea of being able to log only certain locks, I just cannot
+ * think of an easy way to do it.  The best I can come up with is some
+ * pattern (or set of) that are used to decide which locks get logged.  But
+ * that could be expensive if the pattern is checked everytime, and won't
+ * behave as expected if only applied in get_lock.
+ * */
+
+/* The old log functions.
+ * These need their own sort of clean up someday as well.
+ * */
+#define log_msg_lk(key, keylen, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( key, keylen, bb); \
+      printk(PROTO_NAME ": On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#define log_err_lk(key, keylen, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( key, keylen, bb); \
+      printk(KERN_ERR PROTO_NAME ": ERROR On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#define log_msg_lck(lck, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( (lck)->key, (lck)->keylen, bb); \
+      printk(PROTO_NAME ": On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#define log_err_lck(lck, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( (lck)->key, (lck)->keylen, bb); \
+      printk(KERN_ERR PROTO_NAME ": ERROR On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#ifdef DEBUG_LVB
+static void __inline__
+print_lk_lvb (uint8_t * key, uint8_t * lvb, uint8_t st, uint8_t * dir)
+{
+	uint8_t bk[GIO_KEY_SIZE * 2 + 3];
+	uint8_t bl[GIO_LVB_SIZE * 2 + 3];
+	int i;
+	for (i = 0; i < GIO_KEY_SIZE; i++)
+		sprintf (&bk[(i * 2)], "%02x", (key[i]) & 0xff);
+	for (i = 0; i < GIO_LVB_SIZE; i++)
+		sprintf (&bl[(i * 2)], "%02x", (lvb[i]) & 0xff);
+	printk (PROTO_NAME ": On lock 0x%s with state %d\n\t%s LVB 0x%s\n",
+		bk, st, dir, bl);
+}
+
+#define lvb_log_msg_lk(k, fmt, args...) log_msg_lk( k , fmt , ## args )
+#define lvb_log_msg(fmt, args...) log_msg(lgm_Always , fmt , ## args )
+#else				/*DEBUG_LVB */
+#define print_lk_lvb(k,l,s,d)
+#define lvb_log_msg_lk(k, fmt, args...)
+#define lvb_log_msg(fmt, args...)
+#endif				/*DEBUG_LVB */
+
+/****************************************************************************/
+/**
+ * pack_lock_key - 
+ * @key: 
+ * @keylen: 
+ * 
+ * key is: <type><fsname len><fsname>\0<pk len><pk>\0
+ * <type> is: G J F N P
+ * <fsname len> is 0-256
+ * 
+ * Returns: int
+ */
+int pack_lock_key(uint8_t *key, uint16_t keylen, uint8_t type,
+		uint8_t *fsname, uint8_t *pk, uint8_t pklen)
+{
+	int fsnlen;
+	fsnlen = strlen(fsname);
+
+	if( keylen <= (fsnlen + pklen + 5) ) return -1;
+
+	memset (key, 0, keylen);
+
+	key[0] = type;
+
+	key[1] = fsnlen;
+	memcpy(&key[2], fsname, fsnlen);
+	key[2 + fsnlen] = 0;
+
+	key[3 + fsnlen] = pklen;
+
+	memcpy(&key[4 + fsnlen], pk, pklen);
+
+	key[4 + fsnlen + pklen] = 0;
+
+	return fsnlen + pklen + 5;
+}
+
+/**
+ * unpack_lock_key - 
+ * @key: <
+ * @keylen: <
+ * @type: >
+ * @fsname: >
+ * @fsnlen: >
+ * @pk: >
+ * @pklen: >
+ * 
+ * if you're gonna fiddle with bytes returned here, copy first!
+ *
+ * this is broken. do I even really need this?
+ * 
+ * Returns: int
+ */
+int unpack_lock_key(uint8_t *key, uint16_t keylen, uint8_t *type,
+		uint8_t **fsname, uint8_t *fsnlen,
+		uint8_t **pk, uint8_t *pklen)
+{
+	int fsnl, pkl;
+	if( type != NULL )
+		*type = key[0];
+
+	fsnl = key[1];
+	if( fsnlen != NULL && *fsname != NULL ) {
+		*fsnlen = key[1];
+		*fsname = &key[2];
+	}
+
+	/* 0 = key[2 + fsnl] */
+
+	pkl = key[3 + fsnl];
+	if( pklen != NULL && *pk != NULL ) {
+		*pklen = key[3 + fsnl];
+		*pk = &key[4 + fsnl];
+	}
+
+	/* 0 = key[4 + fsnl + *pklen] */
+
+	return fsnl + pkl + 5;
+}
+
+/**
+ * pack_drop_mask - 
+ * @mask: 
+ * @fsname: 
+ * 
+ * 
+ * Returns: int
+ */
+int pack_drop_mask(uint8_t *mask, uint16_t mlen, uint8_t *fsname)
+{
+	int fsnlen;
+	fsnlen = strlen(fsname);
+
+	memset (mask, 0, mlen);
+
+	mask[0] = 0xff;
+	mask[1] = fsnlen;
+	memcpy(&mask[2], fsname, fsnlen);
+	mask[2 + fsnlen] = 0;
+	/* rest should be 0xff */
+
+	return 3 + fsnlen;
+}
+
+/**
+ * gulm_lt_init - 
+ * 
+ * Returns: int
+ */
+int gulm_lt_init (void)
+{
+	int i;
+	gulm_cm.gfs_lockmap = vmalloc(sizeof(gulm_hb_t) * gulm_gfs_lmSize);
+	if (gulm_cm.gfs_lockmap == NULL)
+		return -ENOMEM;
+	for(i=0; i < gulm_gfs_lmSize; i++) {
+		spin_lock_init (&gulm_cm.gfs_lockmap[i].lock);
+		INIT_LIST_HEAD (&gulm_cm.gfs_lockmap[i].bucket);
+	}
+	return 0;
+}
+
+/**
+ * gulm_lt_release - 
+ */
+void gulm_lt_release(void)
+{
+	struct list_head *tmp, *lltmp;
+	gulm_lock_t *lck;
+	int i;
+
+	for(i=0; i < gulm_gfs_lmSize; i++) {
+		list_for_each_safe (tmp, lltmp, &gulm_cm.gfs_lockmap[i].bucket) {
+			lck = list_entry (tmp, gulm_lock_t, gl_list);
+			list_del (tmp);
+
+			if (lck->lvb != NULL) kfree (lck->lvb);
+
+			kfree(lck);
+		}
+	}
+
+	vfree (gulm_cm.gfs_lockmap);
+}
+
+/**
+ * find_and_mark_lock - 
+ * @key: 
+ * @keylen: 
+ * @lockp: 
+ * 
+ * looks for a lock struct of key.  If found, marks it.
+ * 
+ * Returns: TRUE or FALSE
+ */
+int
+find_and_mark_lock (uint8_t * key, uint8_t keylen, gulm_lock_t ** lockp)
+{
+	int found = FALSE;
+	uint32_t bkt;
+	gulm_lock_t *lck = NULL;
+	struct list_head *tmp;
+
+	/* now find the lock */
+	bkt = crc32 (GULM_CRC_INIT, key, keylen);
+	bkt &= gulm_gfs_lmMask;
+
+	spin_lock (&gulm_cm.gfs_lockmap[bkt].lock);
+	list_for_each (tmp, &gulm_cm.gfs_lockmap[bkt].bucket) {
+		lck = list_entry (tmp, gulm_lock_t, gl_list);
+		if (memcmp (lck->key, key, keylen) == 0) {
+			found = TRUE;
+			atomic_inc (&lck->count);
+			break;
+		}
+	}
+	spin_unlock (&gulm_cm.gfs_lockmap[bkt].lock);
+
+	if (found)
+		*lockp = lck;
+
+	return found;
+}
+
+/**
+ * mark_lock - 
+ * @lck: 
+ * 
+ * like above, but since we have the lock, don't search for it.
+ * 
+ * Returns: int
+ */
+void __inline__
+mark_lock (gulm_lock_t * lck)
+{
+	atomic_inc (&lck->count);
+}
+
+/**
+ * unmark_and_release_lock - 
+ * @lck: 
+ * 
+ * decrement the counter on a lock, freeing it if it reaches 0.
+ * (also removes it from the hash table)
+ * 
+ * TRUE if lock was freed.
+ *
+ * Returns: TRUE or FALSE
+ */
+int
+unmark_and_release_lock (gulm_lock_t * lck)
+{
+	uint32_t bkt;
+	int deld = FALSE;
+
+	bkt = crc32 (GULM_CRC_INIT, lck->key, lck->keylen);
+	bkt &= gulm_gfs_lmMask;
+
+	spin_lock (&gulm_cm.gfs_lockmap[bkt].lock);
+	if (atomic_dec_and_test (&lck->count)) {
+		list_del (&lck->gl_list);
+		deld = TRUE;
+	}
+	spin_unlock (&gulm_cm.gfs_lockmap[bkt].lock);
+	if (deld) {
+		if (lck->lvb != NULL) {
+			kfree (lck->lvb);
+		}
+		kfree (lck->key);
+		kfree (lck);
+	}
+
+	return deld;
+}
+
+/****************************************************************************/
+
+/**
+ * gulm_key_to_lm_lockname - 
+ * @key: 
+ * @lockname: 
+ * 
+ */
+void
+gulm_key_to_lm_lockname (uint8_t * key, struct lm_lockname *lockname)
+{
+	int pos;
+
+	pos = key[1] + 4;
+	/* pos now points to the first byte of the GFS lockname that was
+	 * embedded in the gulm lock key, skipping over the fs name.
+	 */
+
+	(*lockname).ln_type = key[pos];
+	(*lockname).ln_number  = (u64) (key[pos+1]) << 56;
+	(*lockname).ln_number |= (u64) (key[pos+2]) << 48;
+	(*lockname).ln_number |= (u64) (key[pos+3]) << 40;
+	(*lockname).ln_number |= (u64) (key[pos+4]) << 32;
+	(*lockname).ln_number |= (u64) (key[pos+5]) << 24;
+	(*lockname).ln_number |= (u64) (key[pos+6]) << 16;
+	(*lockname).ln_number |= (u64) (key[pos+7]) << 8;
+	(*lockname).ln_number |= (u64) (key[pos+8]) << 0;
+}
+
+/**
+ * do_drop_lock_req - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+do_drop_lock_req (uint8_t *key, uint16_t keylen, uint8_t state)
+{
+	gulm_lock_t *lck;
+	unsigned int type;
+	struct lm_lockname lockname;
+
+	if (!find_and_mark_lock (key, keylen, &lck)) {
+		return;
+	}
+
+	switch (state) {
+	case lg_lock_state_Unlock:
+		type = LM_CB_DROPLOCKS;
+		break;
+	case lg_lock_state_Exclusive:
+		type = LM_CB_NEED_E;
+		break;
+	case lg_lock_state_Shared:
+		type = LM_CB_NEED_S;
+		break;
+	case lg_lock_state_Deferred:
+		type = LM_CB_NEED_D;
+		break;
+	default:
+		type = LM_CB_DROPLOCKS;
+		break;
+	}
+	gulm_key_to_lm_lockname (key, &lockname);
+
+	qu_drop_req (&lck->fs->cq, lck->fs->cb, lck->fs->fsdata, type,
+		     lockname.ln_type, lockname.ln_number);
+
+	unmark_and_release_lock (lck);
+}
+
+/****************************************************************************/
+
+/**
+ * calc_lock_result - 
+ * @lck: 
+ * @state: 
+ * @error: 
+ * @flags: 
+ * 
+ * This calculates the correct result to return for gfs lock requests.
+ * 
+ * Returns: int
+ */
+int
+calc_lock_result (gulm_lock_t * lck,
+		  uint8_t state, uint32_t error, uint32_t flags)
+{
+	gulm_fs_t *fs = lck->fs;
+	int result = -69;
+
+	/* adjust result based on success status. */
+	switch (error) {
+	case lg_err_Ok:
+		/* set result to current lock state. */
+		switch (state) {
+		case lg_lock_state_Shared:
+			result = LM_ST_SHARED;
+			break;
+		case lg_lock_state_Deferred:
+			result = LM_ST_DEFERRED;
+			break;
+		case lg_lock_state_Exclusive:
+			result = LM_ST_EXCLUSIVE;
+			break;
+		case lg_lock_state_Unlock:
+			result = LM_ST_UNLOCKED;
+			break;
+		default:
+			GULM_ASSERT (0,
+				     dump_gulm_lock_t (lck);
+				     log_err_lck
+				     (lck, "fsid=%s: Anit no lock state %d.\n",
+						  fs->fs_name, state);
+			    );
+			break;
+		}
+
+		/* if no internal unlocks, it is cachable. */
+		if (result != LM_ST_UNLOCKED && (flags & lg_lock_flag_Cachable))
+			result |= LM_OUT_CACHEABLE;
+
+		break;
+	case lg_err_Canceled:
+		result = LM_OUT_CANCELED | lck->cur_state;
+		break;
+	case lg_err_TryFailed:
+		result = lck->cur_state;	/* if we didn't get it. */
+		break;
+	default:
+		result = -error;
+		break;
+	}
+
+	return result;
+}
+
+/****************************************************************************/
+
+/**
+ * gulm_get_lock - 
+ * @lockspace: 
+ * @name: 
+ * @lockp:
+ * 
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+gulm_get_lock (lm_lockspace_t * lockspace, struct lm_lockname *name,
+	       lm_lock_t ** lockp)
+{
+	int err=0, len, bkt;
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	uint8_t key[GIO_KEY_SIZE];
+	uint8_t temp[9];
+	gulm_lock_t *lck=NULL;
+
+	temp[0] = name->ln_type & 0xff;
+	temp[1] = (name->ln_number >> 56) & 0xff;
+	temp[2] = (name->ln_number >> 48) & 0xff;
+	temp[3] = (name->ln_number >> 40) & 0xff;
+	temp[4] = (name->ln_number >> 32) & 0xff;
+	temp[5] = (name->ln_number >> 24) & 0xff;
+	temp[6] = (name->ln_number >> 16) & 0xff;
+	temp[7] = (name->ln_number >> 8) & 0xff;
+	temp[8] = (name->ln_number >> 0) & 0xff;
+
+	len = pack_lock_key(key, GIO_KEY_SIZE, 'G', fs->fs_name, temp, 9);
+	if( len <=0 ) {err = len; goto exit;}
+
+	if (!find_and_mark_lock (key, len, &lck)) {
+		/* not found, must create. */
+		lck = kmalloc(sizeof(gulm_lock_t), GFP_KERNEL);
+		if (lck == NULL) {
+			err = -ENOMEM;
+			goto exit;
+		}
+		INIT_LIST_HEAD (&lck->gl_list);
+		atomic_set (&lck->count, 1);
+		lck->key = kmalloc (len, GFP_KERNEL);
+		if (lck->key == NULL) {
+			kfree(lck);
+			err = -ENOMEM;
+			goto exit;
+		}
+		memcpy (lck->key, key, len);
+		lck->keylen = len;
+		lck->fs = fs;
+		lck->lvb = NULL;
+		lck->cur_state = LM_ST_UNLOCKED;
+
+		bkt = crc32 (GULM_CRC_INIT, key, len);
+		bkt &= gulm_gfs_lmMask;
+
+		spin_lock (&gulm_cm.gfs_lockmap[bkt].lock);
+		list_add (&lck->gl_list, &gulm_cm.gfs_lockmap[bkt].bucket);
+		spin_unlock (&gulm_cm.gfs_lockmap[bkt].lock);
+
+	}
+	*lockp = lck;
+
+exit:
+	return err;
+}
+
+/**
+ * gulm_put_lock - 
+ * @lock: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+gulm_put_lock (lm_lock_t * lock)
+{
+	unmark_and_release_lock ((gulm_lock_t *) lock);
+}
+
+/**
+ * gulm_lock_finish - 
+ * @glck: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_lock_finish (struct glck_req *item)
+{
+	int result;
+	gulm_lock_t *lck = (gulm_lock_t *)item->misc;
+	gulm_fs_t *fs = lck->fs;
+	struct lm_lockname lockname;
+
+	result = calc_lock_result (lck, item->state, item->error, item->flags);
+
+	gulm_key_to_lm_lockname (lck->key, &lockname);
+
+	qu_async_rpl (&fs->cq, fs->cb, fs->fsdata, &lockname, result);
+
+	/* marked in gulm_lock() */
+	unmark_and_release_lock (lck);
+}
+
+/**
+ * gulm_lock - 
+ * @lock: 
+ * @cur_state: 
+ * @req_state: 
+ * @flags: 
+ * 
+ * 
+ * Returns: int
+ */
+unsigned int
+gulm_lock (lm_lock_t * lock, unsigned int cur_state,
+	   unsigned int req_state, unsigned int flags)
+{
+	glckr_t *item;
+	gulm_lock_t *lck = (gulm_lock_t *) lock;
+	gulm_fs_t *fs = lck->fs;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return -ENOMEM;
+	}
+
+	mark_lock (lck); /* matching unmark is in gulm_lock_finish */
+
+	item->key = lck->key;
+	item->keylen = lck->keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+
+	switch (req_state) {
+	case LM_ST_EXCLUSIVE:
+		item->state = lg_lock_state_Exclusive;
+		break;
+	case LM_ST_DEFERRED:
+		item->state = lg_lock_state_Deferred;
+		break;
+	case LM_ST_SHARED:
+		item->state = lg_lock_state_Shared;
+		break;
+	case LM_ST_UNLOCKED:
+		item->state = lg_lock_state_Unlock;
+		break;
+	default:
+		GULM_ASSERT (0, log_err ("fsid=%s: Anit no lock state %d.\n",
+					 fs->fs_name, req_state););
+		break;
+	}
+	item->flags = 0;
+	if (flags & LM_FLAG_TRY) {
+		item->flags |= lg_lock_flag_Try;
+	}
+	if (flags & LM_FLAG_TRY_1CB) {
+		item->flags |= lg_lock_flag_Try | lg_lock_flag_DoCB;
+	}
+	if (flags & LM_FLAG_NOEXP) {
+		item->flags |= lg_lock_flag_IgnoreExp;
+	}
+	if (flags & LM_FLAG_ANY) {
+		item->flags |= lg_lock_flag_Any;
+	}
+	if (flags & LM_FLAG_PRIORITY) {
+		item->flags |= lg_lock_flag_Piority;
+	}
+	if (lck->lvb != NULL) {
+		item->lvb = lck->lvb;
+		item->lvblen = fs->lvb_size;
+	}else{
+		item->lvb = NULL;
+		item->lvblen = 0;
+	}
+	item->error = 0;
+
+	item->misc = lck;
+	item->finish = gulm_lock_finish;
+
+	lck->cur_state = cur_state;
+
+	glq_queue (item);
+
+	return LM_OUT_ASYNC;
+}
+
+/**
+ * gulm_unlock - 
+ * @lock: 
+ * @cur_state: 
+ * 
+ * 
+ * Returns: int
+ */
+unsigned int
+gulm_unlock (lm_lock_t * lock, unsigned int cur_state)
+{
+	int e;
+	e = gulm_lock (lock, cur_state, LM_ST_UNLOCKED, 0);
+	return e;
+}
+
+/**
+ * gulm_cancel - 
+ * @lock: 
+ * 
+ */
+void
+gulm_cancel (lm_lock_t * lock)
+{
+	glckr_t *item;
+	gulm_lock_t *lck = (gulm_lock_t *) lock;
+
+	mark_lock (lck);
+
+	item = glq_get_new_req();
+	if( item == NULL ) goto exit;
+
+	/* have to make a copy for cancel req. */
+	item->key = kmalloc(lck->keylen, GFP_KERNEL);
+	if (item->key == NULL) {
+		glq_recycle_req(item);
+		goto exit;
+	}
+	memcpy(item->key, lck->key, lck->keylen);
+	item->keylen = lck->keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_cancel;
+	item->finish = NULL;
+
+	glq_cancel(item);
+
+exit:
+	unmark_and_release_lock (lck);
+}
+
+/****************************************************************************/
+struct gulm_lvb_temp_s {
+	int error;
+	struct completion sleep;
+};
+
+/**
+ * gulm_lvb_finish - 
+ * @glck: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_lvb_finish(struct glck_req *glck)
+{
+	struct gulm_lvb_temp_s *g = (struct gulm_lvb_temp_s *)glck->misc;
+	g->error = glck->error;
+	complete (&g->sleep);
+}
+
+/**
+ * gulm_hold_lvb - 
+ * @lock: 
+ * @lvbp:
+ * 
+ * 
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+gulm_hold_lvb (lm_lock_t * lock, char **lvbp)
+{
+	int err = -1;
+	struct gulm_lvb_temp_s ghlt;
+	glckr_t *item;
+	gulm_lock_t *lck = (gulm_lock_t *) lock;
+	gulm_fs_t *fs = lck->fs;
+
+	mark_lock (lck);
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	item->key = lck->key;
+	item->keylen = lck->keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_action;
+	item->state = lg_lock_act_HoldLVB;
+	item->flags = 0;
+	item->error = ghlt.error = 0;
+
+	init_completion (&ghlt.sleep);
+
+	item->misc = &ghlt;
+	item->finish = gulm_lvb_finish;
+
+	lck->lvb = kmalloc (fs->lvb_size, GFP_KERNEL);
+	if (lck->lvb == NULL) {
+		err = -ENOMEM;
+		goto fail;
+	}
+	memset (lck->lvb, 0, fs->lvb_size);
+
+	item->lvb = lck->lvb;
+	item->lvblen = fs->lvb_size;
+
+	glq_queue (item);
+	wait_for_completion (&ghlt.sleep);
+	/* after here, item is no longer valid
+	 * (memory was probably freed.)
+	 * is why we use ghlt.error and not item->error.
+	 */
+
+	if (ghlt.error != lg_err_Ok) {
+		log_err ("fsid=%s: Got error %d on hold lvb request.\n",
+			 fs->fs_name, ghlt.error);
+		kfree (lck->lvb);
+		lck->lvb = NULL;
+		goto fail;
+	}
+
+	*lvbp = lck->lvb;
+
+	unmark_and_release_lock (lck);
+
+	lvb_log_msg_lk (lck->key, "fsid=%s: Exiting gulm_hold_lvb\n",
+			fs->fs_name);
+	return 0;
+      fail:
+	unmark_and_release_lock (lck);
+	if (err != 0)
+		log_msg (lgm_Always,
+			 "fsid=%s: Exiting gulm_hold_lvb with errors (%d)\n",
+			 fs->fs_name, err);
+	return err;
+}
+
+/**
+ * gulm_unhold_lvb - 
+ * @lock: 
+ * @lvb: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+gulm_unhold_lvb (lm_lock_t * lock, char *lvb)
+{
+	struct gulm_lvb_temp_s ghlt;
+	glckr_t *item;
+	gulm_lock_t *lck = (gulm_lock_t *) lock;
+	gulm_fs_t *fs = lck->fs;
+
+	mark_lock (lck);
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		log_err("unhold_lvb: failed to get needed memory. skipping.\n");
+		goto exit;
+	}
+
+	item->key = lck->key;
+	item->keylen = lck->keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_action;
+	item->state = lg_lock_act_UnHoldLVB;
+	item->flags = 0;
+	item->error = ghlt.error = 0;
+
+	init_completion (&ghlt.sleep);
+
+	item->misc = &ghlt;
+	item->finish = gulm_lvb_finish;
+
+	item->lvb = lck->lvb;
+	item->lvblen = fs->lvb_size;
+
+	glq_queue (item);
+	wait_for_completion (&ghlt.sleep);
+	/* after here, item is no longer valid
+	 * (memory was probably freed.)
+	 * is why we use ghlt.error and not item->error.
+	 */
+
+	if (ghlt.error != lg_err_Ok) {
+		log_err ("fsid=%s: Got error %d on unhold LVB request.\n",
+			 lck->fs->fs_name, ghlt.error);
+	}
+	/* free it always.  GFS thinks it is gone no matter what the server
+	 * thinks. (and as much as i hate to say it this way, far better to
+	 * leak in userspace than in kernel space.)
+	 */
+	if (lck->lvb != NULL)
+		kfree (lck->lvb);
+	lck->lvb = NULL;
+      exit:
+	unmark_and_release_lock (lck);
+	lvb_log_msg ("Exiting gulm_unhold_lvb\n");
+}
+
+/**
+ * gulm_sync_lvb - 
+ * @lock: 
+ * @lvb: 
+ * 
+ */
+void
+gulm_sync_lvb (lm_lock_t * lock, char *lvb)
+{
+	struct gulm_lvb_temp_s ghlt;
+	glckr_t *item;
+	gulm_lock_t *lck = (gulm_lock_t *) lock;
+	gulm_fs_t *fs = lck->fs;
+
+	mark_lock (lck);
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		log_err("sync_lvb: failed to get needed memory. skipping.\n");
+		goto exit;
+	}
+
+	item->key = lck->key;
+	item->keylen = lck->keylen;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_action;
+	item->state = lg_lock_act_SyncLVB;
+	item->flags = 0;
+	item->error = ghlt.error = 0;
+
+	init_completion (&ghlt.sleep);
+
+	item->misc = &ghlt;
+	item->finish = gulm_lvb_finish;
+
+	item->lvb = lck->lvb;
+	item->lvblen = fs->lvb_size;
+
+	glq_queue (item);
+	wait_for_completion (&ghlt.sleep);
+	/* after here, item is no longer valid
+	 * (memory was probably freed.)
+	 * is why we use ghlt.error and not item->error.
+	 */
+
+	if (ghlt.error != lg_err_Ok) {
+		log_err ("fsid=%s: Got error %d on sync LVB request.\n",
+			 lck->fs->fs_name, ghlt.error);
+	}
+
+      exit:
+	unmark_and_release_lock (lck);
+	lvb_log_msg ("Exiting gulm_sync_lvb\n");
+
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_main.c linux-patched/fs/gfs_locking/lock_gulm/gulm_main.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_main.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_main.c	2005-01-12 17:20:30.294660135 -0600
@@ -0,0 +1,131 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/init.h>
+
+#include "gulm_lock_queue.h"
+
+MODULE_DESCRIPTION ("Grand Unified Locking Module " GULM_RELEASE_NAME);
+MODULE_AUTHOR ("Red Hat, Inc.");
+MODULE_LICENSE ("GPL");
+
+gulm_cm_t gulm_cm;
+
+struct lm_lockops gulm_ops = {
+      lm_proto_name:PROTO_NAME,
+      lm_mount:gulm_mount,
+      lm_others_may_mount:gulm_others_may_mount,
+      lm_unmount:gulm_unmount,
+      lm_withdraw:gulm_withdraw,
+      lm_get_lock:gulm_get_lock,
+      lm_put_lock:gulm_put_lock,
+      lm_lock:gulm_lock,
+      lm_unlock:gulm_unlock,
+      lm_cancel:gulm_cancel,
+      lm_hold_lvb:gulm_hold_lvb,
+      lm_unhold_lvb:gulm_unhold_lvb,
+      lm_sync_lvb:gulm_sync_lvb,
+      lm_plock_get:gulm_plock_get,
+      lm_plock:gulm_plock,
+      lm_punlock:gulm_punlock,
+      lm_recovery_done:gulm_recovery_done,
+      lm_owner:THIS_MODULE,
+};
+
+/**
+ * init_gulm - Initialize the gulm module
+ *
+ * Returns: 0 on success, -EXXX on failure
+ */
+int __init
+init_gulm (void)
+{
+	int error;
+
+	memset (&gulm_cm, 0, sizeof (gulm_cm_t));
+	gulm_cm.hookup = NULL;
+
+	/* register with the lm layers. */
+	error = lm_register_proto (&gulm_ops);
+	if (error)
+		goto fail;
+
+	error = glq_init();
+	if (error != 0 )
+		goto lm_fail;
+
+	error = gulm_lt_init();
+	if (error != 0)
+		goto glq_fail;
+
+	init_gulm_fs ();
+	sig_watcher_init ();
+
+	printk ("Gulm %s (built %s %s) installed\n",
+		GULM_RELEASE_NAME, __DATE__, __TIME__);
+
+	return 0;
+
+glq_fail:
+	glq_release();
+
+   lm_fail:
+	lm_unregister_proto (&gulm_ops);
+
+      fail:
+	return error;
+}
+
+/**
+ * exit_gulm - cleanup the gulm module
+ *
+ */
+
+void __exit
+exit_gulm (void)
+{
+	gulm_lt_release();
+	glq_release();
+	lm_unregister_proto (&gulm_ops);
+}
+
+module_init (init_gulm);
+module_exit (exit_gulm);
+
+/* the libgulm.h interface. */
+EXPORT_SYMBOL (lg_initialize);
+EXPORT_SYMBOL (lg_release);
+
+EXPORT_SYMBOL (lg_core_handle_messages);
+EXPORT_SYMBOL (lg_core_selector);
+EXPORT_SYMBOL (lg_core_login);
+EXPORT_SYMBOL (lg_core_logout);
+EXPORT_SYMBOL (lg_core_nodeinfo);
+EXPORT_SYMBOL (lg_core_nodelist);
+EXPORT_SYMBOL (lg_core_servicelist);
+EXPORT_SYMBOL (lg_core_corestate);
+EXPORT_SYMBOL (lg_core_shutdown);
+EXPORT_SYMBOL (lg_core_forceexpire);
+EXPORT_SYMBOL (lg_core_forcepending);
+
+EXPORT_SYMBOL (lg_lock_handle_messages);
+EXPORT_SYMBOL (lg_lock_selector);
+EXPORT_SYMBOL (lg_lock_login);
+EXPORT_SYMBOL (lg_lock_logout);
+EXPORT_SYMBOL (lg_lock_state_req);
+EXPORT_SYMBOL (lg_lock_cancel_req);
+EXPORT_SYMBOL (lg_lock_action_req);
+EXPORT_SYMBOL (lg_lock_drop_exp);
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_plock.c linux-patched/fs/gfs_locking/lock_gulm/gulm_plock.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_plock.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_plock.c	2005-01-12 17:20:30.294660135 -0600
@@ -0,0 +1,259 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "gulm_lock_queue.h"
+
+/*****************************************************************************/
+struct gulm_pret_s {
+	int error;
+	struct completion sleep;
+};
+
+/**
+ * gulm_plock_packname - 
+ * @fsname: 
+ * @num: 
+ * @key: 
+ * @keylen: 
+ * 
+ * 
+ * Returns: int
+ */
+int gulm_plock_packname(uint8_t * fsname, uint64_t num, uint8_t *key, uint16_t keylen)
+{
+	uint8_t temp[8];
+	temp[0] = (num >> 56) & 0xff;
+	temp[1] = (num >> 48) & 0xff;
+	temp[2] = (num >> 40) & 0xff;
+	temp[3] = (num >> 32) & 0xff;
+	temp[4] = (num >> 24) & 0xff;
+	temp[5] = (num >> 16) & 0xff;
+	temp[6] = (num >> 8) & 0xff;
+	temp[7] = (num >> 0) & 0xff;
+	return pack_lock_key(key, keylen, 'P', fsname, temp, 8);
+}
+
+/**
+ * gulm_plock_finish - 
+ * @glck: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_plock_finish(struct glck_req *glck)
+{
+	struct gulm_pret_s *g = (struct gulm_pret_s *)glck->misc;
+	g->error = glck->error;
+	complete (&g->sleep);
+}
+
+struct gulm_pqur_s {
+	uint64_t start;
+	uint64_t stop;
+	uint64_t subid;
+	int error;
+	uint8_t state;
+	struct completion sleep;
+};
+/**
+ * gulm_plock_query_finish - 
+ * @glck: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_plock_query_finish(struct glck_req *glck)
+{
+	struct gulm_pqur_s *g = (struct gulm_pqur_s *)glck->misc;
+	g->error = glck->error;
+	g->start = glck->start;
+	g->stop = glck->stop;
+	g->subid = glck->subid;
+	g->state = glck->state;
+	complete (&g->sleep);
+}
+/**
+ * gulm_plock_get - 
+ */
+int
+gulm_plock_get (lm_lockspace_t * lockspace, struct lm_lockname *name,
+		 struct file *file, struct file_lock *fl)
+{
+	int err = 0;
+	struct gulm_pqur_s pqur;
+	uint8_t key[GIO_KEY_SIZE];
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	item->keylen = gulm_plock_packname(fs->fs_name, name->ln_number,
+			key, GIO_KEY_SIZE);
+	item->key = key;
+	item->subid = (unsigned long) fl->fl_owner;
+	item->start = fl->fl_start;
+	item->stop = fl->fl_end;
+	item->type = glq_req_type_query;
+	if (fl->fl_type == F_WRLCK) {
+		item->state = lg_lock_state_Exclusive;
+	} else {
+		item->state = lg_lock_state_Shared;
+	}
+	item->flags = lg_lock_flag_NoCallBacks;
+	item->error = pqur.error = 0;
+
+	init_completion (&pqur.sleep);
+
+	item->misc = &pqur;
+	item->finish = gulm_plock_query_finish;
+
+	glq_queue (item);
+	wait_for_completion (&pqur.sleep);
+
+	if (pqur.error == lg_err_TryFailed) {
+		err = -EAGAIN;
+		fl->fl_start = pqur.start;
+		fl->fl_end = pqur.stop;
+		fl->fl_pid = pqur.subid;
+		if( pqur.state == lg_lock_state_Exclusive )
+			fl->fl_type = F_WRLCK;
+		else
+			fl->fl_type = F_RDLCK;
+	} else if (pqur.error == 0) {
+		fl->fl_type = F_UNLCK;
+	} else {
+		err = -pqur.error;
+	}
+
+fail:
+	return err;
+}
+
+/**
+ * gulm_plock - 
+ *
+ */
+int
+gulm_plock (lm_lockspace_t *lockspace, struct lm_lockname *name,
+		struct file *file, int cmd, struct file_lock *fl)
+{
+	int err = 0;
+	struct gulm_pret_s pret;
+	uint8_t key[GIO_KEY_SIZE];
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	item->keylen = gulm_plock_packname(fs->fs_name, name->ln_number,
+			key, GIO_KEY_SIZE);
+	item->key = key;
+	item->subid = (unsigned long) fl->fl_owner;
+	item->start = fl->fl_start;
+	item->stop = fl->fl_end;
+	item->type = glq_req_type_state;
+	if (fl->fl_type == F_WRLCK) {
+		item->state = lg_lock_state_Exclusive;
+	} else {
+		item->state = lg_lock_state_Shared;
+	}
+	item->flags = lg_lock_flag_NoCallBacks;
+	if (!IS_SETLKW(cmd))
+		item->flags |= lg_lock_flag_Try;
+	item->error = pret.error = 0;
+
+	init_completion (&pret.sleep);
+
+	item->misc = &pret;
+	item->finish = gulm_plock_finish;
+
+	glq_queue (item);
+	/* TODO should be interruptible by signals */
+	wait_for_completion (&pret.sleep);
+
+	if (pret.error == lg_err_TryFailed) {
+		err = -EAGAIN;
+	} else {
+		err = -pret.error;
+	}
+
+	if ( err != 0) err = posix_lock_file_wait(file, fl);
+
+fail:
+	return err;
+}
+
+/**
+ * gulm_unplock - 
+ */
+int
+gulm_punlock (lm_lockspace_t * lockspace, struct lm_lockname *name,
+	      struct file *file, struct file_lock *fl)
+{
+	int err = 0;
+	struct gulm_pret_s pret;
+	uint8_t key[GIO_KEY_SIZE];
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if( item == NULL ) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	item->keylen = gulm_plock_packname(fs->fs_name, name->ln_number,
+			key, GIO_KEY_SIZE);
+	item->key = key;
+	item->subid = (unsigned long) fl->fl_owner;
+	item->start = fl->fl_start;
+	item->stop = fl->fl_end;
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Unlock;
+	item->flags = 0;
+	item->error = pret.error = 0;
+
+	init_completion (&pret.sleep);
+
+	item->misc = &pret;
+	item->finish = gulm_plock_finish;
+
+	glq_queue (item);
+	/* TODO should be interruptible by signals */
+	wait_for_completion (&pret.sleep);
+
+	err = -pret.error;
+	if ( err != 0) err = posix_lock_file_wait(file, fl);
+
+fail:
+	return err;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_prints.h linux-patched/fs/gfs_locking/lock_gulm/gulm_prints.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_prints.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_prints.h	2005-01-12 17:20:30.294660135 -0600
@@ -0,0 +1,45 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __gulm_prints_h__
+#define __gulm_prints_h__
+#include "gulm_log_msg_bits.h"
+
+#define PROTO_NAME "lock_gulm"
+
+#ifdef GULM_ASSERT
+#undef GULM_ASSERT
+#endif
+#define GULM_ASSERT(x, do) \
+{ \
+  if (!(x)) \
+  { \
+    printk("\n"PROTO_NAME":  Assertion failed on line %d of file %s\n" \
+               PROTO_NAME":  assertion:  \"%s\"\n", \
+               __LINE__, __FILE__, #x ); \
+    {do} \
+    panic("\n"PROTO_NAME":  Record message above and reboot.\n"); \
+  } \
+}
+
+#define log_msg(v, fmt, args...) if(((v)&gulm_cm.verbosity)==(v)||(v)==lgm_Always) {\
+   printk(PROTO_NAME ": " fmt, ## args); \
+}
+#define log_err(fmt, args...) {\
+   printk(KERN_ERR PROTO_NAME ": ERROR " fmt, ## args); \
+}
+
+#define log_nop(fmt, args...)
+#define TICK printk("TICK==>" PROTO_NAME ": [%s:%d] pid:%d\n" , __FILE__ , __LINE__ , current->pid )
+
+#endif /*__gulm_prints_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_recsig.c linux-patched/fs/gfs_locking/lock_gulm/gulm_recsig.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_recsig.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_recsig.c	2005-01-12 17:20:30.300658784 -0600
@@ -0,0 +1,337 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "gulm_lock_queue.h"
+
+/* This is some speed hackery to abuse the locking system to allow clients
+ * to notify each other of things.  It is a super simple signaling type
+ * system.  All you can know is that a signal was touched.  Pretty
+ * sreightforword.
+ *
+ * I really would rather have something else.  I've a couple of good ideas,
+ * and will most likely switch to one of those at a later date.  But this
+ * is good enough for now, and will get us through the next release.
+ *
+ * (functionally nothing wrong with this, theoretically, I can think of
+ * better designs than this abuse.)
+ */
+
+extern gulm_cm_t gulm_cm;
+
+struct sig_watcher {
+	struct list_head sw_list;
+	uint8_t *name;
+	uint8_t len;
+	void(*func)(void *misc);
+	void *misc;
+};
+struct list_head sig_watchers_list;
+spinlock_t sig_watchers_lock;
+
+/****************************************************************************/
+/* internal funcs */
+/**
+ * release_sw - 
+ * @name: 
+ * @len: 
+ * 
+ * 
+ * Returns: void
+ */
+static void release_sw(uint8_t *name, uint8_t len)
+{
+	struct list_head *tmp;
+	struct sig_watcher *sw;
+	spin_lock(&sig_watchers_lock);
+	list_for_each(tmp, &sig_watchers_list) {
+		sw = list_entry (tmp, struct sig_watcher, sw_list);
+		if( memcmp(name, sw->name, len) == 0 ) {
+			list_del(tmp);
+			kfree(sw->name);
+			kfree(sw);
+			break;
+		}
+	}
+	spin_unlock(&sig_watchers_lock);
+}
+/**
+ * add_sw - 
+ * @name: 
+ * @len: 
+ * @func: 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+static int add_sw(uint8_t *name, uint8_t len,
+		void(*func)(void *misc), void *misc)
+{
+	struct sig_watcher *sw;
+
+	sw = kmalloc(sizeof(struct sig_watcher), GFP_KERNEL);
+	if( sw == NULL ) return -ENOMEM;
+	sw->name = kmalloc(len, GFP_KERNEL);
+	if( sw->name == NULL ) {
+		kfree(sw);
+		return -ENOMEM;
+	}
+	memcpy(sw->name, name, len);
+	sw->len = len;
+	sw->func = func;
+	sw->misc = misc;
+	INIT_LIST_HEAD (&sw->sw_list);
+	spin_lock(&sig_watchers_lock);
+	list_add(&sw->sw_list, &sig_watchers_list);
+	spin_unlock(&sig_watchers_lock);
+	return 0;
+}
+
+/**
+ * gulm_sw_finish - 
+ * @item: 
+ * 
+ * 
+ * Returns: void
+ */
+void gulm_sw_finish (struct glck_req *item)
+{
+	struct completion *sleep = (struct completion *)item->misc;
+	complete (sleep);
+}
+
+/**
+ * hold_watch_lock - 
+ * @name: 
+ * @len: 
+ * 
+ * 
+ * Returns: void
+ */
+void hold_watch_lock(gulm_fs_t *fs, uint8_t *name, uint8_t len)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+	struct completion sleep;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return;
+	}
+
+	item->keylen = pack_lock_key(key, keylen, 'S', fs->fs_name, name, len);
+	item->key = key;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Shared;
+	item->flags = lg_lock_flag_IgnoreExp;
+	item->error =  0;
+	item->lvb = NULL;
+	item->lvblen = 0;
+
+	init_completion (&sleep);
+
+	item->misc = &sleep;
+	item->finish = gulm_sw_finish;
+
+	glq_queue (item);
+	wait_for_completion (&sleep);
+}
+/**
+ * release_watch_lock - 
+ * @name: 
+ * @len: 
+ * 
+ * 
+ * Returns: void
+ */
+void release_watch_lock(gulm_fs_t *fs, uint8_t *name, uint8_t len)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+	struct completion sleep;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return;
+	}
+
+	item->keylen = pack_lock_key(key, keylen, 'S', fs->fs_name, name, len);
+	item->key = key;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Unlock;
+	item->flags = 0;
+	item->error =  0;
+	item->lvb = NULL;
+	item->lvblen = 0;
+
+	init_completion (&sleep);
+
+	item->misc = &sleep;
+	item->finish = gulm_sw_finish;
+
+	glq_queue (item);
+	wait_for_completion (&sleep);
+}
+/**
+ * signal_watch_lock - 
+ * @name: 
+ * @len: 
+ * 
+ * 
+ * Returns: void
+ */
+void signal_watch_lock(gulm_fs_t *fs, uint8_t *name, uint8_t len)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+	struct completion sleep;
+	glckr_t *item;
+
+	item = glq_get_new_req();
+	if (item == NULL) {
+		return;
+	}
+
+	item->keylen = pack_lock_key(key, keylen, 'S', fs->fs_name, name, len);
+	item->key = key;
+	item->subid = 0;
+	item->start = 0;
+	item->stop = ~((uint64_t)0);
+	item->type = glq_req_type_state;
+	item->state = lg_lock_state_Exclusive;
+	item->flags = lg_lock_flag_Try|lg_lock_flag_DoCB|lg_lock_flag_IgnoreExp;
+	item->error =  0;
+	item->lvb = NULL;
+	item->lvblen = 0;
+
+	init_completion (&sleep);
+
+	item->misc = &sleep;
+	item->finish = gulm_sw_finish;
+
+	glq_queue (item);
+	wait_for_completion (&sleep);
+}
+
+/**
+ * sig_watcher_lock_drop - 
+ * @key: 
+ * @keylen: 
+ * 
+ * 
+ * Returns: void
+ */
+void sig_watcher_lock_drop(uint8_t * key, uint16_t keylen)
+{
+	struct list_head *tmp;
+	struct sig_watcher *sw = NULL;
+	int found = FALSE;
+	uint8_t *fsname, len, *name, nlen;
+	if( key[0] != 'S' ) return; /* not a Signal lock */
+	len = key[1];
+	fsname = &key[2];
+	nlen = key[3 + len];
+	name = &key[4 + len];
+	spin_lock(&sig_watchers_lock);
+	list_for_each(tmp, &sig_watchers_list) {
+		sw = list_entry (tmp, struct sig_watcher, sw_list);
+		if( memcmp(name, sw->name, MIN(nlen, sw->len)) == 0 ) {
+			found = TRUE;
+			break;
+		}
+	}
+	spin_unlock(&sig_watchers_lock);
+	if(found) {
+		sw->func(sw->misc);
+	}
+}
+
+/****************************************************************************/
+
+/**
+ * sig_water_init - 
+ * @oid: 
+ * 
+ * 
+ * Returns: void
+ */
+void sig_watcher_init(void)
+{
+	INIT_LIST_HEAD (&sig_watchers_list);
+	spin_lock_init(&sig_watchers_lock);
+}
+
+
+/**
+ * watch_sig - 
+ * @name: 
+ * @len: 
+ * @misc: 
+ * @misc: 
+ * 
+ * Returns: int
+ */
+int watch_sig(gulm_fs_t *fs, uint8_t *name, uint8_t len, void(*func)(void *misc), void *misc)
+{
+	if( func == NULL ) {
+		/* unlock signal lock */
+		release_watch_lock(fs, name, len);
+		release_sw(name, len);
+	}else{
+		/* hold signal lock shared. */
+		if(add_sw(name, len, func, misc) == 0 ) {
+			hold_watch_lock(fs, name, len);
+		}else{
+			return -ENOMEM;
+		}
+	}
+	return 0;
+}
+
+/**
+ * tap_sig - 
+ * @name: 
+ * @len: 
+ * 
+ * 
+ * Returns: int
+ */
+void tap_sig(gulm_fs_t *fs, uint8_t *name, uint8_t len)
+{
+	signal_watch_lock(fs, name, len);
+#if 0
+	/* Make sure it is still Shr. (very lazy way to do this. but it
+	 * should be low traffic enough not to bother.)
+	 * */
+	hold_watch_lock(fs, name, len);
+#endif
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/handler.c linux-patched/fs/gfs_locking/lock_gulm/handler.c
--- linux-orig/fs/gfs_locking/lock_gulm/handler.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/handler.c	2005-01-12 17:20:30.301658558 -0600
@@ -0,0 +1,343 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/smp_lock.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "handler.h"
+
+/* things about myself
+ * mostly just for verbosity here.
+ * */
+extern gulm_cm_t gulm_cm;
+
+/* the task struct */
+typedef struct runtask_s {
+	struct list_head rt_list;
+
+	gulm_fn fn;
+	lm_callback_t cb;
+	lm_fsdata_t *fsdata;
+	int type;
+	uint64_t lmnum;
+	unsigned int lmtype;
+	int result;
+
+} runtask_t;
+/* ooo crufty. */
+#define LM_CB_GULM_FN 169
+#if LM_CB_GULM_FN == LM_CB_NEED_E || \
+    LM_CB_GULM_FN == LM_CB_NEED_D || \
+    LM_CB_GULM_FN == LM_CB_NEED_S || \
+    LM_CB_GULM_FN == LM_CB_NEED_RECOVERY || \
+    LM_CB_GULM_FN == LM_CB_DROPLOCKS || \
+    LM_CB_GULM_FN == LM_CB_ASYNC
+#error "LM_CB_GULM_FN collision with other LM_CB_*"
+#endif
+
+static __inline__ int
+queue_empty (callback_qu_t * cq)
+{
+	int ret;
+	spin_lock (&cq->list_lock);
+	ret = list_empty (&cq->run_tasks);
+	spin_unlock (&cq->list_lock);
+	return ret;
+}
+
+/**
+ * handler - 
+ * @d: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+handler (void *d)
+{
+	callback_qu_t *cq = (callback_qu_t *) d;
+	runtask_t *rt;
+	struct list_head *tmp;
+	struct lm_lockname lockname;
+	struct lm_async_cb acb;
+
+	daemonize ("gulm_Cb_Handler");
+	atomic_inc (&cq->num_threads);
+	complete (&cq->startup);
+
+	while (cq->running) {
+		do {
+			DECLARE_WAITQUEUE (__wait_chan, current);
+			current->state = TASK_INTERRUPTIBLE;
+			add_wait_queue (&cq->waiter, &__wait_chan);
+			if (queue_empty (cq))
+				schedule ();
+			remove_wait_queue (&cq->waiter, &__wait_chan);
+			current->state = TASK_RUNNING;
+		} while (0);
+
+		if (!cq->running)
+			break;
+		/* remove item from list */
+		spin_lock (&cq->list_lock);
+		if (list_empty (&cq->run_tasks)) {
+			spin_unlock (&cq->list_lock);
+			continue;	/* nothing here. move on */
+		}
+		/* take items off the end of the list, since we add them to the
+		 * beginning.
+		 */
+		tmp = (&cq->run_tasks)->prev;
+		list_del (tmp);
+		cq->task_count--;
+		spin_unlock (&cq->list_lock);
+
+		rt = list_entry (tmp, runtask_t, rt_list);
+
+		if (rt->type == LM_CB_ASYNC) {
+			acb.lc_name.ln_number = rt->lmnum;
+			acb.lc_name.ln_type = rt->lmtype;
+			acb.lc_ret = rt->result;
+			rt->cb (rt->fsdata, rt->type, &acb);
+		} else if (rt->type == LM_CB_GULM_FN) {
+			rt->fn (rt->fsdata);
+		} else {
+			lockname.ln_number = rt->lmnum;
+			lockname.ln_type = rt->lmtype;
+			rt->cb (rt->fsdata, rt->type, &lockname);
+		}
+
+		kfree (rt);
+
+	}			/*while(running) */
+
+	atomic_dec (&cq->num_threads);
+	complete (&cq->startup);
+	return 0;
+}
+
+/**
+ * display_handler_queue - 
+ * @cq: 
+ * 
+ * remember, items are added to the head, and removed from the tail.
+ * So the last item listed, is the next item to be handled.
+ * 
+ */
+void
+display_handler_queue (callback_qu_t * cq)
+{
+	struct list_head *lltmp;
+	runtask_t *rt;
+	int i = 0;
+	log_msg (lgm_Always, "Dumping Handler queue with %d items, max %d\n",
+		 cq->task_count, cq->task_max);
+	spin_lock (&cq->list_lock);
+	list_for_each (lltmp, &cq->run_tasks) {
+		rt = list_entry (lltmp, runtask_t, rt_list);
+		if (rt->type == LM_CB_ASYNC) {
+			log_msg (lgm_Always,
+				 "%4d ASYNC    (%" PRIu64 ", %u) result:%#x\n",
+				 i, rt->lmnum, rt->lmtype, rt->result);
+		} else if (rt->type == LM_CB_GULM_FN) {
+			log_msg (lgm_Always, "%4d GULM FN  func:%p data:%p\n",
+				 i, rt->fn, rt->fsdata);
+		} else {	/* callback. */
+			log_msg (lgm_Always,
+				 "%4d CALLBACK req:%u (%" PRIu64 ", %u)\n", i,
+				 rt->type, rt->lmnum, rt->lmtype);
+		}
+		i++;
+	}
+	spin_unlock (&cq->list_lock);
+}
+
+/**
+ * alloc_runtask - 
+ * Returns: runtask_t
+ */
+runtask_t *
+alloc_runtask (void)
+{
+	runtask_t *rt;
+	rt = kmalloc (sizeof (runtask_t), GFP_KERNEL);
+	return rt;
+}
+
+/**
+ * qu_function_call - 
+ * @cq: 
+ * @fn: 
+ * @data: 
+ * 
+ * Generic function execing on the handler thread.  Mostly so I can add
+ * single things quick without having to build all the details into the
+ * handler queues.
+ * 
+ * Returns: int
+ */
+int
+qu_function_call (callback_qu_t * cq, gulm_fn fn, void *data)
+{
+	runtask_t *rt;
+	rt = alloc_runtask ();
+	if (rt == NULL)
+		return -ENOMEM;
+	rt->cb = NULL;
+	rt->fn = fn;
+	rt->fsdata = data;
+	rt->type = LM_CB_GULM_FN;
+	rt->lmtype = 0;
+	rt->lmnum = 0;
+	rt->result = 0;
+	INIT_LIST_HEAD (&rt->rt_list);
+	spin_lock (&cq->list_lock);
+	list_add (&rt->rt_list, &cq->run_tasks);
+	cq->task_count++;
+	if (cq->task_count > cq->task_max)
+		cq->task_max = cq->task_count;
+	spin_unlock (&cq->list_lock);
+	wake_up (&cq->waiter);
+	return 0;
+}
+
+/**
+ * qu_async_rpl - 
+ * @cq: 
+ * @cb: 
+ * @fsdata: 
+ * @lockname: 
+ * @result: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+qu_async_rpl (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+	      struct lm_lockname *lockname, int result)
+{
+	runtask_t *rt;
+	rt = alloc_runtask ();
+	if (rt == NULL)
+		return -ENOMEM;
+	rt->cb = cb;
+	rt->fsdata = fsdata;
+	rt->type = LM_CB_ASYNC;
+	rt->lmtype = lockname->ln_type;
+	rt->lmnum = lockname->ln_number;
+	rt->result = result;
+	INIT_LIST_HEAD (&rt->rt_list);
+	spin_lock (&cq->list_lock);
+	list_add (&rt->rt_list, &cq->run_tasks);
+	cq->task_count++;
+	if (cq->task_count > cq->task_max)
+		cq->task_max = cq->task_count;
+	spin_unlock (&cq->list_lock);
+	wake_up (&cq->waiter);
+	return 0;
+}
+
+/**
+ * qu_drop_req - 
+ * 
+ * Returns: <0:Error; =0:Ok
+ */
+int
+qu_drop_req (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+	     int type, uint8_t lmtype, uint64_t lmnum)
+{
+	runtask_t *rt;
+	rt = alloc_runtask ();
+	if (rt == NULL)
+		return -ENOMEM;
+	rt->cb = cb;
+	rt->fsdata = fsdata;
+	rt->type = type;
+	rt->lmtype = lmtype;
+	rt->lmnum = lmnum;
+	rt->result = 0;
+	INIT_LIST_HEAD (&rt->rt_list);
+	spin_lock (&cq->list_lock);
+	list_add (&rt->rt_list, &cq->run_tasks);
+	cq->task_count++;
+	if (cq->task_count > cq->task_max)
+		cq->task_max = cq->task_count;
+	spin_unlock (&cq->list_lock);
+	wake_up (&cq->waiter);
+	return 0;
+}
+
+/**
+ * stop_callback_qu - stop the handler thread
+ */
+void
+stop_callback_qu (callback_qu_t * cq)
+{
+	struct list_head *lltmp, *tmp;
+	runtask_t *rt;
+
+	if (cq->running) {
+		cq->running = FALSE;
+		/* make sure all thread stop.
+		 * */
+		while (atomic_read (&cq->num_threads) > 0) {
+			wake_up (&cq->waiter);
+			wait_for_completion (&cq->startup);
+		}
+		/* clear out any left overs. */
+		list_for_each_safe (tmp, lltmp, &cq->run_tasks) {
+			rt = list_entry (tmp, runtask_t, rt_list);
+			list_del (tmp);
+			kfree (rt);
+		}
+	}
+}
+
+/**
+ * start_callback_qu - 
+ *
+ * Returns: <0:Error, >=0:Ok
+ */
+int
+start_callback_qu (callback_qu_t * cq, int cnt)
+{
+	int err;
+	INIT_LIST_HEAD (&cq->run_tasks);
+	spin_lock_init (&cq->list_lock);
+	init_completion (&cq->startup);
+	init_waitqueue_head (&cq->waiter);
+	atomic_set (&cq->num_threads, 0);
+	cq->running = TRUE;
+	cq->task_count = 0;
+	cq->task_max = 0;
+	if (cnt <= 0)
+		cnt = 2;
+	for (; cnt > 0; cnt--) {
+		err = kernel_thread (handler, cq, 0);
+		if (err < 0) {
+			stop_callback_qu (cq);
+			/* calling stop here might not behave correctly in all error
+			 * cases.
+			 */
+			return err;
+		}
+		wait_for_completion (&cq->startup);
+	}
+	return 0;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/handler.h linux-patched/fs/gfs_locking/lock_gulm/handler.h
--- linux-orig/fs/gfs_locking/lock_gulm/handler.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/handler.h	2005-01-12 17:20:30.301658558 -0600
@@ -0,0 +1,42 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __handler_c__
+#define __handler_c__
+#include <linux/lm_interface.h>
+
+struct callback_qu_s {
+	struct completion startup;
+	int running;
+	int task_count;
+	int task_max;
+	struct list_head run_tasks;
+	spinlock_t list_lock;
+	wait_queue_head_t waiter;
+	atomic_t num_threads;
+};
+typedef struct callback_qu_s callback_qu_t;
+
+/* kinda an excess overloading */
+typedef void (*gulm_fn) (void *);
+int qu_function_call (callback_qu_t * cq, gulm_fn fn, void *data);
+
+int qu_async_rpl (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+		  struct lm_lockname *lockname, int result);
+int qu_drop_req (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+		 int type, uint8_t lmtype, uint64_t lmnum);
+int start_callback_qu (callback_qu_t * cq, int cnt);
+void stop_callback_qu (callback_qu_t * cq);
+void display_handler_queue (callback_qu_t * cq);
+
+#endif /*__handler_c__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_core.c linux-patched/fs/gfs_locking/lock_gulm/lg_core.c
--- linux-orig/fs/gfs_locking/lock_gulm/lg_core.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_core.c	2005-01-12 17:20:30.301658558 -0600
@@ -0,0 +1,669 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/* All of the core related functions for services are here. */
+
+#include "lg_priv.h"
+
+/**
+ * lg_core_selector - 
+ * @ulm_interface_p: 
+ * 
+ * 
+ * Returns: int
+ */
+xdr_socket
+lg_core_selector (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL || lg->first_magic != LGMAGIC
+	    || lg->last_magic != LGMAGIC)
+#ifdef __KERNEL__
+		return NULL;
+#else
+		return -EINVAL;
+#endif
+
+	return lg->core_fd;
+}
+
+/**
+ * lg_core_handle_messages - 
+ * @ulm_interface_p: 
+ * @lg_core_callbacks_t: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_handle_messages (gulm_interface_p lgp, lg_core_callbacks_t * ccbp,
+			 void *misc)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_dec_t *dec;
+	int err = 0;
+	uint64_t x_gen;
+	uint32_t x_code, x_error, x_rank;
+	struct in6_addr x_ip;
+	uint8_t x_state, x_mode;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EBADR;
+
+	down (&lg->core_recver);
+	if (lg->in_core_hm)
+		return -EDEADLK;
+	lg->in_core_hm = TRUE;
+	up (&lg->core_recver);
+
+	dec = lg->core_dec;
+
+	err = xdr_dec_uint32 (dec, &x_code);
+	if (err != 0)
+		goto exit;
+
+	if (gulm_core_login_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_uint64 (dec, &x_gen)) < 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) < 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_rank)) < 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) < 0)
+				break;
+		} while (0);
+		if (err != 0)
+			goto exit;
+		if (ccbp->login_reply == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->login_reply (misc, x_gen, x_error, x_rank, x_state);
+		goto exit;
+	} else if (gulm_core_logout_rpl == x_code) {
+		if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+			goto exit;
+		if (ccbp->logout_reply != NULL) {
+			err = ccbp->logout_reply (misc);
+		}
+
+		xdr_close (&lg->core_fd);
+		xdr_enc_release (lg->core_enc);
+		lg->core_enc = NULL;
+		xdr_dec_release (lg->core_dec);
+		lg->core_dec = NULL;
+
+		goto exit;
+	} else if (gulm_core_mbr_lstrpl == x_code) {
+		if (ccbp->nodelist != NULL) {
+			err = ccbp->nodelist (misc, lglcb_start, NULL, 0, 0);
+			if (err != 0)
+				goto exit;
+		}
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec) != 0) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+				if ((err = xdr_dec_ipv6 (dec, &x_ip)) != 0)
+					break;
+				if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+					break;
+				if ((err = xdr_dec_uint8 (dec, &x_mode)) != 0)
+					break;
+				if ((err = xdr_dec_uint8 (dec, &x_mode)) != 0)
+					break;
+				if ((err = xdr_dec_uint32 (dec, &x_rank)) != 0)
+					break;
+				if ((err = xdr_dec_uint64 (dec, &x_gen)) != 0)
+					break;
+				if ((err = xdr_dec_uint64 (dec, &x_gen)) != 0)
+					break;
+				if ((err = xdr_dec_uint64 (dec, &x_gen)) != 0)
+					break;
+
+				if (ccbp->nodelist != NULL) {
+					err =
+					    ccbp->nodelist (misc, lglcb_item,
+							    lg->cfba, &x_ip,
+							    x_state);
+					if (err != 0)
+						goto exit;
+				}
+
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->nodelist == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->nodelist (misc, lglcb_stop, NULL, 0, 0);
+		goto exit;
+	} else if (gulm_core_state_chgs == x_code) {
+		do {
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_mode)) != 0)
+				break;
+			if (x_state == gio_Mbr_ama_Slave) {
+				if ((err = xdr_dec_ipv6 (dec, &x_ip)) != 0)
+					break;
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->statechange == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->statechange (misc, x_state, x_mode, &x_ip, lg->cfba);
+		goto exit;
+	} else if (gulm_core_mbr_updt == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_string_ag (dec, &lg->cfba,
+						&lg->cfba_len)) != 0)
+				break;
+			if ((err = xdr_dec_ipv6 (dec, &x_ip)) != 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->nodechange == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->nodechange (misc, lg->cfba, &x_ip, x_state);
+		goto exit;
+	} else if (gulm_core_res_list == x_code) {
+		if (ccbp->service_list != NULL) {
+			if ((err =
+			     ccbp->service_list (misc, lglcb_start, NULL)) != 0)
+				goto exit;
+		}
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec)) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+				if (ccbp->service_list != NULL) {
+					if ((err =
+					     ccbp->service_list (misc,
+								 lglcb_item,
+								 lg->cfba)) !=
+					    0) {
+						goto exit;
+					}
+				}
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->service_list == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->service_list (misc, lglcb_stop, NULL);
+		goto exit;
+	} else if (gulm_info_stats_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec) != 0) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfbb,
+							&lg->cfbb_len)) != 0)
+					break;
+			}
+		} while (0);
+		goto exit;
+	} else if (gulm_err_reply == x_code) {
+		if ((err = xdr_dec_uint32 (dec, &x_code)) != 0)
+			goto exit;
+		if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+			goto exit;
+		if (ccbp->error == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->error (misc, x_error);
+		goto exit;
+	} else {
+		/* unknown code. what to do? */
+		err = -EPROTO;
+		goto exit;
+	}
+
+      exit:
+	lg->in_core_hm = FALSE;
+	return err;
+}
+
+/**
+ * lg_core_login - 
+ * @lgp: 
+ * @important: 
+ *
+ * On any error, things are closed and released to the state of things
+ * before you called login.
+ * 
+ * Returns: int
+ */
+int
+lg_core_login (gulm_interface_p lgp, int important)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct sockaddr_in6 adr;
+	int err;
+	xdr_socket cfd;
+	xdr_enc_t *enc;
+	xdr_dec_t *dec;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	adr.sin6_family = AF_INET6;
+	adr.sin6_addr = in6addr_loopback;
+	adr.sin6_port = htons (lg->core_port);
+
+	if ((err = xdr_open (&cfd)) < 0) {
+		return err;
+	}
+
+	if ((err = xdr_connect (&adr, cfd)) < 0) {
+		xdr_close (&cfd);
+		return err;
+	}
+
+	enc = xdr_enc_init (cfd, 128);
+	if (enc == NULL) {
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	dec = xdr_dec_init (cfd, 128);
+	if (enc == NULL) {
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_reslgn_req)) < 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, GIO_WIREPROT_VERS)) < 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->clusterID)) < 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->service_name)) < 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, gulm_svc_opt_locked |
+				      gulm_svc_opt_important)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) < 0)
+			break;
+	} while (0);
+	if (err != 0) {
+		xdr_dec_release (dec);
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return err;
+	}
+
+	down (&lg->core_sender);
+	lg->core_fd = cfd;
+	lg->core_enc = enc;
+	lg->core_dec = dec;
+	up (&lg->core_sender);
+
+	return 0;
+}
+
+/**
+ * lg_core_logout - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_logout (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_logout_req)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->service_name)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, gio_Mbr_ama_Resource)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_nodeinfo - 
+ * @lgp: 
+ * @nodename: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_nodeinfo (gulm_interface_p lgp, char *nodename)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	if (nodename == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_mbr_req)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, nodename)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_nodelist - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_nodelist (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_mbr_lstreq)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_servicelist - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_servicelist (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_res_req)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_corestate - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_corestate (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_state_req)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_shutdown - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_shutdown (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_shutdown)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_forceexpire - 
+ * @lgp: 
+ * @node_name: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_forceexpire (gulm_interface_p lgp, char *nodename)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	if (nodename == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_mbr_force)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, nodename)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_forcepending - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_forcepending (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_forcepend)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_lock.c linux-patched/fs/gfs_locking/lock_gulm/lg_lock.c
--- linux-orig/fs/gfs_locking/lock_gulm/lg_lock.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_lock.c	2005-01-12 17:20:30.315655406 -0600
@@ -0,0 +1,785 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/* all of the lock related fucntion are here. */
+#include "lg_priv.h"
+
+/**
+ * lg_lock_selector - 
+ * @ulm_interface_p: 
+ * 
+ * 
+ * Returns: int
+ */
+xdr_socket
+lg_lock_selector (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL || lg->first_magic != LGMAGIC
+	    || lg->last_magic != LGMAGIC)
+#ifdef __KERNEL__
+		return NULL;
+#else
+		return -EINVAL;
+#endif
+
+	return lg->lock_fd;
+}
+
+/**
+ * lg_lock_handle_messages - 
+ * @ulm_interface_p: 
+ * @lg_lockspace_callbacks_t: 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_handle_messages (gulm_interface_p lgp, lg_lockspace_callbacks_t * cbp,
+			 void *misc)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_dec_t *dec;
+	int err = 0;
+	uint64_t x_subid, x_start, x_stop;
+	uint32_t x_code, x_error, x_flags;
+	uint16_t x_keylen, x_lvblen = 0;
+	uint8_t x_state;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EBADR;
+
+	down (&lg->lock_recver);
+	if (lg->in_lock_hm)
+		return -EDEADLK;
+	lg->in_lock_hm = TRUE;
+	up (&lg->lock_recver);
+
+	dec = lg->lock_dec;
+
+	err = xdr_dec_uint32 (dec, &x_code);
+	if (err != 0)
+		goto exit;
+
+	if (gulm_lock_login_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+		} while (0);
+		if (err != 0)
+			goto exit;
+		if (cbp->login_reply == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->login_reply (misc, x_error, x_state);
+		goto exit;
+	} else if (gulm_lock_logout_rpl == x_code) {
+		if (cbp->logout_reply != NULL) {
+			err = cbp->logout_reply (misc);
+		}
+
+		xdr_close (&lg->lock_fd);
+		xdr_enc_release (lg->lock_enc);
+		lg->lock_enc = NULL;
+		xdr_dec_release (lg->lock_dec);
+		lg->lock_dec = NULL;
+
+		goto exit;
+	} else if (gulm_lock_state_rpl == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_start)) != 0 )
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_stop)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_flags)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+			if (x_flags & gio_lck_fg_hasLVB) {
+				if ((err =
+				     xdr_dec_raw_ag (dec, (void **) &lg->lfbb,
+						     &lg->lfbb_len,
+						     &x_lvblen)) != 0)
+					break;
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (x_keylen <= 4) {
+			err = -EPROTO;	/* or something */
+			goto exit;
+		}
+		if (cbp->lock_state == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->lock_state (misc, &lg->lfba[4], x_keylen - 4,
+				       x_subid, x_start, x_stop,
+				       x_state, x_flags, x_error,
+				       lg->lfbb, x_lvblen);
+		goto exit;
+	} else if (gulm_lock_action_rpl == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (x_keylen <= 4) {
+			err = -EPROTO;	/* or something */
+			goto exit;
+		}
+		if (cbp->lock_action == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err =
+		    cbp->lock_action (misc, &lg->lfba[4], x_keylen - 4,
+				      x_subid, x_state, x_error);
+		goto exit;
+	} else if (gulm_lock_query_rpl == x_code) {
+		uint64_t x_c_subid=0, x_c_start=0, x_c_stop=0;
+		uint8_t x_c_state=0;
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_start)) != 0 )
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_stop)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+			/* i realize that I'm pretty much ignoring the fact that
+			 * this is can be a list of items.  As of current, there
+			 * is never more than one item on this list.
+			 * I think I made it a list so it could be in the future,
+			 * even though I cannot think of why.
+			 */
+			if ((err = xdr_dec_list_start(dec)) != 0)
+				break;
+			while (xdr_dec_list_stop(dec) != 0) {
+				if((err = xdr_dec_string_ag(dec, &lg->lfbb, &lg->lfbb_len)) != 0) break;
+				if((err = xdr_dec_uint64(dec, &x_c_subid)) != 0 ) break;
+				if((err = xdr_dec_uint64(dec, &x_c_start)) != 0 ) break;
+				if((err = xdr_dec_uint64(dec, &x_c_stop)) != 0 ) break;
+				if((err = xdr_dec_uint8(dec, &x_c_state)) != 0) break;
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (x_keylen <= 4) {
+			err = -EPROTO;	/* or something */
+			goto exit;
+		}
+		if (cbp->lock_query == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->lock_query (misc, &lg->lfba[4], x_keylen - 4,
+				       x_subid, x_start, x_stop, x_state,
+				       x_error, lg->lfbb, x_c_subid,
+				       x_c_start, x_c_stop, x_c_state);
+		goto exit;
+	} else if (gulm_lock_cb_state == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (cbp->drop_lock_req == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err =
+		    cbp->drop_lock_req (misc, &lg->lfba[4], x_keylen - 4,
+					x_subid, x_state);
+		goto exit;
+	} else if (gulm_lock_cb_dropall == x_code) {
+		if (cbp->drop_all == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->drop_all (misc);
+		goto exit;
+	} else if (gulm_info_stats_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec) != 0) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->lfba,
+							&lg->lfba_len)) != 0)
+					break;
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->lfbb,
+							&lg->lfbb_len)) != 0)
+					break;
+			}
+		} while (0);
+		goto exit;
+	} else if (gulm_err_reply == x_code) {
+		do {
+			if ((err = xdr_dec_uint32 (dec, &x_code)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+		} while (0);
+		if (err != 0)
+			goto exit;
+		if (cbp->error == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->error (misc, x_error);
+		goto exit;
+	} else {
+		err = -EPROTO;
+		goto exit;
+	}
+
+      exit:
+	lg->in_lock_hm = FALSE;
+	return err;
+}
+
+/**
+ * lg_lock_login - 
+ * @ulm_interface_p: 
+ * @4: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_login (gulm_interface_p lgp, uint8_t lockspace[4])
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct sockaddr_in6 adr;
+	int err;
+	xdr_socket cfd;
+	xdr_enc_t *enc;
+	xdr_dec_t *dec;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	adr.sin6_family = AF_INET6;
+	adr.sin6_addr = in6addr_loopback;
+	adr.sin6_port = htons (lg->lock_port);
+
+	if ((err = xdr_open (&cfd)) < 0) {
+		return err;
+	}
+
+	if ((err = xdr_connect (&adr, cfd)) < 0) {
+		xdr_close (&cfd);
+		return err;
+	}
+
+	enc = xdr_enc_init (cfd, 512);
+	if (enc == NULL) {
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	dec = xdr_dec_init (cfd, 512);
+	if (enc == NULL) {
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_login_req)) < 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, GIO_WIREPROT_VERS)) < 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->service_name)) < 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, gio_lck_st_Client)) < 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) < 0)
+			break;
+
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_sel_lckspc)) < 0)
+			break;
+		if ((err = xdr_enc_raw (enc, lockspace, 4)) < 0)
+			break;
+		/* don't flush here.
+		 * dumb programmer stunt.  This way, the lockspace selection won't
+		 * happen until the next thing the user of this lib sends.  Which
+		 * means it will be after we have received the login reply.
+		 *
+		 * Is there really a good reason not to flush here?
+		 */
+	} while (0);
+	if (err != 0) {
+		xdr_dec_release (dec);
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return err;
+	}
+
+	down (&lg->lock_sender);
+	lg->lock_fd = cfd;
+	lg->lock_enc = enc;
+	lg->lock_dec = dec;
+
+	memcpy (lg->lockspace, lockspace, 4);
+	up (&lg->lock_sender);
+
+	return 0;
+}
+
+/**
+ * lg_lock_logout - 
+ * @ulm_interface_p: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_logout (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_logout_req)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_state_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @flags: 
+ * @LVB: 
+ * @LVBlen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_state_req (gulm_interface_p lgp, uint8_t * key, uint16_t keylen,
+		   uint64_t subid, uint64_t start, uint64_t stop,
+		   uint8_t state, uint32_t flags, uint8_t * LVB,
+		   uint16_t LVBlen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	uint32_t iflgs = 0;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	if (state != lg_lock_state_Unlock &&
+	    state != lg_lock_state_Exclusive &&
+	    state != lg_lock_state_Deferred && state != lg_lock_state_Shared)
+		return -EINVAL;
+
+	/* make sure only the accepted flags get passed through. */
+	if ((flags & lg_lock_flag_DoCB) == lg_lock_flag_DoCB)
+		iflgs |= lg_lock_flag_DoCB;
+	if ((flags & lg_lock_flag_Try) == lg_lock_flag_Try)
+		iflgs |= lg_lock_flag_Try;
+	if ((flags & lg_lock_flag_Any) == lg_lock_flag_Any)
+		iflgs |= lg_lock_flag_Any;
+	if ((flags & lg_lock_flag_IgnoreExp) == lg_lock_flag_IgnoreExp)
+		iflgs |= lg_lock_flag_IgnoreExp;
+	if ((flags & lg_lock_flag_Piority) == lg_lock_flag_Piority)
+		iflgs |= lg_lock_flag_Piority;
+
+	enc = lg->lock_enc;
+
+	if (LVB != NULL && LVBlen > 0)
+		iflgs |= gio_lck_fg_hasLVB;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_state_req)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, subid)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, start)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, stop)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, state)) != 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, iflgs)) != 0)
+			break;
+		if (iflgs & gio_lck_fg_hasLVB)
+			if ((err = xdr_enc_raw (enc, LVB, LVBlen)) != 0)
+				break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_cancel_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_cancel_req (gulm_interface_p lgp, uint8_t * key, uint16_t keylen,
+		uint64_t subid)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_action_req)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, subid)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, gio_lck_st_Cancel)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_action_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * @action: 
+ * @LVB: 
+ * @LVBlen: 
+ * 
+ * XXX
+ * I wonder if I should actually break this into three seperate calls for
+ * the lvb stuff.  Does it really matter?
+ * 
+ * Returns: int
+ */
+int
+lg_lock_action_req (gulm_interface_p lgp, uint8_t * key, uint16_t keylen,
+		    uint64_t subid, uint8_t action, uint8_t * LVB,
+		    uint16_t LVBlen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	if (action != lg_lock_act_HoldLVB &&
+	    action != lg_lock_act_UnHoldLVB && action != lg_lock_act_SyncLVB)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_action_req)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, subid)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, action)) != 0)
+			break;
+		if (action == gio_lck_st_SyncLVB)
+			if ((err = xdr_enc_raw (enc, LVB, LVBlen)) != 0)
+				break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_query_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * @subid: 
+ * @start: 
+ * @stop: 
+ * @state: 
+ * 
+ * 
+ * Returns: int
+ */
+int lg_lock_query_req(gulm_interface_p lgp, uint8_t *key, uint16_t keylen,
+      uint64_t subid, uint64_t start, uint64_t stop, uint8_t state)
+{
+   gulm_interface_t *lg = (gulm_interface_t *)lgp;
+   struct iovec iov[2];
+   xdr_enc_t *enc;
+   int err;
+
+   /* make sure it is a gulm_interface_p. */
+   if( lg == NULL ) return -EINVAL;
+   if( lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC ) return -EINVAL;
+
+   if( lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+      return -EINVAL;
+
+   if( state != lg_lock_state_Unlock &&
+       state != lg_lock_state_Exclusive &&
+       state != lg_lock_state_Deferred &&
+       state != lg_lock_state_Shared )
+      return -EINVAL;
+
+   if( stop < start ) return -EINVAL;
+
+   enc = lg->lock_enc;
+
+   iov[0].iov_base = lg->lockspace;
+   iov[0].iov_len = 4;
+   iov[1].iov_base = key;
+   iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+   do{
+      if((err = xdr_enc_uint32(enc, gulm_lock_query_req)) != 0 ) break;
+      if((err = xdr_enc_raw_iov(enc, 2, iov)) != 0 ) break;
+      if((err = xdr_enc_uint64(enc, subid)) != 0) break;
+      if((err = xdr_enc_uint64(enc, start)) != 0) break;
+      if((err = xdr_enc_uint64(enc, stop)) != 0) break;
+      if((err = xdr_enc_uint8(enc, state)) != 0 ) break;
+      if((err = xdr_enc_flush(enc)) != 0 ) break;
+   }while(0);
+	up (&lg->lock_sender);
+   return err;
+}
+
+/**
+ * lg_lock_drop_exp - 
+ * @ulm_interface_p: 
+ * @holder: 
+ * @keymask: 
+ * @kmlen: 
+ * 
+ * holder is the node name of the expired holder that you want to clear.
+ * Only locks matching the keymask will be looked at. (most of the time you
+ * will just set key to a bunch of 0xff to match all) The keymask lets you
+ * basically subdivide your lockspace into smaller seperate parts.
+ * (example, there is one gfs lockspace, but each filesystem gets its own
+ * subpart of that larger space)
+ *
+ * If holder is NULL, all expired holders in your lockspace will get
+ * dropped.
+ * 
+ * Returns: int
+ */
+int
+lg_lock_drop_exp (gulm_interface_p lgp, uint8_t * holder, uint8_t * key,
+		  uint16_t keylen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = (key != NULL) ? keylen : 0;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_drop_exp)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, holder)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+int
+lg_lock_expire (gulm_interface_p lgp, uint8_t * holder, uint8_t * key,
+		  uint16_t keylen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = (key != NULL) ? keylen : 0;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_expire)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, holder)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
+
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_main.c linux-patched/fs/gfs_locking/lock_gulm/lg_main.c
--- linux-orig/fs/gfs_locking/lock_gulm/lg_main.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_main.c	2005-01-12 17:20:30.319654505 -0600
@@ -0,0 +1,209 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/* This is where all of the library specific functions exist.
+ * Not many, but keeps things clean.
+ */
+
+#include "lg_priv.h"
+#include "gulm.h"
+extern gulm_cm_t gulm_cm;
+
+/**
+ * lg_initialize - 
+ * @gulm_interface_p:
+ * @cluster_name:
+ * @service_name: 
+ * 
+ * if returning an error, nothing was done to the value of gulm_interface_p
+ * 
+ * Returns: gulm_interface_p
+ */
+int
+lg_initialize (gulm_interface_p * ret, char *cluster_name, char *service_name)
+{
+	gulm_interface_t *lg;
+	int err, len;
+
+	lg = kmalloc (sizeof (gulm_interface_t), GFP_KERNEL);
+	if (lg == NULL)
+		return -ENOMEM;
+
+	memset (lg, 0, sizeof (gulm_interface_t));
+	lg->first_magic = LGMAGIC;
+	lg->last_magic = LGMAGIC;
+
+	if (cluster_name == NULL)
+		cluster_name = "cluster";
+	len = strlen (cluster_name) + 1;
+	lg->clusterID = kmalloc (len, GFP_KERNEL);
+	if (lg->clusterID == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+	memcpy (lg->clusterID, cluster_name, len);
+
+	len = strlen (service_name) + 1;
+	lg->service_name = kmalloc (len, GFP_KERNEL);
+	if (lg->service_name == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+	memcpy (lg->service_name, service_name, len);
+
+	/* set up flutter bufs. */
+	lg->cfba_len = 64;
+	lg->cfba = kmalloc (lg->cfba_len, GFP_KERNEL);
+	if (lg->cfba == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	lg->cfbb_len = 64;
+	lg->cfbb = kmalloc (lg->cfbb_len, GFP_KERNEL);
+	if (lg->cfbb == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	lg->lfba_len = 128;
+	lg->lfba = kmalloc (lg->lfba_len, GFP_KERNEL);
+	if (lg->lfba == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	lg->lfbb_len = 128;
+	lg->lfbb = kmalloc (lg->lfbb_len, GFP_KERNEL);
+	if (lg->lfbb == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	/* setup mutexes */
+	init_MUTEX (&lg->core_sender);
+	init_MUTEX (&lg->core_recver);
+	init_MUTEX (&lg->lock_sender);
+	init_MUTEX (&lg->lock_recver);
+
+	lg->core_port = 40040;
+	lg->lock_port = 40042;
+
+	*ret = lg;
+	return 0;
+      fail_nomem:
+	if (lg->clusterID != NULL)
+		kfree (lg->clusterID);
+	if (lg->service_name != NULL)
+		kfree (lg->service_name);
+	if (lg->cfba != NULL)
+		kfree (lg->cfba);
+	if (lg->cfbb != NULL)
+		kfree (lg->cfbb);
+	if (lg->lfba != NULL)
+		kfree (lg->lfba);
+	if (lg->lfbb != NULL)
+		kfree (lg->lfbb);
+	kfree (lg);
+	return err;
+}
+
+/**
+ * lg_release - 
+ * @lg: 
+ * 
+ */
+void
+lg_release (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	if (lgp == NULL)
+		return;
+	/* make sure it is a gulm_interface_p. */
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return;
+
+	if (lg->service_name != NULL)
+		kfree (lg->service_name);
+	if (lg->clusterID != NULL)
+		kfree (lg->clusterID);
+
+	/* wonder if I should send a logout packet? */
+	if (lg->core_enc != NULL)
+		xdr_enc_release (lg->core_enc);
+	if (lg->core_dec != NULL)
+		xdr_dec_release (lg->core_dec);
+	xdr_close (&lg->core_fd);
+
+	if (lg->lock_enc != NULL)
+		xdr_enc_release (lg->lock_enc);
+	if (lg->lock_dec != NULL)
+		xdr_dec_release (lg->lock_dec);
+	xdr_close (&lg->lock_fd);
+
+	if (lg->cfba != NULL)
+		kfree (lg->cfba);
+	if (lg->cfbb != NULL)
+		kfree (lg->cfbb);
+	if (lg->lfba != NULL)
+		kfree (lg->lfba);
+	if (lg->lfbb != NULL)
+		kfree (lg->lfbb);
+
+	kfree (lg);
+}
+
+/**
+ * lg_set_core_port - 
+ * @lgp: 
+ * @new: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_set_core_port (gulm_interface_p lgp, uint16_t new)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	if (lgp == NULL)
+		return -EINVAL;
+	/* make sure it is a gulm_interface_p. */
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	lg->core_port = new;
+	return 0;
+}
+
+/**
+ * lg_set_ltpx_port - 
+ * @lgp: 
+ * @new: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_set_lock_port (gulm_interface_p lgp, uint16_t new)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	if (lgp == NULL)
+		return -EINVAL;
+	/* make sure it is a gulm_interface_p. */
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	lg->lock_port = new;
+
+	return 0;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_priv.h linux-patched/fs/gfs_locking/lock_gulm/lg_priv.h
--- linux-orig/fs/gfs_locking/lock_gulm/lg_priv.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_priv.h	2005-01-12 17:20:30.319654505 -0600
@@ -0,0 +1,86 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __lg_priv_h__
+#define __lg_priv_h__
+/* private details that we don't want to give the users of this lib access
+ * to go here.
+ */
+
+#ifdef __linux__
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+#endif /*__linux__*/
+
+#include "xdr.h"
+#include "gio_wiretypes.h"
+#include "libgulm.h"
+
+#define LGMAGIC (0x474d4354)
+
+struct gulm_interface_s {
+	/* since we've masked this to a void* to the users, it is a nice safty
+	 * net to put a little magic in here so we know things stay good.
+	 */
+	uint32_t first_magic;
+
+	/* WHAT IS YOUR NAME?!? */
+	char *service_name;
+
+	char *clusterID;
+
+	uint16_t core_port;
+	xdr_socket core_fd;
+	xdr_enc_t *core_enc;
+	xdr_dec_t *core_dec;
+	struct semaphore core_sender;
+	struct semaphore core_recver;
+	int in_core_hm;
+
+	uint16_t lock_port;
+	xdr_socket lock_fd;
+	xdr_enc_t *lock_enc;
+	xdr_dec_t *lock_dec;
+	struct semaphore lock_sender;
+	struct semaphore lock_recver;
+	int in_lock_hm;
+	uint8_t lockspace[4];
+
+	/* in the message recver func, we read data into these buffers and pass
+	 * them to the callback function.  This way we avoid doinf mallocs and
+	 * frees on every callback.
+	 */
+	uint16_t cfba_len;
+	uint8_t *cfba;
+	uint16_t cfbb_len;
+	uint8_t *cfbb;
+	uint16_t lfba_len;
+	uint8_t *lfba;
+	uint16_t lfbb_len;
+	uint8_t *lfbb;
+
+	uint32_t last_magic;
+};
+typedef struct gulm_interface_s gulm_interface_t;
+
+#ifndef TRUE
+#define TRUE (1)
+#endif
+
+#ifndef FALSE
+#define FALSE (0)
+#endif
+
+#endif /*__lg_priv_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/libgulm.h linux-patched/fs/gfs_locking/lock_gulm/libgulm.h
--- linux-orig/fs/gfs_locking/lock_gulm/libgulm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/libgulm.h	2005-01-12 17:20:30.319654505 -0600
@@ -0,0 +1,199 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __libgulm_h__
+#define __libgulm_h__
+
+/* bit messy, but we need this to be rather seemless in both kernel and
+ * userspace. and this seems the easiest way to do it.
+ */
+
+#ifdef __linux__
+#include <linux/in6.h>
+typedef struct socket *lg_socket;
+#endif /*__linux__*/
+
+typedef void *gulm_interface_p;
+
+/* mallocs the interface structure.
+ */
+int lg_initialize (gulm_interface_p *, char *cluster_name, char *service_name);
+/* frees struct.
+ */
+void lg_release (gulm_interface_p);
+
+/* Determins where we are with a itemlist callback */
+typedef enum { lglcb_start, lglcb_item, lglcb_stop } lglcb_t;
+
+/****** Core specifics ******/
+
+/* leaving a callback pointer as NULL, will cause that message type to 
+ * be ignored. */
+typedef struct lg_core_callbacks_s {
+	int (*login_reply) (void *misc, uint64_t gen, uint32_t error,
+			    uint32_t rank, uint8_t corestate);
+	int (*logout_reply) (void *misc);
+	int (*nodelist) (void *misc, lglcb_t type, char *name,
+			 struct in6_addr * ip, uint8_t state);
+	int (*statechange) (void *misc, uint8_t corestate, uint8_t quorate,
+			    struct in6_addr * masterip, char *mastername);
+	int (*nodechange) (void *misc, char *nodename,
+			   struct in6_addr * nodeip, uint8_t nodestate);
+	int (*service_list) (void *misc, lglcb_t type, char *service);
+	int (*error) (void *misc, uint32_t err);
+} lg_core_callbacks_t;
+
+/* this will trigger a callback from gulm_core_callbacks_t 
+ * handles one message! Either stick this inside of a thread,
+ * or in a poll()/select() loop using the function below.
+ * This will block until there is a message sent from core. 
+ */
+int lg_core_handle_messages (gulm_interface_p, lg_core_callbacks_t *,
+			     void *misc);
+
+/* this returns the filedescriptor that the library is using to 
+ * communicate with the core. This is only for using in a poll() 
+ * or select() call to avoid having the gulm_core_handle_messages()
+ * call block. 
+ */
+lg_socket lg_core_selector (gulm_interface_p);
+
+/* Queue requests. */
+int lg_core_login (gulm_interface_p, int important);
+int lg_core_logout (gulm_interface_p);
+int lg_core_nodeinfo (gulm_interface_p, char *nodename);
+int lg_core_nodelist (gulm_interface_p);
+int lg_core_servicelist (gulm_interface_p);
+int lg_core_corestate (gulm_interface_p);
+
+/* for completeness mostly. */
+int lg_core_shutdown (gulm_interface_p);
+int lg_core_forceexpire (gulm_interface_p, char *node_name);
+int lg_core_forcepending (gulm_interface_p);
+
+/* Node states
+ * First three are actual states, as well as changes.  Last is only a node
+ * change message.
+ * */
+#define lg_core_Logged_in  (0x05)
+#define lg_core_Logged_out (0x06)
+#define lg_core_Expired    (0x07)
+#define lg_core_Fenced     (0x08)
+/* Core states */
+#define lg_core_Slave       (0x01)
+#define lg_core_Master      (0x02)
+#define lg_core_Pending     (0x03)
+#define lg_core_Arbitrating (0x04)
+#define lg_core_Client      (0x06)
+
+/****** lock space specifics *****/
+/* note that this library masks out the lock table seperation. 
+ */
+
+typedef struct lg_lockspace_callbacks_s {
+	int (*login_reply) (void *misc, uint32_t error, uint8_t which);
+	int (*logout_reply) (void *misc);
+	int (*lock_state) (void *misc, uint8_t * key, uint16_t keylen,
+			   uint64_t subid, uint64_t start, uint64_t stop,
+			   uint8_t state, uint32_t flags, uint32_t error,
+			   uint8_t * LVB, uint16_t LVBlen);
+	int (*lock_action) (void *misc, uint8_t * key, uint16_t keylen,
+			    uint64_t subid, uint8_t action, uint32_t error);
+	int (*drop_lock_req) (void *misc, uint8_t * key, uint16_t keylen,
+			      uint64_t subid, uint8_t state);
+	int (*lock_query) (void *misc, uint8_t * key, uint16_t keylen,
+			   uint64_t subid, uint64_t start, uint64_t stop,
+			   uint8_t state, uint32_t error, uint8_t * cnode,
+			   uint64_t csubid, uint64_t cstart, uint64_t cstop,
+			   uint8_t cstate);
+	int (*drop_all) (void *misc);
+	int (*error) (void *misc, uint32_t err);
+} lg_lockspace_callbacks_t;
+
+/* Like the core handle messages function, but for the lockspace.
+ * Handles one message, blocks.
+ */
+
+int lg_lock_handle_messages (gulm_interface_p, lg_lockspace_callbacks_t *,
+			     void *misc);
+
+/* this returns the filedescriptor that the library is using to 
+ * communicate with the ltpx. This is only for using in a poll() 
+ * or select() call to avoid having the gulm_lock_handle_messages()
+ * call block. 
+ */
+lg_socket lg_lock_selector (gulm_interface_p);
+
+/* Lockspace request calls */
+int lg_lock_login (gulm_interface_p, uint8_t lockspace[4]);
+int lg_lock_logout (gulm_interface_p);
+int lg_lock_state_req (gulm_interface_p, uint8_t * key, uint16_t keylen,
+                       uint64_t subid, uint64_t start, uint64_t stop,
+		       uint8_t state, uint32_t flags, uint8_t * LVB,
+		       uint16_t LVBlen);
+int lg_lock_cancel_req (gulm_interface_p, uint8_t * key, uint16_t keylen,
+			uint64_t subid);
+int lg_lock_action_req (gulm_interface_p, uint8_t * key, uint16_t keylen,
+			uint64_t subid, uint8_t action,
+			uint8_t * LVB, uint16_t LVBlen);
+int lg_lock_query_req(gulm_interface_p lgp, uint8_t *key, uint16_t keylen,
+      uint64_t subid, uint64_t start, uint64_t stop, uint8_t state);
+int lg_lock_drop_exp (gulm_interface_p, uint8_t * holder,
+		      uint8_t * keymask, uint16_t kmlen);
+int lg_lock_expire (gulm_interface_p lgp, uint8_t * holder, uint8_t * key,
+		  uint16_t keylen);
+
+/* state requests */
+#define lg_lock_state_Unlock    (0x00)
+#define lg_lock_state_Exclusive (0x01)
+#define lg_lock_state_Deferred  (0x02)
+#define lg_lock_state_Shared    (0x03)
+
+/* actions */
+#define lg_lock_act_HoldLVB     (0x0b)
+#define lg_lock_act_UnHoldLVB   (0x0c)
+#define lg_lock_act_SyncLVB     (0x0d)
+
+/* flags */
+#define lg_lock_flag_DoCB        (0x00000001)
+#define lg_lock_flag_Try         (0x00000002)
+#define lg_lock_flag_Any         (0x00000004)
+#define lg_lock_flag_IgnoreExp   (0x00000008)
+#define lg_lock_flag_Cachable    (0x00000020)
+#define lg_lock_flag_Piority     (0x00000040)
+#define lg_lock_flag_NoCallBacks (0x00000100)
+
+/* These are the possible values that can be in the error fields. */
+#define lg_err_Ok              (0)
+#define lg_err_BadLogin        (1001)
+#define lg_err_BadCluster      (1003)
+#define lg_err_BadConfig       (1004)
+#define lg_err_BadGeneration   (1005)
+#define lg_err_BadWireProto    (1019)
+
+#define lg_err_NotAllowed      (1006)
+#define lg_err_Unknown_Cs      (1007)
+#define lg_err_BadStateChg     (1008)
+#define lg_err_MemoryIssues    (1009)
+
+#define lg_err_TryFailed       (1011)
+#define lg_err_AlreadyPend     (1013)
+#define lg_err_Canceled        (1015)
+
+#define lg_err_NoSuchFS        (1016)
+#define lg_err_NoSuchJID       (1017)
+#define lg_err_NoSuchName      (1018)
+
+#endif /*__libgulm_h__*/
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.c linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.c
--- linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.c	2005-01-12 17:20:30.320654280 -0600
@@ -0,0 +1,66 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gio_wiretypes.h"
+
+char *
+gio_Err_to_str (int x)
+{
+	char *t = "Unknown GULM Err";
+	switch (x) {
+	case gio_Err_Ok:
+		t = "Ok";
+		break;
+
+	case gio_Err_BadLogin:
+		t = "Bad Login";
+		break;
+	case gio_Err_BadCluster:
+		t = "Bad Cluster ID";
+		break;
+	case gio_Err_BadConfig:
+		t = "Incompatible configurations";
+		break;
+	case gio_Err_BadGeneration:
+		t = "Bad Generation ID";
+		break;
+	case gio_Err_BadWireProto:
+		t = "Bad Wire Protocol Version";
+		break;
+
+	case gio_Err_NotAllowed:
+		t = "Not Allowed";
+		break;
+	case gio_Err_Unknown_Cs:
+		t = "Uknown Client";
+		break;
+	case gio_Err_BadStateChg:
+		t = "Bad State Change";
+		break;
+	case gio_Err_MemoryIssues:
+		t = "Memory Problems";
+		break;
+
+	case gio_Err_TryFailed:
+		t = "Try Failed";
+		break;
+	case gio_Err_AlreadyPend:
+		t = "Request Already Pending";
+		break;
+	case gio_Err_Canceled:
+		t = "Request Canceled";
+		break;
+	}
+	return t;
+}
+
diff -urN linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.h linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.h
--- linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.h	2005-01-12 17:20:30.320654280 -0600
@@ -0,0 +1,17 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __utils_tostr_h__
+#define __utils_tostr_h__
+char *gio_Err_to_str (int x);
+#endif /*__utils_tostr_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr.h linux-patched/fs/gfs_locking/lock_gulm/xdr.h
--- linux-orig/fs/gfs_locking/lock_gulm/xdr.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr.h	2005-01-12 17:20:30.320654280 -0600
@@ -0,0 +1,98 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __gulm_xdr_h__
+#define __gulm_xdr_h__
+typedef struct xdr_enc_s xdr_enc_t;
+typedef struct xdr_dec_s xdr_dec_t;
+
+/* sockets in kernel space are done a bit different than socket in
+ * userspace.  But we need to have them appear to be the same.
+ */
+#ifdef __KERNEL__
+
+#ifdef __linux__
+#include <linux/net.h>
+#include <linux/in.h>
+#include <linux/in6.h>
+#include <linux/socket.h>
+#include <net/sock.h>
+
+typedef struct socket *xdr_socket;
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+#include <sys/types.h>
+#include <sys/uio.h>
+#include <sys/socket.h>
+#include <netinet/in.h>
+#include <netinet/tcp.h>
+#include <unistd.h>
+#include <errno.h>
+typedef int xdr_socket;
+#endif /*__KERNEL__*/
+
+/* start things up */
+int xdr_open (xdr_socket * sk);
+int xdr_connect (struct sockaddr_in6 *adr, xdr_socket sk);
+void xdr_close (xdr_socket * sk);
+
+/* deep, basic io */
+#ifdef __KERNEL__
+#ifdef __linux__
+size_t xdr_send (struct socket *sock, void *buf, size_t size);
+size_t xdr_recv (struct socket *sock, void *buf, size_t size);
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+ssize_t xdr_recv (int fd, void *buf, size_t len);
+ssize_t xdr_send (int fd, void *buf, size_t len);
+#endif /*__KERNEL__*/
+
+xdr_enc_t *xdr_enc_init (xdr_socket sk, int buffer_size);
+xdr_dec_t *xdr_dec_init (xdr_socket sk, int buffer_size);
+int xdr_enc_flush (xdr_enc_t * xdr);
+int xdr_enc_release (xdr_enc_t * xdr);	/* calls xdr_enc_flush() */
+void xdr_enc_force_release (xdr_enc_t * xdr);	/* doesn't call xdr_enc_flush() */
+void xdr_dec_release (xdr_dec_t * xdr);
+/* xdr_enc_force_release() is for when you get and error sending and you
+ * want to free that stuff up right away.  If you use the regular release
+ * for enc, it will fail if it cannot send data over the filedesciptor.
+ */
+
+/* encoders add to a stream */
+int xdr_enc_uint64 (xdr_enc_t * xdr, uint64_t i);
+int xdr_enc_uint32 (xdr_enc_t * xdr, uint32_t i);
+int xdr_enc_uint16 (xdr_enc_t * xdr, uint16_t i);
+int xdr_enc_uint8 (xdr_enc_t * xdr, uint8_t i);
+int xdr_enc_ipv6 (xdr_enc_t * enc, struct in6_addr *ip);
+int xdr_enc_raw (xdr_enc_t * xdr, void *pointer, uint16_t len);
+int xdr_enc_raw_iov (xdr_enc_t * xdr, int count, struct iovec *iov);
+int xdr_enc_string (xdr_enc_t * xdr, uint8_t * s);
+int xdr_enc_list_start (xdr_enc_t * xdr);
+int xdr_enc_list_stop (xdr_enc_t * xdr);
+
+/* decoders remove from stream */
+int xdr_dec_uint64 (xdr_dec_t * xdr, uint64_t * i);
+int xdr_dec_uint32 (xdr_dec_t * xdr, uint32_t * i);
+int xdr_dec_uint16 (xdr_dec_t * xdr, uint16_t * i);
+int xdr_dec_uint8 (xdr_dec_t * xdr, uint8_t * i);
+int xdr_dec_ipv6 (xdr_dec_t * xdr, struct in6_addr *ip);
+int xdr_dec_raw (xdr_dec_t * xdr, void *p, uint16_t * l);	/* no malloc */
+int xdr_dec_raw_m (xdr_dec_t * xdr, void **p, uint16_t * l);	/* mallocs p */
+int xdr_dec_raw_ag (xdr_dec_t * xdr, void **p, uint16_t * bl, uint16_t * rl);
+int xdr_dec_string (xdr_dec_t * xdr, uint8_t ** strp);	/* mallocs s */
+int xdr_dec_string_nm (xdr_dec_t * xdr, uint8_t * strp, size_t l);	/* no malloc */
+int xdr_dec_string_ag (xdr_dec_t * xdr, uint8_t ** s, uint16_t * bl);
+int xdr_dec_list_start (xdr_dec_t * xdr);
+int xdr_dec_list_stop (xdr_dec_t * xdr);
+
+#endif /*__gulm_xdr_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr_base.c linux-patched/fs/gfs_locking/lock_gulm/xdr_base.c
--- linux-orig/fs/gfs_locking/lock_gulm/xdr_base.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr_base.c	2005-01-12 17:20:30.321654054 -0600
@@ -0,0 +1,904 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+ * This is a bit of an abstraction layer to get this working in both kernel
+ * and userspace.
+ */
+#define TRUE  (1)
+#define FALSE (0)
+#define MIN(a,b) ((a<b)?a:b)
+
+#ifdef __linux__
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+#endif /*__linux__*/
+
+#include "xdr.h"
+
+/**
+ * xdr_realloc - a realloc for kernel space.
+ * @a: < pointer to realloc
+ * @nl: < desired new size
+ * @ol: < current old size
+ * 
+ * Not as good as the real realloc, since it always moves memory.  But good
+ * enough for as little as it will get used here.
+ *
+ * XXX this is broken.
+ * 
+ * Returns: void*
+ */
+static void *
+xdr_realloc (void *a, size_t nl, size_t ol)
+{
+	if (nl == ol) {
+		return a;
+	} else if (nl == 0) {
+		kfree (a);
+		return NULL;
+	} else if (a == NULL && nl > 0) {
+		return kmalloc (nl, GFP_KERNEL);
+	} else {
+		void *tmp;
+		tmp = kmalloc (nl, GFP_KERNEL);
+		if (tmp == NULL)
+			return NULL;
+		memcpy (tmp, a, MIN (nl, ol));
+		kfree (a);
+		return tmp;
+	}
+}
+
+typedef enum { xdr_enc, xdr_dec } xdr_type;
+
+/* encoders have this sorta non-blocking, growing buffering stunt.
+ * makes them a bit different from the decoders now.
+ */
+struct xdr_enc_s {
+	size_t default_buf_size;
+	xdr_socket fd;
+	xdr_type type;
+	size_t length;
+	size_t curloc;
+	uint8_t *stream;
+};
+
+/* decoders only pull a single item off of the socket at a time.
+ * so this is all they need.
+ */
+struct xdr_dec_s {
+	size_t length;		/* total byte length of the stream */
+	size_t curloc;		/* current byte offset from start */
+	uint8_t *stream;	/* start of the encoded stream. */
+	xdr_socket fd;
+	xdr_type type;
+};
+
+/* the types of data we support. */
+
+#define XDR_NULL          0x00	/* NOT A VALID TAG!!! used in dec code. */
+#define XDR_LIST_START    0x01
+#define XDR_LIST_STOP     0x02
+/* list is a variable length device.  It is a start tag, some number of
+ * xdr_enc_*, then an stop tag.  It's main purpose is to provide a method
+ * of encasing data.
+ * */
+#define XDR_STRING        0x04
+/* string tag is followed by a uint16 which is the byte length */
+#define XDR_RAW           0x05
+/* raw tag is followed by a uint16 which is the byte length
+ * if 65535 bytes isn't enough, split your data and put multiples of these
+ * back to back.  (idea of xdr is to avoid this twit.)
+ * */
+
+/* note, if the size of these should variate, I'm screwed.  Should consider
+ * changing this all to the bit shift and array access to be more concrete.
+ * later.
+ */
+#define XDR_UINT64        0x06
+#define XDR_UINT32        0x07
+#define XDR_UINT16        0x08
+#define XDR_UINT8         0x09
+/* should add signed ints */
+
+#define XDR_IPv6          0x0a	/* 16 bytes, IPv6 address */
+
+/* any other base types?
+ */
+
+#define XDR_DEFAULT_BUFFER_SIZE 4096
+/*****************************************************************************/
+
+/**
+ * xdr_enc_init - 
+ * @fd: 
+ * @buffer_size: 
+ * 
+ * 
+ * Returns: xdr_enc_t*
+ */
+xdr_enc_t *
+xdr_enc_init (xdr_socket fd, int buffer_size)
+{
+	xdr_enc_t *xdr;
+
+	if (buffer_size <= 0)
+		buffer_size = XDR_DEFAULT_BUFFER_SIZE;
+
+	xdr = kmalloc (sizeof (xdr_enc_t), GFP_KERNEL);
+	if (xdr == NULL)
+		return NULL;
+	xdr->stream = kmalloc (buffer_size, GFP_KERNEL);
+	if (xdr->stream == NULL) {
+		kfree (xdr);
+		return NULL;
+	}
+	xdr->fd = fd;
+	xdr->type = xdr_enc;
+	xdr->default_buf_size = buffer_size;
+	xdr->length = buffer_size;
+	xdr->curloc = 0;
+
+	return xdr;
+}
+
+/**
+ * xdr_dec_init - 
+ * @fd: 
+ * @buffer_size: 
+ * 
+ * 
+ * Returns: xdr_dec_t*
+ */
+xdr_dec_t *
+xdr_dec_init (xdr_socket fd, int buffer_size)
+{
+	xdr_dec_t *xdr;
+
+	if (buffer_size <= 0)
+		buffer_size = XDR_DEFAULT_BUFFER_SIZE;
+
+	xdr = kmalloc (sizeof (xdr_dec_t), GFP_KERNEL);
+	if (xdr == NULL)
+		return NULL;
+	xdr->length = buffer_size;
+	xdr->curloc = 0;
+	xdr->stream = kmalloc (buffer_size, GFP_KERNEL);
+	xdr->fd = fd;
+	xdr->type = xdr_dec;
+	if (xdr->stream == NULL) {
+		kfree (xdr);
+		return NULL;
+	}
+	*(xdr->stream) = XDR_NULL;	/* so the first dec_call will call get_next */
+	return xdr;
+}
+
+/*****************************************************************************/
+/**
+ * xdr_enc_flush - 
+ * @xdr: 
+ * 
+ * Returns: int
+ */
+int
+xdr_enc_flush (xdr_enc_t * xdr)
+{
+	int err;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (xdr->type != xdr_enc)
+		return -EINVAL;
+	if (xdr->curloc == 0)
+		return 0;
+
+	err = xdr_send (xdr->fd, xdr->stream, xdr->curloc);
+	if (err < 0)
+		return err;
+	if (err == 0)
+		return -EPROTO;	/* why? */
+	xdr->curloc = 0;
+
+	return 0;
+}
+
+/**
+ * xdr_release - 
+ * @xdr: 
+ *
+ * Free the memory, losing whatever may be there.
+ */
+void
+xdr_dec_release (xdr_dec_t * xdr)
+{
+	if (xdr == NULL)
+		return;
+	kfree (xdr->stream);
+	kfree (xdr);
+}
+
+/**
+ * xdr_enc_force_release - 
+ * @xdr: 
+ * 
+ * Free the memory, losing whatever may be there.
+ */
+void
+xdr_enc_force_release (xdr_enc_t * xdr)
+{
+	if (xdr == NULL)
+		return;
+	if (xdr->stream != NULL)
+		kfree (xdr->stream);
+	kfree (xdr);
+}
+
+/**
+ * xdr_enc_release - 
+ * @xdr: 
+ * 
+ * Free things up, trying to send any possible leftover data first.
+ * 
+ * Returns: int
+ */
+int
+xdr_enc_release (xdr_enc_t * xdr)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = xdr_enc_flush (xdr)) != 0)
+		return e;
+	xdr_enc_force_release (xdr);
+	return 0;
+}
+
+/*****************************************************************************/
+/**
+ * grow_stream - 
+ * @xdr: 
+ * @len: 
+ * 
+ * each single encoded call needs to fit within a buffer.  So we make sure
+ * the buffer is big enough.
+ *
+ * If the buffer is big enough, but just doesn't have room, we send the
+ * data in the buffer, emptying it, first.
+ * 
+ * Returns: int
+ */
+static int
+grow_stream (xdr_enc_t * enc, size_t len)
+{
+	int err;
+	uint8_t *c;
+
+	/* buffer must be big enough for one type entry. */
+	if (len > enc->length) {
+		c = xdr_realloc (enc->stream, len, enc->length);
+		if (c == NULL)
+			return -ENOMEM;
+		enc->stream = c;
+		enc->length = len;
+	}
+
+	/* if there isn't room on the end of this chunk,
+	 * try sending what we've got.
+	 */
+	if (enc->curloc + len > enc->length) {
+		err = xdr_enc_flush (enc);
+		if (err != 0) {
+			/* error, better pass this up. */
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+/**
+ * append_bytes - 
+ * @xdr: 
+ * @xdr_type: 
+ * @bytes: 
+ * @len: 
+ * 
+ * 
+ * Returns: int
+ */
+static int
+append_bytes (xdr_enc_t * xdr, uint8_t xdr_type, void *bytes, size_t len)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (xdr->type != xdr_enc)
+		return -EINVAL;
+
+	/* len + 1; need the one byte for the type code. */
+	if ((e = grow_stream (xdr, len + 1)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = xdr_type;
+	xdr->curloc += 1;
+	memcpy ((xdr->stream + xdr->curloc), bytes, len);
+	xdr->curloc += len;
+
+	return 0;
+}
+
+int
+xdr_enc_uint64 (xdr_enc_t * xdr, uint64_t i)
+{
+	uint64_t b = cpu_to_be64 (i);
+	return append_bytes (xdr, XDR_UINT64, &b, sizeof (uint64_t));
+}
+
+int
+xdr_enc_uint32 (xdr_enc_t * xdr, uint32_t i)
+{
+	uint32_t b = cpu_to_be32 (i);
+	return append_bytes (xdr, XDR_UINT32, &b, sizeof (uint32_t));
+}
+
+int
+xdr_enc_uint16 (xdr_enc_t * xdr, uint16_t i)
+{
+	uint16_t b = cpu_to_be16 (i);
+	return append_bytes (xdr, XDR_UINT16, &b, sizeof (uint16_t));
+}
+
+int
+xdr_enc_uint8 (xdr_enc_t * xdr, uint8_t i)
+{
+	return append_bytes (xdr, XDR_UINT8, &i, sizeof (uint8_t));
+}
+
+int
+xdr_enc_ipv6 (xdr_enc_t * xdr, struct in6_addr *ip)
+{				/* bytes should already be in the right order. */
+	return append_bytes (xdr, XDR_IPv6, ip->s6_addr, 16);
+}
+
+int
+xdr_enc_raw (xdr_enc_t * xdr, void *p, uint16_t len)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = grow_stream (xdr, len + 3)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_RAW;
+	xdr->curloc += 1;
+	(uint16_t) * ((uint16_t *) (xdr->stream + xdr->curloc)) =
+	    cpu_to_be16 (len);
+	xdr->curloc += 2;
+	memcpy ((xdr->stream + xdr->curloc), p, len);
+	xdr->curloc += len;
+	return 0;
+}
+
+int
+xdr_enc_raw_iov (xdr_enc_t * xdr, int count, struct iovec *iov)
+{
+	size_t total = 0;
+	int i, err;
+	if (xdr == NULL || count < 1 || iov == NULL)
+		return -EINVAL;
+	for (i = 0; i < count; i++)
+		total += iov[i].iov_len;
+	/* make sure it fits in a uint16_t */
+	if (total > 0xffff)
+		return -EFBIG;
+	/* grow to fit */
+	if ((err = grow_stream (xdr, total + 3)) != 0)
+		return err;
+	/* copy in header and size */
+	*(xdr->stream + xdr->curloc) = XDR_RAW;
+	xdr->curloc += 1;
+	(uint16_t) * ((uint16_t *) (xdr->stream + xdr->curloc)) =
+	    cpu_to_be16 (total);
+	xdr->curloc += 2;
+	/* copy in all iovbufs */
+	for (i = 0; i < count; i++) {
+		if (iov[i].iov_base == NULL)
+			continue;
+		memcpy ((xdr->stream + xdr->curloc), iov[i].iov_base,
+			iov[i].iov_len);
+		xdr->curloc += iov[i].iov_len;
+	}
+	return 0;
+}
+
+int
+xdr_enc_string (xdr_enc_t * xdr, uint8_t * s)
+{
+	int len, e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (s == NULL)
+		len = 0;
+	else
+		len = strlen (s);
+	if ((e = grow_stream (xdr, len + 3)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_STRING;
+	xdr->curloc += 1;
+	(uint16_t) * ((uint16_t *) (xdr->stream + xdr->curloc)) =
+	    cpu_to_be16 (len);
+	xdr->curloc += 2;
+	if (len > 0) {
+		memcpy ((xdr->stream + xdr->curloc), s, len);
+		xdr->curloc += len;
+	}
+	return 0;
+}
+
+int
+xdr_enc_list_start (xdr_enc_t * xdr)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = grow_stream (xdr, 1)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_LIST_START;
+	xdr->curloc += 1;
+	return 0;
+}
+
+int
+xdr_enc_list_stop (xdr_enc_t * xdr)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = grow_stream (xdr, 1)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_LIST_STOP;
+	xdr->curloc += 1;
+	return 0;
+}
+
+/*****************************************************************************/
+
+/**
+ * get_next - 
+ * @xdr: 
+ * 
+ * get what ever may be next, and put it into the buffer.
+ * 
+ * Returns: int
+ */
+static int
+get_next (xdr_dec_t * xdr)
+{
+	int err;
+	uint16_t len;
+	if ((err = xdr_recv (xdr->fd, xdr->stream, 1)) < 0)
+		return err;
+	if (err == 0)
+		return -EPROTO;
+	xdr->curloc = 1;
+	if (*(xdr->stream) == XDR_UINT64) {
+		len = sizeof (uint64_t);
+	} else if (*(xdr->stream) == XDR_UINT32) {
+		len = sizeof (uint32_t);
+	} else if (*(xdr->stream) == XDR_UINT16) {
+		len = sizeof (uint16_t);
+	} else if (*(xdr->stream) == XDR_UINT8) {
+		len = sizeof (uint8_t);
+	} else if (*(xdr->stream) == XDR_IPv6) {
+		len = 16;
+	} else if (*(xdr->stream) == XDR_STRING) {
+		if ((err = xdr_recv (xdr->fd, (xdr->stream + 1), 2)) < 0)
+			return err;
+		if (err == 0)
+			return -EPROTO;
+		len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+		xdr->curloc += 2;
+	} else if (*(xdr->stream) == XDR_RAW) {
+		if ((err = xdr_recv (xdr->fd, (xdr->stream + 1), 2)) < 0)
+			return err;
+		if (err == 0)
+			return -EPROTO;
+		len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+		xdr->curloc += 2;
+	} else if (*(xdr->stream) == XDR_LIST_START) {
+		xdr->curloc = 0;
+		return 0;
+	} else if (*(xdr->stream) == XDR_LIST_STOP) {
+		xdr->curloc = 0;
+		return 0;
+	} else {
+		return -1;
+	}
+
+	/* grow buffer if need be. */
+	if (xdr->curloc + len > xdr->length) {
+		uint8_t *c;
+		c = xdr_realloc (xdr->stream, xdr->curloc + len, xdr->length);
+		if (c == NULL)
+			return -ENOMEM;
+		xdr->stream = c;
+		xdr->length = xdr->curloc + len;
+	}
+
+	if (len > 0) {
+		if ((err =
+		     xdr_recv (xdr->fd, (xdr->stream + xdr->curloc), len)) < 0)
+			return err;
+		if (err == 0)
+			return -EPROTO;
+	}
+	xdr->curloc = 0;
+	return 0;
+}
+
+int
+xdr_dec_uint64 (xdr_dec_t * xdr, uint64_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT64)
+		return -ENOMSG;
+	*i = be64_to_cpu (*((uint64_t *) (xdr->stream + 1)));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_uint32 (xdr_dec_t * xdr, uint32_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT32)
+		return -ENOMSG;
+	*i = be32_to_cpu (*((uint32_t *) (xdr->stream + 1)));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_uint16 (xdr_dec_t * xdr, uint16_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT16)
+		return -ENOMSG;
+	*i = be16_to_cpu (*((uint16_t *) (xdr->stream + 1)));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_uint8 (xdr_dec_t * xdr, uint8_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT8)
+		return -ENOMSG;
+	*i = *((uint8_t *) (xdr->stream + 1));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_ipv6 (xdr_dec_t * xdr, struct in6_addr *ip)
+{
+	int err;
+	if (xdr == NULL || ip == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_IPv6)
+		return -ENOMSG;
+	memcpy (ip, xdr->stream + 1, 16);
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* mallocing version */
+int
+xdr_dec_raw_m (xdr_dec_t * xdr, void **p, uint16_t * l)
+{
+	int len;
+	void *str;
+	int err;
+
+	if (xdr == NULL || p == NULL || l == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_RAW)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	str = kmalloc (len, GFP_KERNEL);
+	if (str == NULL)
+		return -ENOMEM;
+	memcpy (str, (xdr->stream + xdr->curloc), len);
+	xdr->curloc += len;
+
+	*p = str;
+	*l = len;
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* non-mallocing version */
+int
+xdr_dec_raw (xdr_dec_t * xdr, void *p, uint16_t * l)
+{
+	int len;
+	int err;
+
+	if (xdr == NULL || p == NULL || l == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_RAW)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > *l)
+		return -1;
+
+	memcpy (p, (xdr->stream + xdr->curloc), len);
+	xdr->curloc += len;
+
+	*l = len;
+
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/**
+ * xdr_dec_raw_ag - auto-growing version
+ * @xdr: 
+ * @p: <> pointer to buffer
+ * @bl: <> size of the buffer
+ * @rl: > size of data read from stream
+ * 
+ * This form of xdr_dec_raw will increase the size of a pre-malloced buffer
+ * to fit the data it is reading.  It is kind of a merger of the
+ * non-mallocing and mallocing versions.
+ * 
+ * Returns: int
+ */
+int
+xdr_dec_raw_ag (xdr_dec_t * xdr, void **p, uint16_t * bl, uint16_t * rl)
+{
+	int len;
+	int err;
+
+	if (xdr == NULL || p == NULL || bl == NULL || rl == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_RAW)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > *bl) {	/* grow p */
+		void *temp;
+		temp = xdr_realloc (*p, len, *bl);
+		if (temp == NULL)
+			return -ENOMEM;
+		*bl = len;
+		*p = temp;
+	}
+
+	memcpy (*p, (xdr->stream + xdr->curloc), len);
+	xdr->curloc += len;
+
+	*rl = len;
+
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* mallocing version */
+int
+xdr_dec_string (xdr_dec_t * xdr, uint8_t ** strp)
+{
+	int len;
+	char *str;
+	int err;
+	if (xdr == NULL || strp == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_STRING)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > 0) {
+		str = kmalloc (len + 1, GFP_KERNEL);
+		if (str == NULL)
+			return -ENOMEM;
+		str[len] = '\0';
+		memcpy (str, (xdr->stream + xdr->curloc), len);
+		xdr->curloc += len;
+
+		*strp = str;
+	} else {
+		*strp = NULL;
+	}
+
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* non-mallocing version */
+int
+xdr_dec_string_nm (xdr_dec_t * xdr, uint8_t * string, size_t l)
+{
+	int len;
+	int err;
+	if (xdr == NULL || string == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_STRING)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > 0) {
+		memcpy (string, (xdr->stream + xdr->curloc), MIN (len, l));
+		if (l > len) {
+			string[len] = '\0';
+		}
+		string[l - 1] = '\0';
+	} else {
+		string[0] = '\0';
+	}
+
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_string_ag (xdr_dec_t * xdr, uint8_t ** s, uint16_t * bl)
+{
+	int len;
+	int err;
+	if (xdr == NULL || s == NULL || bl == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_STRING)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len == 0) {		/* empty string */
+		**s = '\0';
+		*(xdr->stream) = XDR_NULL;
+		return 0;
+	}
+
+	if (len >= *bl) {	/* grow s */
+		void *temp;
+		temp = xdr_realloc (*s, len + 1, *bl);
+		if (temp == NULL)
+			return -ENOMEM;
+		*bl = len + 1;
+		*s = temp;
+	}
+
+	memcpy (*s, (xdr->stream + xdr->curloc), len);
+	(*s)[len] = '\0';
+
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_list_start (xdr_dec_t * xdr)
+{
+	int err;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_LIST_START)
+		return -ENOMSG;
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_list_stop (xdr_dec_t * xdr)
+{
+	int err;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_LIST_STOP)
+		return -ENOMSG;
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr_io.c linux-patched/fs/gfs_locking/lock_gulm/xdr_io.c
--- linux-orig/fs/gfs_locking/lock_gulm/xdr_io.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr_io.c	2005-01-12 17:20:30.321654054 -0600
@@ -0,0 +1,169 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+ * does the lowest level of reads and writes.
+ * In kernel and/or userspace.
+ */
+
+#include "xdr.h"
+
+#ifdef __KERNEL__
+#ifdef __linux__
+#include <linux/net.h>
+#include <linux/in.h>
+#include <linux/socket.h>
+#include <net/sock.h>
+#include "asm/uaccess.h"
+
+/**
+ * do_tfer - transfers data over a socket
+ * @sock: < socket
+ * @iov: <> iovec of buffers
+ * @n:    < how many iovecs
+ * @size: < total data size to send/recv
+ * @dir:  < send or recv
+ * @timeout: < how many sec to wait. 0 == forever.
+ * 
+ * Returns: <0: Error
+ *         >=0: Bytes transfered
+ */
+static int
+do_tfer (struct socket *sock, struct iovec *iov, int n, int size, int dir)
+{
+	unsigned long flags;
+	sigset_t oldset;
+	struct msghdr m;
+	mm_segment_t fs;
+	int rv, moved = 0;
+
+	fs = get_fs ();
+	set_fs (get_ds ());
+
+	/* XXX do I still want the signal stuff? */
+	spin_lock_irqsave (&current->sighand->siglock, flags);
+	oldset = current->blocked;
+	siginitsetinv (&current->blocked,
+		       sigmask (SIGKILL) | sigmask (SIGTERM));
+	recalc_sigpending ();
+	spin_unlock_irqrestore (&current->sighand->siglock, flags);
+
+	memset (&m, 0, sizeof (struct msghdr));
+	for (;;) {
+		m.msg_iov = iov;
+		m.msg_iovlen = n;
+		m.msg_flags = MSG_NOSIGNAL;
+
+		if (dir)
+			rv = sock_sendmsg (sock, &m, size - moved);
+		else
+			rv = sock_recvmsg (sock, &m, size - moved, 0);
+
+		if (rv <= 0)
+			goto out_err;
+		moved += rv;
+
+		if (moved >= size)
+			break;
+
+		/* adjust iov's for next transfer */
+		while (iov->iov_len == 0) {
+			iov++;
+			n--;
+		}
+
+	}
+	rv = moved;
+      out_err:
+	spin_lock_irqsave (&current->sighand->siglock, flags);
+	current->blocked = oldset;
+	recalc_sigpending ();
+	spin_unlock_irqrestore (&current->sighand->siglock, flags);
+
+	set_fs (fs);
+
+	return rv;
+}
+
+size_t
+xdr_send (struct socket * sock, void *buf, size_t size)
+{
+	struct iovec iov;
+	int res;
+
+	iov.iov_base = buf;
+	iov.iov_len = size;
+
+	res = do_tfer (sock, &iov, 1, size, 1);
+
+	return res;
+}
+
+size_t
+xdr_recv (struct socket * sock, void *buf, size_t size)
+{
+	struct iovec iov;
+	int res;
+
+	iov.iov_base = buf;
+	iov.iov_len = size;
+
+	res = do_tfer (sock, &iov, 1, size, 0);
+
+	return res;
+}
+
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+
+#include <errno.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+
+ssize_t
+xdr_recv (int fd, void *buf, size_t len)
+{
+	ssize_t cnt = 0;
+	size_t ttl = 0;
+	while (len > 0) {
+		cnt = recv (fd, buf, len, 0);
+		if (cnt == 0)
+			return 0;
+		if (cnt < 0)
+			return -errno;
+		len -= cnt;
+		buf += cnt;
+		ttl += cnt;
+	}
+	return ttl;
+}
+
+ssize_t
+xdr_send (int fd, void *buf, size_t len)
+{
+	ssize_t cnt = 0;
+	size_t ttl = 0;
+	while (len > 0) {
+		cnt = send (fd, buf, len, 0);
+		if (cnt == 0)
+			return 0;
+		if (cnt < 0)
+			return -errno;
+		len -= cnt;
+		buf += cnt;
+		ttl += cnt;
+	}
+	return ttl;
+}
+
+#endif /*__KERNEL__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr_socket.c linux-patched/fs/gfs_locking/lock_gulm/xdr_socket.c
--- linux-orig/fs/gfs_locking/lock_gulm/xdr_socket.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr_socket.c	2005-01-12 17:20:30.321654054 -0600
@@ -0,0 +1,82 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+ * This file opens and closes a socket.
+ * In kernel and/or userspace.
+ */
+
+#include "xdr.h"
+
+#ifdef __KERNEL__
+#ifdef __linux__
+
+int
+xdr_open (xdr_socket * xsk)
+{
+	return sock_create (AF_INET6, SOCK_STREAM, 0, xsk);
+}
+
+int
+xdr_connect (struct sockaddr_in6 *adr, xdr_socket xsk)
+{
+	return xsk->ops->connect (xsk,
+				  (struct sockaddr *) adr,
+				  sizeof (struct sockaddr_in6), 0);
+}
+
+void
+xdr_close (xdr_socket * xsk)
+{
+	if (*xsk == NULL)
+		return;
+	sock_release (*xsk);
+	*xsk = NULL;
+}
+
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+
+int
+xdr_open (xdr_socket * xsk)
+{
+	int sk;
+	sk = socket (AF_INET6, SOCK_STREAM, 0);
+	if (sk < 0)
+		return -errno;
+	*xsk = sk;
+	return 0;
+}
+
+int
+xdr_connect (struct sockaddr_in6 *adr, xdr_socket xsk)
+{
+	int err;
+	err =
+	    connect (xsk, (struct sockaddr *) adr,
+		     sizeof (struct sockaddr_in6));
+	if (err < 0)
+		return -errno;
+	return 0;
+}
+
+void
+xdr_close (xdr_socket * xsk)
+{
+	if (*xsk < 0)
+		return;
+	close (*xsk);
+	*xsk = -1;
+}
+
+#endif /*__KERNEL__*/
